{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FS_LSTM.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOa0gqQO+zXED9HVX9RSRNF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"oaAC0JBCN02j"},"source":["# Google Drive Mount\n"]},{"cell_type":"code","metadata":{"id":"LpqemH7GOMqY"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ysfLObq7Hl-g"},"source":["%cd /content/drive/My\\ Drive/Colab\\ Notebooks"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UDhFNOi1GdyD"},"source":["# Libraries"]},{"cell_type":"code","metadata":{"id":"IUH1g9xyOaba"},"source":["#Importing Libraries and Packages\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, IterableDataset\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# calculate train time, writing train data to files etc.\n","import os \n","import logging\n","import pandas as pd\n","import numpy as np\n","import time\n","from pathlib import Path\n","from random import randint\n","from scipy import signal\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc\n","\n","import pdb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1--dGDwEN-P4"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"id":"vEx9hj5FOdcE"},"source":["# Data split\n","class Split_data:\n","    def __init__(self, dir_path: str):\n","\n","        self.files = tuple(Path(dir_path).glob(\"**/*.csv\"))\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def splitset(self,split_ratio,random_seed,shuffle_dataset = True):\n","        dataset_size = len(self.files)\n","        indices = list(range(dataset_size))\n","        split = int(np.floor(split_ratio * len(self.files)))\n","        if shuffle_dataset:\n","            np.random.seed(random_seed)\n","            np.random.shuffle(indices)\n","        train_indices, val_indices = indices[split:], indices[:split]\n","        return train_indices,val_indices\n","\n","# Extracting data from csv files\n","class CoolDataset(IterableDataset):\n","\n","    def __init__(self, dir_path: str, seq_length: str, input_size: str, samples_per_events: str, indices, convolution=False):\n","\n","        super().__init__()\n","        self.files = tuple(Path(dir_path).glob(\"**/*.csv\"))\n","        self.indices = indices\n","        self.seq_length = seq_length\n","        self.input_size = input_size\n","        self.SAMPLES_PER_EVENT = samples_per_events\n","        self.window = signal.gaussian(8, std=3)\n","        self.convolution = convolution\n","\n","        assert seq_length % 2 == 0, \"Please pass an even seq length\"\n","\n","    def __iter__(self):\n","\n","        # Initialise Counter for events and files\n","        self.file_nr = 0\n","        self.event_in_file = 0\n","        self._sample_nr = 0\n","\n","        return self\n","\n","    def __next__(self):\n","        # Reads the current file and looks for event\n","        df = self.read_file(self.files[self.indices[self.file_nr]])  # could be cached so you dont read it anew every iteration\n","        events = df[df[\"FS\"] ==1]\n","        if events.shape[0] > 0:\n","            if self._sample_nr < self.SAMPLES_PER_EVENT:\n","                # just give back the current event again, with different sampling, until we have generated\n","                # SAMPLES_PER_EVENT such samples\n","                # pdb.set_trace()\n","                if self._sample_nr == 0:\n","                    event_frame = events.iloc[self.event_in_file].name\n","                if self._sample_nr == 1:\n","                    event_frame = events.iloc[self.event_in_file].name\n","                if self._sample_nr == 2:\n","                    event_frame = events.iloc[self.event_in_file].name\n","                if self._sample_nr == 3:\n","                    event_frame = events.iloc[self.event_in_file].name\n","                if self._sample_nr == 4:\n","                    event_frame = events.iloc[self.event_in_file].name + 1\n","                if self._sample_nr == 5:\n","                    event_frame = events.iloc[self.event_in_file].name + 1\n","                if self._sample_nr == 6:\n","                    event_frame = events.iloc[self.event_in_file].name - 1\n","                if self._sample_nr == 7:\n","                    event_frame = events.iloc[self.event_in_file].name - 1\n","                if self._sample_nr == 8:\n","                    event_frame = events.iloc[self.event_in_file].name - 2\n","                if self._sample_nr == 9:\n","                    event_frame = events.iloc[self.event_in_file].name + 2\n","                 \n","                input_data, output_data = self.sample_seq_around_event_frame(df, event_frame)\n","                self._sample_nr += 1\n","            # else:\n","            elif self._sample_nr == self.SAMPLES_PER_EVENT:\n","                \n","                # pdb.set_trace()\n","                self.event_in_file += 1  # work on the next event in this file\n","                self._sample_nr = 0  # reset for the next event\n","                \n","                # check whether we are done with this file\n","                # otherwise we return the next event on the beginning of the next iteration\n","                if self.event_in_file >= len(events):\n","                    self.file_nr += 1\n","                    # If there still are files to run, it resets the variables\n","                    if self.file_nr < len(self.indices):\n","                        # pdb.set_trace()\n","                        logging.info(\"File is complete. Going to new file...\")\n","                        self.event_in_file = 0\n","                        self._sample_nr = 0\n","                        return next(self)\n","                    else:\n","                        # processed the last file, we are done\n","                        logging.info(\"File is complete. All files done. Stopping...\")\n","                        raise StopIteration\n","                elif self.event_in_file < len(events):\n","\n","                    # pdb.set_trace()\n","\n","                    event_frame = events.iloc[self.event_in_file].name\n","                    input_data, output_data = self.sample_seq_around_event_frame(df, event_frame)\n","                    self._sample_nr += 1\n","        else:\n","            logging.info(\"No events detected\")\n","            # pdb.set_trace()\n","            self.file_nr += 1\n","            self.event_in_file = 0\n","            self._sample_nr = 0\n","            return next(self)\n","\n","        return input_data, output_data\n","\n","    def sample_seq_around_event_frame(self, df, event_idx):\n","\n","        # Returns inputs with event data\n","        start_idx = event_idx - randint(10, self.seq_length / 2)\n","        if start_idx > 0:\n","            end_idx = start_idx + self.seq_length\n","            if end_idx <= len(df):\n","                input = df.iloc[start_idx:end_idx, 0:self.input_size].to_numpy()\n","                output = df.iloc[start_idx:end_idx]['FS'].to_numpy()\n","            elif end_idx > len(df):\n","                end_idx = len(df)\n","                start_idx = end_idx - self.seq_length\n","                input = df.iloc[start_idx:end_idx, 0:self.input_size].to_numpy()\n","                output = df.iloc[start_idx:end_idx]['FS'].to_numpy()\n","        elif start_idx <= 0:\n","            start_idx = event_idx\n","            end_idx = start_idx + self.seq_length\n","            input = df.iloc[start_idx:end_idx, 0:self.input_size].to_numpy()\n","            output = df.iloc[start_idx:end_idx]['FS'].to_numpy()\n","            if end_idx <= len(df):\n","                input = df.iloc[start_idx:end_idx, 0:self.input_size].to_numpy()\n","                output = df.iloc[start_idx:end_idx]['FS'].to_numpy()\n","            elif end_idx > len(df):\n","                end_idx = len(df)\n","                start_idx = end_idx - self.seq_length\n","                input = df.iloc[start_idx:end_idx, 0:self.input_size].to_numpy()\n","                output = df.iloc[start_idx:end_idx]['FS'].to_numpy()\n","\n","        # Converted to Tensor\n","        if self.convolution:\n","            output = signal.convolve(output, self.window, mode='same')\n","\n","        input_data = input\n","        output_data = output\n","\n","        assert input_data.shape[0] == output_data.shape[0] == self.seq_length\n","\n","        return input_data, output_data\n","\n","    def read_file(self, f):\n","\n","        df = pd.read_csv(open(f, \"r\"))\n","        fname = os.path.basename(f)\n","        if fname[0:2] == 'RT':\n","            df = df.drop(['Unnamed: 0','ID',\n","                          'High_RTOE_X','RTOE_X','RTOE_Y','RTOE_Z','V_RTOE_X','V_RTOE_Y','V_RTOE_Z',\n","                          'High_RHEE_X',#'RHEE_X','RHEE_Y','RHEE_Z','V_RHEE_X','V_RHEE_Y','V_RHEE_Z',\n","                          'High_RANK_X','RANK_X','RANK_Y','RANK_Z','V_RANK_X','V_RANK_Y','V_RANK_Z',\n","                          'High_RHLX_X',#'RHLX_X','RHLX_Y','RHLX_Z','V_RHLX_X','V_RHLX_Y','V_RHLX_Z',\n","                          'High_RPMT5_X','RPMT5_X','RPMT5_Y','RPMT5_Z','V_RPMT5_X','V_RPMT5_Y','V_RPMT5_Z'], axis=1)#'RPMT5_X','RPMT5_Y','RPMT5_Z','V_RPMT5_X','V_RPMT5_Y','V_RPMT5_Z'\n","        elif fname[0:2] == 'LT':\n","            df = df.drop(['Unnamed: 0','ID',\n","                          'High_LTOE_X','LTOE_X','LTOE_Y','LTOE_Z','V_LTOE_X','V_LTOE_Y','V_LTOE_Z',\n","                          'High_LHEE_X',#LHEE_X','LHEE_Y','LHEE_Z','V_LHEE_X','V_LHEE_Y','V_LHEE_Z',\n","                          'High_LANK_X','LANK_X','LANK_Y','LANK_Z','V_LANK_X','V_LANK_Y','V_LANK_Z',\n","                          'High_LHLX_X',#'LHLX_X','LHLX_Y','LHLX_Z','V_LHLX_X','V_LHLX_Y','V_LHLX_Z',\n","                          'High_LPMT5_X','LPMT5_X','LPMT5_Y','LPMT5_Z','V_LPMT5_X','V_LPMT5_Y','V_LPMT5_Z'], axis=1)#'LPMT5_X','LPMT5_Y','LPMT5_Z','V_LPMT5_X','V_LPMT5_Y','V_LPMT5_Z'\n","        return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LrouCpqEOAUc"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"iPq_8WdYOloE"},"source":["class Network(nn.Module):\n","    # TO DO\n","    def __init__(self, config):\n","        super(Network, self).__init__()\n","\n","        # Model construct Configuration\n","        self.input_size = config.input_size\n","        self.hidden_size = config.hidden_size\n","        self.output_size = config.output_size\n","        self.batch_size = config.batch_size\n","        self.num_layers = config.num_layers\n","        self.drop_out = config.drop_out\n","        self.seq_length = config.seq_length\n","        self.device = config.device\n","        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, dropout = self.drop_out, batch_first=True,bidirectional=True)\n","        self.linear = nn.Linear(self.hidden_size*2, self.output_size,bias= True)\n","        torch.nn.init.xavier_uniform_(self.linear.weight)\n","\n","    def forward(self, x):\n","\n","        hidden, cell = self.init_hidden()\n","        out, _ = self.lstm(x, (hidden, cell))\n","        logits = self.linear(out)\n","\n","        return logits[:, :, -1]\n","\n","    def init_hidden(self):\n","\n","        weight = next((self.parameters())).data\n","        hidden, cell = (weight.new(self.num_layers*2, self.batch_size, self.hidden_size).zero_().to(self.device),\n","                        weight.new(self.num_layers*2, self.batch_size, self.hidden_size).zero_().to(self.device))\n","        return hidden, cell"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DwDmwFJboh8f"},"source":["# Early Stop"]},{"cell_type":"code","metadata":{"id":"mnRV3u22oiK6"},"source":["class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    # def __init__(self, patience: str,, delta: str, Name: str, verbose=False):\n","    def __init__(self, patience: str, delta: str, Name: str,  verbose = False,):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.Name = Name\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}\\n')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model\\n')\n","        torch.save(model.state_dict(), f\"Models/2markers/FS/HLXHEE/v1/{self.Name}-FScheckpoint.pt\",_use_new_zipfile_serialization=False)\n","        self.val_loss_min = val_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-df0ApraOCUQ"},"source":["# Training and Validation"]},{"cell_type":"code","metadata":{"id":"Cf2k1ArgOofi"},"source":["class Trainer:\n","\n","    def __init__(self,input_size, batch_size,seq_length,hidden_size,num_layers,drop_out,lr,epoch,config):\n","\n","        # System configuration\n","        self.device = config.device\n","        self.log_interval = config.log_interval\n","        self.output_size = config.output_size\n","        self.seed = config.seed\n","        self.validation_split = config.validation_split\n","        self.convolution = config.convolution\n","        torch.manual_seed(self.seed)\n","\n","        # Hyper Parameters\n","        config.input_size = input_size\n","        config.batch_size = batch_size\n","        config.hidden_size = hidden_size\n","        config.seq_length = seq_length\n","        config.num_layers = num_layers\n","        config.drop_out = drop_out\n","        config.lr = lr\n","\n","        # Model Construction\n","        self.model = Network(config).to(self.device)\n","        self.model = self.model.to(self.device)\n","        print(self.model)\n","\n","        # Optimizer and Loss\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n","        self.pos_weight = torch.ones([config.weight_length])  \n","        self.pos_weight_factor = self.pos_weight * config.weight_factor\n","        self.criterion = nn.BCEWithLogitsLoss(pos_weight= self.pos_weight_factor).to(self.device)\n","       \n","        # Initialise the early_stopping object\n","        self.Name = f\"FS-{config.weight_factor}-WF-{hidden_size}-HS-{num_layers}-NL-{lr}-LR-{epoch}-epochs\"\n","        self.early_stopping = EarlyStopping(patience=model_config.patience, verbose=True,delta = model_config.delta,Name = self.Name)\n","        print(self.Name)\n","\n","        # DataLoader\n","        dataset = Split_data(r\"data/iteration1/train/\")\n","        train_idx, val_idx = dataset.splitset(self.validation_split,self.seed)\n","        self.train_loader = DataLoader(CoolDataset(r\"data/iteration1/train/\", config.seq_length, config.input_size, config.samples_per_event, train_idx,convolution=self.convolution), batch_size=config.batch_size, drop_last=True, shuffle=False)\n","        self.val_loader = DataLoader(CoolDataset(r\"data/iteration1/train/\", config.seq_length, config.input_size, config.samples_per_event, val_idx,convolution=self.convolution), batch_size=config.batch_size, drop_last=True, shuffle=False)\n","\n","        self.globaliter = 0     \n","        train_log_dir = 'logs/tensorboard_FS/2markers/train/HLXHEE'+ self.Name\n","        val_log_dir = 'logs/tensorboard_FS/2markers/val/HLXHEE' + self.Name\n","        self.train_summary_writer = SummaryWriter(train_log_dir)\n","        self.val_summary_writer =  SummaryWriter(val_log_dir)\n","\n","    def train(self,epoch):\n","      \n","      self.model.train()\n","      start = time.time()\n","      with self.train_summary_writer:\n","        for batch_idx, (data, target) in enumerate(self.train_loader):\n","              \n","              self.optimizer.zero_grad()\n","\n","              data, target = data.to(self.device), target.to(self.device)\n","              predictions = self.model(data.float())\n","              loss = self.criterion(predictions.float(), target.float())\n","              loss.backward()\n","              \n","              self.optimizer.step()\n","              pred = torch.sigmoid(predictions.detach())\n","              correct_indx_positive = pred[target > 0.5]  # Should have batch_size * 1's\n","              correct_indx_negative = pred[target <= 0.5]  # Should have (batch_size*seq_length-batch_size) * 0'\n","\n","              TPR = len(correct_indx_positive[correct_indx_positive > 0.5]) / len(correct_indx_positive)\n","              TNR = len(correct_indx_negative[correct_indx_negative <= 0.5]) / len(correct_indx_negative)\n","              TPR = TPR * 100\n","              TNR = TNR * 100\n","\n","\n","              self.globaliter += 1\n","              \n","              if batch_idx % self.log_interval == 0:\n","\n","                  print('Train Epoch: {}\\tLoss: {:.6f}\\tTPR: {}\\tTNR: {}\\tTime: {:.6f}'.format(epoch,loss.item(), TPR, TNR, (time.time() - start)))\n","                  self.train_summary_writer.add_scalar('Loss', loss.item(),self.globaliter)\n","  \n","    def val(self):\n","        \n","        self.model.eval()\n","        val_loss = 0\n","        start = time.time()\n","        with self.val_summary_writer:\n","          with torch.no_grad():\n","            for data, target in self.val_loader:\n","\n","                  data, target = data.to(self.device), target.to(self.device)\n","\n","                  predictions = self.model(data.float())\n","\n","                  val_loss = self.criterion(predictions.float(), target.float())\n","\n","                  pred = torch.sigmoid(predictions.detach())\n","                  correct_indx_positive = pred[target > 0.5]  # Should have batch_size * 1's\n","                  correct_indx_negative = pred[target <= 0.5]  # Should have (batch_size*seq_length-batch_size) * 0'\n","\n","                  TPR = len(correct_indx_positive[correct_indx_positive > 0.5]) / len(correct_indx_positive)\n","                  TNR = len(correct_indx_negative[correct_indx_negative <= 0.5]) / len(correct_indx_negative)\n","                  TPR = TPR * 100\n","                  TNR = TNR * 100\n","\n","\n","            print('Val_loss: {:.6f}\\tTPR: {}\\tTNR: {}\\tTime: {:.6f}\\n'.format(val_loss.item(), TPR, TNR, (time.time() - start)))\n","            self.val_summary_writer.add_scalar('val_loss', val_loss.item(),self.globaliter)\n","            return val_loss, TPR, TNR, self.Name"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5hBKti3JOEp_"},"source":["# Hyperparmeter Setting"]},{"cell_type":"code","metadata":{"id":"xvjgWhf-N0fr"},"source":["def main(hparam, model_config):\n","    for input_size in hparam['input_size']:\n","        for batch_size in hparam['batch_size']:\n","            for seq_length in hparam['seq_length']:\n","                for hidden_size in hparam['hidden_size']:\n","                    for lr in hparam['lr']:\n","                        for num_layers in hparam['num_layers']:\n","                            for drop_out in hparam['drop_out']:\n","                                for epochs in hparam['epochs']:\n","                                    trainer = Trainer(input_size, batch_size, seq_length, hidden_size, num_layers, drop_out, lr, epochs, model_config)\n","                                    TPR = dict()\n","                                    TNR = dict()\n","                                    for epoch in range(epochs):\n","                                        epoch_start = time.time()\n","                                        trainer.train(epoch)\n","                                        # pdb.set_trace()\n","                                        val_loss, TPR[epoch], TNR[epoch],Name = trainer.val()\n","                                        trainer.early_stopping(val_loss, trainer.model)\n","                                        if trainer.early_stopping.early_stop:\n","                                            print(\"Early stopping\")\n","                                            break\n","                                        print(f\"Epoch Duration {time.time() - epoch_start}\")\n","                                    # csv file save\n","                                    ROC = pd.DataFrame({'TPR':pd.Series(TPR),'TNR':pd.Series(TNR)})\n","                                    ROC.to_csv(f\"Models/2markers/FS/HLXHEE/v1/{Name}-ROC.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U89ullE8O6Rm"},"source":["# Main"]},{"cell_type":"code","metadata":{"id":"UnlPvKxYOwXK","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600968145187,"user_tz":-120,"elapsed":40046203,"user":{"displayName":"Yong Kuk Kim","photoUrl":"","userId":"05925217294532758280"}},"outputId":"19d8be40-7f7b-4e7b-d305-2ff3fd598556"},"source":["class Config:\n","\n","    def __init__(self, **kwargs):\n","        for key, value in kwargs.items():\n","            setattr(self, key, value)\n","            \n","if __name__ == '__main__':\n","    \n","    if torch.cuda.is_available():\n","      device = torch.device(\"cuda\") \n","      print(\"Running on the GPU\")\n","    else:\n","      device = torch.device(\"cpu\")\n","      print(\"Running on the CPU\")\n","\n","\n","    model_config = Config(\n","        device=device,\n","        # Early Stop\n","        patience=20,\n","        delta=0.001,\n","        log_interval=1000,\n","        # Dataset Configuration\n","        validation_split=0.2,\n","        seed=2,\n","        samples_per_event=1,\n","        convolution = True,\n","        output_size=1,\n","        # Weight loss\n","        weight_length=128,\n","        weight_factor=13,\n","    )\n","\n","    hparam = {\n","        \n","        'input_size': [12],   # 2 markers:12 3 markers: 18, 4 markers: 24, 5 markers:30, 6 markers:36, 7 markers:42, 8 markers:48\n","        'batch_size': [64],\n","        'seq_length': [128],\n","        'hidden_size': [256,512,1024],\n","        'num_layers': [2,5,10],\n","        'drop_out' : [0.5],\n","        'lr': [0.00001],\n","        'epochs': [100],\n","    }\n","\n","    main(hparam, model_config)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running on the GPU\n","Network(\n","  (lstm): LSTM(12, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=512, out_features=1, bias=True)\n",")\n","FS-13-WF-256-HS-2-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.064282\tTPR: 52.95358649789029\tTNR: 55.72687224669603\tTime: 13.846872\n","Val_loss: 0.856621\tTPR: 60.3448275862069\tTNR: 95.28985507246377\tTime: 94.157672\n","\n","Validation loss decreased (inf --> 0.856621).  Saving model\n","\n","Epoch Duration 483.5841841697693\n","Train Epoch: 1\tLoss: 0.894950\tTPR: 60.970464135021096\tTNR: 90.82663902565432\tTime: 1.104084\n","Val_loss: 0.721300\tTPR: 63.577586206896555\tTNR: 95.36749482401656\tTime: 11.294921\n","\n","Validation loss decreased (0.856621 --> 0.721300).  Saving model\n","\n","Epoch Duration 57.92519998550415\n","Train Epoch: 2\tLoss: 0.779394\tTPR: 63.92405063291139\tTNR: 94.4286084477844\tTime: 1.090584\n","Val_loss: 0.620926\tTPR: 64.87068965517241\tTNR: 94.8628364389234\tTime: 11.216306\n","\n","Validation loss decreased (0.721300 --> 0.620926).  Saving model\n","\n","Epoch Duration 57.71124982833862\n","Train Epoch: 3\tLoss: 0.678348\tTPR: 65.82278481012658\tTNR: 94.48043534594454\tTime: 1.065310\n","Val_loss: 0.541854\tTPR: 67.24137931034483\tTNR: 94.77225672877847\tTime: 11.137433\n","\n","Validation loss decreased (0.620926 --> 0.541854).  Saving model\n","\n","Epoch Duration 57.3429811000824\n","Train Epoch: 4\tLoss: 0.598465\tTPR: 70.67510548523207\tTNR: 94.5711324177248\tTime: 1.079843\n","Val_loss: 0.480486\tTPR: 77.80172413793103\tTNR: 93.95703933747413\tTime: 11.194763\n","\n","Validation loss decreased (0.541854 --> 0.480486).  Saving model\n","\n","Epoch Duration 58.16384768486023\n","Train Epoch: 5\tLoss: 0.538907\tTPR: 75.9493670886076\tTNR: 93.70303187354236\tTime: 1.078915\n","Val_loss: 0.427946\tTPR: 84.69827586206897\tTNR: 92.7148033126294\tTime: 11.097238\n","\n","Validation loss decreased (0.480486 --> 0.427946).  Saving model\n","\n","Epoch Duration 57.02931189537048\n","Train Epoch: 6\tLoss: 0.479494\tTPR: 82.91139240506328\tTNR: 93.44389738274165\tTime: 1.076270\n","Val_loss: 0.385848\tTPR: 88.36206896551724\tTNR: 91.93840579710145\tTime: 11.131850\n","\n","Validation loss decreased (0.427946 --> 0.385848).  Saving model\n","\n","Epoch Duration 56.92129373550415\n","Train Epoch: 7\tLoss: 0.435538\tTPR: 85.65400843881856\tTNR: 93.00336874838041\tTime: 1.077710\n","Val_loss: 0.352714\tTPR: 88.14655172413794\tTNR: 91.99016563146998\tTime: 11.122461\n","\n","Validation loss decreased (0.385848 --> 0.352714).  Saving model\n","\n","Epoch Duration 56.962810039520264\n","Train Epoch: 8\tLoss: 0.394631\tTPR: 88.39662447257383\tTNR: 92.62762373671936\tTime: 1.063734\n","Val_loss: 0.327372\tTPR: 89.22413793103449\tTNR: 92.18426501035196\tTime: 11.127342\n","\n","Validation loss decreased (0.352714 --> 0.327372).  Saving model\n","\n","Epoch Duration 56.751829385757446\n","Train Epoch: 9\tLoss: 0.364910\tTPR: 90.29535864978902\tTNR: 92.5369266649391\tTime: 1.074765\n","Val_loss: 0.305889\tTPR: 92.45689655172413\tTNR: 92.17132505175984\tTime: 11.070632\n","\n","Validation loss decreased (0.327372 --> 0.305889).  Saving model\n","\n","Epoch Duration 58.064127683639526\n","Train Epoch: 10\tLoss: 0.330789\tTPR: 91.77215189873418\tTNR: 92.89971495206012\tTime: 1.057763\n","Val_loss: 0.289959\tTPR: 93.75\tTNR: 92.30072463768117\tTime: 11.086892\n","\n","Validation loss decreased (0.305889 --> 0.289959).  Saving model\n","\n","Epoch Duration 56.996909618377686\n","Train Epoch: 11\tLoss: 0.317614\tTPR: 93.45991561181435\tTNR: 92.54988338947913\tTime: 1.095922\n","Val_loss: 0.274131\tTPR: 94.39655172413794\tTNR: 92.74068322981367\tTime: 11.122094\n","\n","Validation loss decreased (0.289959 --> 0.274131).  Saving model\n","\n","Epoch Duration 56.86859083175659\n","Train Epoch: 12\tLoss: 0.291669\tTPR: 95.78059071729957\tTNR: 92.60171028763928\tTime: 1.084853\n","Val_loss: 0.268091\tTPR: 93.53448275862068\tTNR: 93.15476190476191\tTime: 11.083369\n","\n","Validation loss decreased (0.274131 --> 0.268091).  Saving model\n","\n","Epoch Duration 56.81704235076904\n","Train Epoch: 13\tLoss: 0.283169\tTPR: 94.30379746835443\tTNR: 92.86084477844001\tTime: 1.064282\n","Val_loss: 0.260913\tTPR: 93.31896551724138\tTNR: 93.43944099378882\tTime: 11.098557\n","\n","Validation loss decreased (0.268091 --> 0.260913).  Saving model\n","\n","Epoch Duration 56.81435561180115\n","Train Epoch: 14\tLoss: 0.265666\tTPR: 95.78059071729957\tTNR: 93.26250323918114\tTime: 1.089453\n","Val_loss: 0.256062\tTPR: 92.88793103448276\tTNR: 93.80175983436853\tTime: 11.120610\n","\n","Validation loss decreased (0.260913 --> 0.256062).  Saving model\n","\n","Epoch Duration 56.78735542297363\n","Train Epoch: 15\tLoss: 0.256762\tTPR: 97.46835443037975\tTNR: 93.27545996372118\tTime: 1.134668\n","Val_loss: 0.250697\tTPR: 92.02586206896551\tTNR: 94.24171842650104\tTime: 11.045596\n","\n","Validation loss decreased (0.256062 --> 0.250697).  Saving model\n","\n","Epoch Duration 57.83907961845398\n","Train Epoch: 16\tLoss: 0.244720\tTPR: 96.83544303797468\tTNR: 94.02694998704327\tTime: 1.066558\n","Val_loss: 0.241873\tTPR: 92.88793103448276\tTNR: 94.68167701863354\tTime: 10.969275\n","\n","Validation loss decreased (0.250697 --> 0.241873).  Saving model\n","\n","Epoch Duration 56.74195313453674\n","Train Epoch: 17\tLoss: 0.235199\tTPR: 97.8902953586498\tTNR: 93.79372894532261\tTime: 1.075889\n","Val_loss: 0.242970\tTPR: 93.75\tTNR: 94.56521739130434\tTime: 10.962651\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 56.71968364715576\n","Train Epoch: 18\tLoss: 0.227843\tTPR: 97.0464135021097\tTNR: 94.22130085514382\tTime: 1.059157\n","Val_loss: 0.238199\tTPR: 92.88793103448276\tTNR: 94.824016563147\tTime: 11.156487\n","\n","Validation loss decreased (0.241873 --> 0.238199).  Saving model\n","\n","Epoch Duration 56.590595722198486\n","Train Epoch: 19\tLoss: 0.227409\tTPR: 97.25738396624473\tTNR: 94.32495465146411\tTime: 1.087906\n","Val_loss: 0.241347\tTPR: 92.67241379310344\tTNR: 95.32867494824016\tTime: 10.965371\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 56.53748440742493\n","Train Epoch: 20\tLoss: 0.223265\tTPR: 95.35864978902954\tTNR: 94.40269499870433\tTime: 1.047214\n","Val_loss: 0.242371\tTPR: 90.30172413793103\tTNR: 95.58747412008282\tTime: 11.024251\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 57.761168479919434\n","Train Epoch: 21\tLoss: 0.223943\tTPR: 95.78059071729957\tTNR: 94.48043534594454\tTime: 1.062297\n","Val_loss: 0.238602\tTPR: 88.57758620689656\tTNR: 96.19565217391305\tTime: 11.037997\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 56.51571750640869\n","Train Epoch: 22\tLoss: 0.228396\tTPR: 95.9915611814346\tTNR: 94.83026690852553\tTime: 1.078171\n","Val_loss: 0.241394\tTPR: 89.65517241379311\tTNR: 95.96273291925466\tTime: 11.089219\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 56.59682607650757\n","Train Epoch: 23\tLoss: 0.210269\tTPR: 95.78059071729957\tTNR: 95.06348795024617\tTime: 1.052040\n","Val_loss: 0.236999\tTPR: 92.24137931034483\tTNR: 95.7815734989648\tTime: 11.016620\n","\n","Validation loss decreased (0.238199 --> 0.236999).  Saving model\n","\n","Epoch Duration 56.5009925365448\n","Train Epoch: 24\tLoss: 0.208809\tTPR: 94.09282700421942\tTNR: 95.37444933920705\tTime: 1.060997\n","Val_loss: 0.247825\tTPR: 89.00862068965517\tTNR: 96.11801242236024\tTime: 11.048877\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 56.55015850067139\n","Train Epoch: 25\tLoss: 0.212993\tTPR: 94.51476793248945\tTNR: 95.10235812386628\tTime: 1.072711\n","Val_loss: 0.232613\tTPR: 91.16379310344827\tTNR: 96.3379917184265\tTime: 11.127226\n","\n","Validation loss decreased (0.236999 --> 0.232613).  Saving model\n","\n","Epoch Duration 57.09310579299927\n","Train Epoch: 26\tLoss: 0.196807\tTPR: 97.8902953586498\tTNR: 95.02461777662606\tTime: 1.169167\n","Val_loss: 0.242419\tTPR: 88.14655172413794\tTNR: 96.36387163561076\tTime: 10.970973\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 57.11807084083557\n","Train Epoch: 27\tLoss: 0.200410\tTPR: 94.9367088607595\tTNR: 95.50401658460741\tTime: 1.067108\n","Val_loss: 0.238183\tTPR: 88.79310344827587\tTNR: 96.71325051759835\tTime: 11.110125\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 56.73493218421936\n","Train Epoch: 28\tLoss: 0.199272\tTPR: 97.0464135021097\tTNR: 95.1800984711065\tTime: 1.083207\n","Val_loss: 0.251755\tTPR: 89.22413793103449\tTNR: 96.84265010351967\tTime: 11.191843\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 57.31497621536255\n","Train Epoch: 29\tLoss: 0.199098\tTPR: 94.09282700421942\tTNR: 95.69836745270796\tTime: 1.084331\n","Val_loss: 0.257088\tTPR: 86.85344827586206\tTNR: 96.51915113871635\tTime: 11.222937\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 57.428327560424805\n","Train Epoch: 30\tLoss: 0.182126\tTPR: 96.41350210970464\tTNR: 95.93158849442861\tTime: 1.063390\n","Val_loss: 0.247575\tTPR: 87.28448275862068\tTNR: 96.82971014492753\tTime: 10.988478\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 56.935367584228516\n","Train Epoch: 31\tLoss: 0.188999\tTPR: 95.35864978902954\tTNR: 95.50401658460741\tTime: 1.071464\n","Val_loss: 0.248450\tTPR: 88.36206896551724\tTNR: 96.75207039337475\tTime: 11.091767\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 57.78857946395874\n","Train Epoch: 32\tLoss: 0.186970\tTPR: 96.62447257383965\tTNR: 95.54288675822752\tTime: 1.060433\n","Val_loss: 0.244564\tTPR: 87.93103448275862\tTNR: 96.73913043478261\tTime: 10.917121\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 56.16139769554138\n","Train Epoch: 33\tLoss: 0.182980\tTPR: 97.67932489451476\tTNR: 95.62062710546773\tTime: 1.053861\n","Val_loss: 0.262301\tTPR: 86.63793103448276\tTNR: 96.67443064182196\tTime: 10.956140\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 56.02887678146362\n","Train Epoch: 34\tLoss: 0.173410\tTPR: 97.67932489451476\tTNR: 96.00932884166883\tTime: 1.049845\n","Val_loss: 0.256351\tTPR: 86.42241379310344\tTNR: 97.10144927536231\tTime: 10.854541\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 55.76811242103577\n","Train Epoch: 35\tLoss: 0.183853\tTPR: 96.20253164556962\tTNR: 95.95750194350869\tTime: 1.070483\n","Val_loss: 0.258242\tTPR: 85.12931034482759\tTNR: 97.06262939958592\tTime: 10.936273\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 56.065600633621216\n","Train Epoch: 36\tLoss: 0.174802\tTPR: 96.62447257383965\tTNR: 96.3202902306297\tTime: 1.070975\n","Val_loss: 0.261346\tTPR: 86.20689655172413\tTNR: 97.06262939958592\tTime: 11.228351\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 56.61145305633545\n","Train Epoch: 37\tLoss: 0.169215\tTPR: 97.0464135021097\tTNR: 96.26846333246955\tTime: 1.138638\n","Val_loss: 0.271993\tTPR: 85.34482758620689\tTNR: 97.2567287784679\tTime: 10.834023\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 56.0776424407959\n","Train Epoch: 38\tLoss: 0.172440\tTPR: 98.10126582278481\tTNR: 96.04819901528894\tTime: 1.083426\n","Val_loss: 0.282499\tTPR: 84.05172413793103\tTNR: 97.26966873706004\tTime: 10.892625\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 55.858967304229736\n","Train Epoch: 39\tLoss: 0.165789\tTPR: 97.25738396624473\tTNR: 96.60533817051049\tTime: 1.188821\n","Val_loss: 0.265836\tTPR: 88.14655172413794\tTNR: 97.08850931677019\tTime: 11.008298\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 57.13098621368408\n","Train Epoch: 40\tLoss: 0.181804\tTPR: 95.14767932489451\tTNR: 96.43690075149001\tTime: 1.064690\n","Val_loss: 0.245517\tTPR: 86.20689655172413\tTNR: 97.2567287784679\tTime: 11.108321\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 56.13244700431824\n","Train Epoch: 41\tLoss: 0.168332\tTPR: 96.41350210970464\tTNR: 96.59238144597046\tTime: 1.085457\n","Val_loss: 0.250964\tTPR: 87.5\tTNR: 97.28260869565217\tTime: 11.298425\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 56.53715205192566\n","Train Epoch: 42\tLoss: 0.153983\tTPR: 98.73417721518987\tTNR: 96.5016843741902\tTime: 1.096596\n","Val_loss: 0.274300\tTPR: 85.99137931034483\tTNR: 97.32142857142857\tTime: 11.163130\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 57.08771991729736\n","Train Epoch: 43\tLoss: 0.167496\tTPR: 96.83544303797468\tTNR: 96.56646799689038\tTime: 1.062878\n","Val_loss: 0.262923\tTPR: 86.20689655172413\tTNR: 97.4508281573499\tTime: 11.104390\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 56.87234044075012\n","Train Epoch: 44\tLoss: 0.160335\tTPR: 97.0464135021097\tTNR: 96.79968903861104\tTime: 1.049963\n","Val_loss: 0.241221\tTPR: 89.22413793103449\tTNR: 97.16614906832298\tTime: 10.884041\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 56.49325895309448\n","Train Epoch: 45\tLoss: 0.160109\tTPR: 96.62447257383965\tTNR: 96.6442083441306\tTime: 1.049932\n","Val_loss: 0.239304\tTPR: 89.4396551724138\tTNR: 97.23084886128365\tTime: 11.059015\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 256, num_layers=5, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=512, out_features=1, bias=True)\n",")\n","FS-13-WF-256-HS-5-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.080265\tTPR: 99.57805907172997\tTNR: 0.42757190982119725\tTime: 1.198296\n","Val_loss: 0.993956\tTPR: 10.129310344827585\tTNR: 99.61180124223603\tTime: 11.351236\n","\n","Validation loss decreased (inf --> 0.993956).  Saving model\n","\n","Epoch Duration 62.469804525375366\n","Train Epoch: 1\tLoss: 1.011487\tTPR: 9.282700421940929\tTNR: 99.61129826379891\tTime: 1.204423\n","Val_loss: 0.844404\tTPR: 47.8448275862069\tTNR: 97.5284679089027\tTime: 11.827694\n","\n","Validation loss decreased (0.993956 --> 0.844404).  Saving model\n","\n","Epoch Duration 63.89151859283447\n","Train Epoch: 2\tLoss: 0.887573\tTPR: 36.91983122362869\tTNR: 98.34153925887536\tTime: 1.230764\n","Val_loss: 0.580002\tTPR: 60.3448275862069\tTNR: 94.56521739130434\tTime: 11.504369\n","\n","Validation loss decreased (0.844404 --> 0.580002).  Saving model\n","\n","Epoch Duration 62.86255884170532\n","Train Epoch: 3\tLoss: 0.641691\tTPR: 57.59493670886076\tTNR: 95.4651464109873\tTime: 1.236736\n","Val_loss: 0.408950\tTPR: 81.25\tTNR: 90.6444099378882\tTime: 11.553949\n","\n","Validation loss decreased (0.580002 --> 0.408950).  Saving model\n","\n","Epoch Duration 62.99327325820923\n","Train Epoch: 4\tLoss: 0.442626\tTPR: 78.27004219409282\tTNR: 91.9668307851775\tTime: 1.205939\n","Val_loss: 0.334383\tTPR: 94.61206896551724\tTNR: 89.89389233954451\tTime: 11.576128\n","\n","Validation loss decreased (0.408950 --> 0.334383).  Saving model\n","\n","Epoch Duration 63.248114824295044\n","Train Epoch: 5\tLoss: 0.352024\tTPR: 92.40506329113924\tTNR: 91.22829748639543\tTime: 1.224647\n","Val_loss: 0.307404\tTPR: 95.6896551724138\tTNR: 91.11024844720497\tTime: 11.482202\n","\n","Validation loss decreased (0.334383 --> 0.307404).  Saving model\n","\n","Epoch Duration 62.98131990432739\n","Train Epoch: 6\tLoss: 0.321981\tTPR: 92.40506329113924\tTNR: 91.8890904379373\tTime: 1.264249\n","Val_loss: 0.294924\tTPR: 95.90517241379311\tTNR: 91.51138716356108\tTime: 11.600971\n","\n","Validation loss decreased (0.307404 --> 0.294924).  Saving model\n","\n","Epoch Duration 64.27779412269592\n","Train Epoch: 7\tLoss: 0.303151\tTPR: 94.9367088607595\tTNR: 91.73360974345685\tTime: 1.231872\n","Val_loss: 0.276503\tTPR: 96.76724137931035\tTNR: 92.15838509316771\tTime: 11.268488\n","\n","Validation loss decreased (0.294924 --> 0.276503).  Saving model\n","\n","Epoch Duration 62.47907781600952\n","Train Epoch: 8\tLoss: 0.280800\tTPR: 95.14767932489451\tTNR: 92.86084477844001\tTime: 1.211792\n","Val_loss: 0.269862\tTPR: 96.33620689655173\tTNR: 92.52070393374741\tTime: 11.256960\n","\n","Validation loss decreased (0.276503 --> 0.269862).  Saving model\n","\n","Epoch Duration 61.695531606674194\n","Train Epoch: 9\tLoss: 0.267832\tTPR: 95.9915611814346\tTNR: 92.08344130603784\tTime: 1.202106\n","Val_loss: 0.254561\tTPR: 96.76724137931035\tTNR: 93.32298136645963\tTime: 11.312628\n","\n","Validation loss decreased (0.269862 --> 0.254561).  Saving model\n","\n","Epoch Duration 61.78013873100281\n","Train Epoch: 10\tLoss: 0.255513\tTPR: 95.35864978902954\tTNR: 93.3532003109614\tTime: 1.188004\n","Val_loss: 0.255686\tTPR: 94.82758620689656\tTNR: 93.43944099378882\tTime: 11.759547\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 61.97029209136963\n","Train Epoch: 11\tLoss: 0.241460\tTPR: 96.20253164556962\tTNR: 93.50868100544183\tTime: 1.204657\n","Val_loss: 0.242153\tTPR: 95.04310344827587\tTNR: 94.25465838509317\tTime: 11.142131\n","\n","Validation loss decreased (0.254561 --> 0.242153).  Saving model\n","\n","Epoch Duration 61.9778938293457\n","Train Epoch: 12\tLoss: 0.232794\tTPR: 95.9915611814346\tTNR: 94.26017102876393\tTime: 1.209851\n","Val_loss: 0.235708\tTPR: 95.47413793103449\tTNR: 94.46169772256728\tTime: 11.174965\n","\n","Validation loss decreased (0.242153 --> 0.235708).  Saving model\n","\n","Epoch Duration 61.20440220832825\n","Train Epoch: 13\tLoss: 0.230323\tTPR: 94.51476793248945\tTNR: 94.53226224410469\tTime: 1.192594\n","Val_loss: 0.247149\tTPR: 93.75\tTNR: 94.44875776397515\tTime: 11.098469\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 61.14132332801819\n","Train Epoch: 14\tLoss: 0.215066\tTPR: 96.62447257383965\tTNR: 94.66182948950505\tTime: 1.180957\n","Val_loss: 0.240740\tTPR: 93.10344827586206\tTNR: 94.94047619047619\tTime: 11.191760\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 60.976234912872314\n","Train Epoch: 15\tLoss: 0.216351\tTPR: 96.20253164556962\tTNR: 94.68774293858513\tTime: 1.171062\n","Val_loss: 0.232023\tTPR: 94.82758620689656\tTNR: 94.65579710144928\tTime: 11.682664\n","\n","Validation loss decreased (0.235708 --> 0.232023).  Saving model\n","\n","Epoch Duration 62.2183518409729\n","Train Epoch: 16\tLoss: 0.213093\tTPR: 96.83544303797468\tTNR: 94.32495465146411\tTime: 1.200778\n","Val_loss: 0.238959\tTPR: 92.88793103448276\tTNR: 95.2639751552795\tTime: 11.266110\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 62.62800407409668\n","Train Epoch: 17\tLoss: 0.198519\tTPR: 97.0464135021097\tTNR: 94.92096398030579\tTime: 1.188012\n","Val_loss: 0.242233\tTPR: 92.67241379310344\tTNR: 95.04399585921325\tTime: 11.201385\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 61.438539266586304\n","Train Epoch: 18\tLoss: 0.190644\tTPR: 98.10126582278481\tTNR: 94.64887276496502\tTime: 1.193700\n","Val_loss: 0.254019\tTPR: 91.37931034482759\tTNR: 95.66511387163561\tTime: 11.134007\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 61.07618522644043\n","Train Epoch: 19\tLoss: 0.187953\tTPR: 96.62447257383965\tTNR: 95.49105986006737\tTime: 1.179115\n","Val_loss: 0.228623\tTPR: 94.18103448275862\tTNR: 95.21221532091097\tTime: 11.213510\n","\n","Validation loss decreased (0.232023 --> 0.228623).  Saving model\n","\n","Epoch Duration 61.197213649749756\n","Train Epoch: 20\tLoss: 0.196055\tTPR: 97.25738396624473\tTNR: 94.77844001036539\tTime: 1.199546\n","Val_loss: 0.251842\tTPR: 90.73275862068965\tTNR: 95.898033126294\tTime: 11.519873\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 61.69810938835144\n","Train Epoch: 21\tLoss: 0.183140\tTPR: 97.0464135021097\tTNR: 95.77610779994818\tTime: 1.160533\n","Val_loss: 0.239628\tTPR: 92.88793103448276\tTNR: 95.38043478260869\tTime: 11.628734\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 62.080852031707764\n","Train Epoch: 22\tLoss: 0.190409\tTPR: 96.20253164556962\tTNR: 95.54288675822752\tTime: 1.176870\n","Val_loss: 0.237944\tTPR: 92.67241379310344\tTNR: 95.66511387163561\tTime: 11.235802\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 61.367233753204346\n","Train Epoch: 23\tLoss: 0.196302\tTPR: 94.9367088607595\tTNR: 95.27079554288676\tTime: 1.204018\n","Val_loss: 0.220495\tTPR: 93.53448275862068\tTNR: 95.94979296066253\tTime: 11.246991\n","\n","Validation loss decreased (0.228623 --> 0.220495).  Saving model\n","\n","Epoch Duration 61.65308904647827\n","Train Epoch: 24\tLoss: 0.214404\tTPR: 96.41350210970464\tTNR: 95.81497797356829\tTime: 1.183037\n","Val_loss: 0.232173\tTPR: 92.45689655172413\tTNR: 96.11801242236024\tTime: 11.322278\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 62.24623465538025\n","Train Epoch: 25\tLoss: 0.171985\tTPR: 96.83544303797468\tTNR: 95.90567504534853\tTime: 1.211848\n","Val_loss: 0.230315\tTPR: 93.10344827586206\tTNR: 95.75569358178055\tTime: 11.303940\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 62.66590762138367\n","Train Epoch: 26\tLoss: 0.171448\tTPR: 97.67932489451476\tTNR: 95.85384814718839\tTime: 1.204155\n","Val_loss: 0.236613\tTPR: 91.59482758620689\tTNR: 95.88509316770187\tTime: 11.843130\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 63.420297145843506\n","Train Epoch: 27\tLoss: 0.175890\tTPR: 95.35864978902954\tTNR: 96.34620367970977\tTime: 1.211538\n","Val_loss: 0.233407\tTPR: 91.59482758620689\tTNR: 96.57091097308489\tTime: 11.442391\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 62.7431960105896\n","Train Epoch: 28\tLoss: 0.165686\tTPR: 96.83544303797468\tTNR: 96.20367970976937\tTime: 1.206091\n","Val_loss: 0.220517\tTPR: 91.37931034482759\tTNR: 96.58385093167702\tTime: 11.424945\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 62.63813662528992\n","Train Epoch: 29\tLoss: 0.179910\tTPR: 95.78059071729957\tTNR: 96.12593936252915\tTime: 1.211374\n","Val_loss: 0.230559\tTPR: 91.37931034482759\tTNR: 96.35093167701864\tTime: 11.462421\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 62.72946333885193\n","Train Epoch: 30\tLoss: 0.162232\tTPR: 97.0464135021097\tTNR: 96.47577092511013\tTime: 1.199424\n","Val_loss: 0.218363\tTPR: 91.8103448275862\tTNR: 96.70031055900621\tTime: 11.330986\n","\n","Validation loss decreased (0.220495 --> 0.218363).  Saving model\n","\n","Epoch Duration 62.61103630065918\n","Train Epoch: 31\tLoss: 0.153907\tTPR: 97.46835443037975\tTNR: 96.81264576315107\tTime: 1.234479\n","Val_loss: 0.221056\tTPR: 91.37931034482759\tTNR: 96.777950310559\tTime: 11.542244\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 63.29403471946716\n","Train Epoch: 32\tLoss: 0.154100\tTPR: 97.8902953586498\tTNR: 96.5016843741902\tTime: 1.214535\n","Val_loss: 0.219827\tTPR: 93.10344827586206\tTNR: 96.13095238095238\tTime: 11.382672\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 62.49629998207092\n","Train Epoch: 33\tLoss: 0.143667\tTPR: 99.15611814345992\tTNR: 96.30733350608966\tTime: 1.207672\n","Val_loss: 0.204741\tTPR: 93.10344827586206\tTNR: 96.8555900621118\tTime: 11.380929\n","\n","Validation loss decreased (0.218363 --> 0.204741).  Saving model\n","\n","Epoch Duration 62.32010841369629\n","Train Epoch: 34\tLoss: 0.159914\tTPR: 97.0464135021097\tTNR: 96.73490541591086\tTime: 1.201033\n","Val_loss: 0.237457\tTPR: 90.94827586206897\tTNR: 96.99792960662525\tTime: 11.412003\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 62.57150411605835\n","Train Epoch: 35\tLoss: 0.147406\tTPR: 97.67932489451476\tTNR: 96.90334283493132\tTime: 1.212895\n","Val_loss: 0.220625\tTPR: 91.37931034482759\tTNR: 96.68737060041408\tTime: 11.440626\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 62.822672843933105\n","Train Epoch: 36\tLoss: 0.154273\tTPR: 98.10126582278481\tTNR: 96.11298263798912\tTime: 1.210470\n","Val_loss: 0.215054\tTPR: 92.45689655172413\tTNR: 96.79089026915115\tTime: 11.535807\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 63.37918829917908\n","Train Epoch: 37\tLoss: 0.146397\tTPR: 97.67932489451476\tTNR: 97.13656387665198\tTime: 1.224334\n","Val_loss: 0.229887\tTPR: 92.24137931034483\tTNR: 96.9332298136646\tTime: 11.392028\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 62.72103953361511\n","Train Epoch: 38\tLoss: 0.141334\tTPR: 98.73417721518987\tTNR: 96.87742938585126\tTime: 1.220812\n","Val_loss: 0.205938\tTPR: 91.59482758620689\tTNR: 97.2179089026915\tTime: 11.570102\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 62.77007079124451\n","Train Epoch: 39\tLoss: 0.152161\tTPR: 97.25738396624473\tTNR: 96.87742938585126\tTime: 1.211564\n","Val_loss: 0.224751\tTPR: 91.8103448275862\tTNR: 96.99792960662525\tTime: 11.437807\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 62.9122428894043\n","Train Epoch: 40\tLoss: 0.135762\tTPR: 98.31223628691983\tTNR: 97.08473697849183\tTime: 1.203016\n","Val_loss: 0.227515\tTPR: 91.16379310344827\tTNR: 97.15320910973085\tTime: 11.477910\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 62.89114332199097\n","Train Epoch: 41\tLoss: 0.157704\tTPR: 95.35864978902954\tTNR: 96.99403990671158\tTime: 1.212519\n","Val_loss: 0.198793\tTPR: 91.8103448275862\tTNR: 97.42494824016563\tTime: 11.498533\n","\n","Validation loss decreased (0.204741 --> 0.198793).  Saving model\n","\n","Epoch Duration 63.49504804611206\n","Train Epoch: 42\tLoss: 0.141172\tTPR: 97.46835443037975\tTNR: 97.20134749935217\tTime: 1.214906\n","Val_loss: 0.209061\tTPR: 91.8103448275862\tTNR: 97.3343685300207\tTime: 11.449007\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 62.733619689941406\n","Train Epoch: 43\tLoss: 0.134410\tTPR: 97.67932489451476\tTNR: 97.40865509199274\tTime: 1.212592\n","Val_loss: 0.205460\tTPR: 91.8103448275862\tTNR: 97.3343685300207\tTime: 11.395103\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 62.43744707107544\n","Train Epoch: 44\tLoss: 0.132860\tTPR: 97.8902953586498\tTNR: 97.29204457113242\tTime: 1.202703\n","Val_loss: 0.209253\tTPR: 91.8103448275862\tTNR: 97.26966873706004\tTime: 11.381003\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 62.57293510437012\n","Train Epoch: 45\tLoss: 0.130546\tTPR: 98.94514767932489\tTNR: 97.05882352941177\tTime: 1.214748\n","Val_loss: 0.221592\tTPR: 91.16379310344827\tTNR: 97.43788819875776\tTime: 11.441827\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 62.89201807975769\n","Train Epoch: 46\tLoss: 0.157121\tTPR: 95.35864978902954\tTNR: 97.27908784659238\tTime: 1.203972\n","Val_loss: 0.225942\tTPR: 92.45689655172413\tTNR: 97.38612836438924\tTime: 11.464092\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 63.47544026374817\n","Train Epoch: 47\tLoss: 0.139940\tTPR: 97.46835443037975\tTNR: 97.30500129567245\tTime: 1.203102\n","Val_loss: 0.220216\tTPR: 91.37931034482759\tTNR: 97.36024844720497\tTime: 11.460371\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 62.83338403701782\n","Train Epoch: 48\tLoss: 0.141409\tTPR: 97.67932489451476\tTNR: 97.20134749935217\tTime: 1.215118\n","Val_loss: 0.198262\tTPR: 92.88793103448276\tTNR: 97.43788819875776\tTime: 11.525870\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 62.86664581298828\n","Train Epoch: 49\tLoss: 0.141569\tTPR: 97.0464135021097\tTNR: 97.47343871469293\tTime: 1.238036\n","Val_loss: 0.197230\tTPR: 92.67241379310344\tTNR: 97.47670807453416\tTime: 11.497034\n","\n","Validation loss decreased (0.198793 --> 0.197230).  Saving model\n","\n","Epoch Duration 62.91386079788208\n","Train Epoch: 50\tLoss: 0.128443\tTPR: 98.10126582278481\tTNR: 97.51230888831304\tTime: 1.224878\n","Val_loss: 0.201138\tTPR: 93.53448275862068\tTNR: 97.59316770186336\tTime: 11.492155\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 63.280393838882446\n","Train Epoch: 51\tLoss: 0.154980\tTPR: 95.56962025316456\tTNR: 97.3568281938326\tTime: 1.228787\n","Val_loss: 0.205290\tTPR: 92.24137931034483\tTNR: 97.46376811594203\tTime: 11.491823\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 63.828272104263306\n","Train Epoch: 52\tLoss: 0.138354\tTPR: 96.20253164556962\tTNR: 97.499352163773\tTime: 1.240930\n","Val_loss: 0.221149\tTPR: 91.8103448275862\tTNR: 97.58022774327122\tTime: 11.506589\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 63.01430368423462\n","Train Epoch: 53\tLoss: 0.139989\tTPR: 96.62447257383965\tTNR: 97.43456854107282\tTime: 1.223600\n","Val_loss: 0.201212\tTPR: 92.88793103448276\tTNR: 97.58022774327122\tTime: 11.531482\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 63.08781099319458\n","Train Epoch: 54\tLoss: 0.145662\tTPR: 95.9915611814346\tTNR: 97.44752526561285\tTime: 1.223435\n","Val_loss: 0.217475\tTPR: 91.8103448275862\tTNR: 97.55434782608695\tTime: 11.912168\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 63.459861755371094\n","Train Epoch: 55\tLoss: 0.126532\tTPR: 97.8902953586498\tTNR: 97.55117906193314\tTime: 1.208294\n","Val_loss: 0.211414\tTPR: 92.45689655172413\tTNR: 97.4120082815735\tTime: 11.593408\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 63.14638710021973\n","Train Epoch: 56\tLoss: 0.140029\tTPR: 96.83544303797468\tTNR: 97.46048199015289\tTime: 1.210719\n","Val_loss: 0.200639\tTPR: 92.24137931034483\tTNR: 97.68374741200829\tTime: 11.550725\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 63.931121587753296\n","Train Epoch: 57\tLoss: 0.132302\tTPR: 96.62447257383965\tTNR: 97.44752526561285\tTime: 1.226203\n","Val_loss: 0.187940\tTPR: 94.39655172413794\tTNR: 97.42494824016563\tTime: 11.586165\n","\n","Validation loss decreased (0.197230 --> 0.187940).  Saving model\n","\n","Epoch Duration 63.381314277648926\n","Train Epoch: 58\tLoss: 0.143568\tTPR: 96.41350210970464\tTNR: 97.44752526561285\tTime: 1.229759\n","Val_loss: 0.194702\tTPR: 92.88793103448276\tTNR: 97.63198757763976\tTime: 11.579478\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 63.40094208717346\n","Train Epoch: 59\tLoss: 0.140103\tTPR: 95.9915611814346\tTNR: 97.46048199015289\tTime: 1.225335\n","Val_loss: 0.194251\tTPR: 93.75\tTNR: 97.51552795031056\tTime: 11.626899\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 63.6535439491272\n","Train Epoch: 60\tLoss: 0.131182\tTPR: 97.0464135021097\tTNR: 97.70665975641359\tTime: 1.222316\n","Val_loss: 0.208140\tTPR: 92.45689655172413\tTNR: 97.80020703933747\tTime: 11.556252\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 63.265159606933594\n","Train Epoch: 61\tLoss: 0.127084\tTPR: 96.83544303797468\tTNR: 97.69370303187355\tTime: 1.224514\n","Val_loss: 0.191533\tTPR: 93.31896551724138\tTNR: 97.5672877846791\tTime: 11.456366\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 63.92773509025574\n","Train Epoch: 62\tLoss: 0.121568\tTPR: 98.31223628691983\tTNR: 97.70665975641359\tTime: 1.223062\n","Val_loss: 0.190238\tTPR: 93.31896551724138\tTNR: 97.72256728778468\tTime: 11.516172\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 63.13332653045654\n","Train Epoch: 63\tLoss: 0.137561\tTPR: 95.78059071729957\tTNR: 97.7844001036538\tTime: 1.219068\n","Val_loss: 0.197636\tTPR: 93.31896551724138\tTNR: 97.74844720496894\tTime: 11.615490\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 63.52172088623047\n","Train Epoch: 64\tLoss: 0.142201\tTPR: 95.78059071729957\tTNR: 97.51230888831304\tTime: 1.224805\n","Val_loss: 0.202641\tTPR: 92.67241379310344\tTNR: 97.4896480331263\tTime: 11.501814\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 63.57886219024658\n","Train Epoch: 65\tLoss: 0.120056\tTPR: 98.31223628691983\tTNR: 97.87509717543405\tTime: 1.230226\n","Val_loss: 0.196650\tTPR: 93.53448275862068\tTNR: 97.8131469979296\tTime: 11.560484\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 63.23041582107544\n","Train Epoch: 66\tLoss: 0.143029\tTPR: 95.56962025316456\tTNR: 97.51230888831304\tTime: 1.220664\n","Val_loss: 0.180326\tTPR: 94.18103448275862\tTNR: 97.55434782608695\tTime: 11.527409\n","\n","Validation loss decreased (0.187940 --> 0.180326).  Saving model\n","\n","Epoch Duration 63.96084523200989\n","Train Epoch: 67\tLoss: 0.117823\tTPR: 98.73417721518987\tTNR: 97.6418761337134\tTime: 1.232667\n","Val_loss: 0.186893\tTPR: 94.61206896551724\tTNR: 97.72256728778468\tTime: 11.530508\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 62.981855154037476\n","Train Epoch: 68\tLoss: 0.129780\tTPR: 97.8902953586498\tTNR: 97.6418761337134\tTime: 1.227516\n","Val_loss: 0.199971\tTPR: 92.88793103448276\tTNR: 97.61904761904762\tTime: 11.477765\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 62.97346639633179\n","Train Epoch: 69\tLoss: 0.121344\tTPR: 97.46835443037975\tTNR: 97.8232702772739\tTime: 1.237518\n","Val_loss: 0.220276\tTPR: 91.59482758620689\tTNR: 97.68374741200829\tTime: 11.538240\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 63.29353904724121\n","Train Epoch: 70\tLoss: 0.124704\tTPR: 98.10126582278481\tTNR: 97.66778958279347\tTime: 1.203710\n","Val_loss: 0.187141\tTPR: 94.39655172413794\tTNR: 97.72256728778468\tTime: 11.398638\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 62.83473992347717\n","Train Epoch: 71\tLoss: 0.117835\tTPR: 98.52320675105484\tTNR: 97.862140450894\tTime: 1.202394\n","Val_loss: 0.189972\tTPR: 93.96551724137932\tTNR: 97.68374741200829\tTime: 11.414039\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 63.259437084198\n","Train Epoch: 72\tLoss: 0.123627\tTPR: 97.46835443037975\tTNR: 97.83622700181395\tTime: 1.212855\n","Val_loss: 0.180541\tTPR: 94.39655172413794\tTNR: 97.70962732919256\tTime: 11.483425\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 62.68625473976135\n","Train Epoch: 73\tLoss: 0.123788\tTPR: 98.31223628691983\tTNR: 97.65483285825344\tTime: 1.217899\n","Val_loss: 0.183537\tTPR: 93.96551724137932\tTNR: 97.72256728778468\tTime: 11.503997\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 62.92206573486328\n","Train Epoch: 74\tLoss: 0.115541\tTPR: 98.31223628691983\tTNR: 97.9657942472143\tTime: 1.232139\n","Val_loss: 0.190858\tTPR: 93.96551724137932\tTNR: 97.72256728778468\tTime: 11.580618\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 63.32166361808777\n","Train Epoch: 75\tLoss: 0.127870\tTPR: 96.83544303797468\tTNR: 97.75848665457373\tTime: 1.206406\n","Val_loss: 0.173569\tTPR: 93.96551724137932\tTNR: 97.78726708074534\tTime: 11.649529\n","\n","Validation loss decreased (0.180326 --> 0.173569).  Saving model\n","\n","Epoch Duration 63.211763858795166\n","Train Epoch: 76\tLoss: 0.111688\tTPR: 98.52320675105484\tTNR: 98.04353459445451\tTime: 1.324012\n","Val_loss: 0.184271\tTPR: 93.96551724137932\tTNR: 97.82608695652173\tTime: 11.532085\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 63.94085431098938\n","Train Epoch: 77\tLoss: 0.123744\tTPR: 97.46835443037975\tTNR: 97.93988079813423\tTime: 1.222707\n","Val_loss: 0.183757\tTPR: 94.18103448275862\tTNR: 97.65786749482402\tTime: 11.531094\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 62.86868762969971\n","Train Epoch: 78\tLoss: 0.117425\tTPR: 98.10126582278481\tTNR: 97.91396734905416\tTime: 1.223270\n","Val_loss: 0.181367\tTPR: 94.61206896551724\tTNR: 97.72256728778468\tTime: 11.552702\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 63.088597774505615\n","Train Epoch: 79\tLoss: 0.113829\tTPR: 98.73417721518987\tTNR: 98.03057786991448\tTime: 1.213222\n","Val_loss: 0.192789\tTPR: 93.31896551724138\tTNR: 97.73550724637681\tTime: 11.599663\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 63.360109090805054\n","Train Epoch: 80\tLoss: 0.118473\tTPR: 97.46835443037975\tTNR: 97.88805389997408\tTime: 1.235031\n","Val_loss: 0.188496\tTPR: 94.61206896551724\tTNR: 97.70962732919256\tTime: 12.180116\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 63.75923800468445\n","Train Epoch: 81\tLoss: 0.111655\tTPR: 98.94514767932489\tTNR: 97.862140450894\tTime: 1.323291\n","Val_loss: 0.190525\tTPR: 93.96551724137932\tTNR: 97.68374741200829\tTime: 11.565863\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 63.43666076660156\n","Train Epoch: 82\tLoss: 0.120502\tTPR: 98.52320675105484\tTNR: 97.77144337911376\tTime: 1.207487\n","Val_loss: 0.185850\tTPR: 94.18103448275862\tTNR: 97.8131469979296\tTime: 11.534708\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 63.10085344314575\n","Train Epoch: 83\tLoss: 0.123471\tTPR: 97.67932489451476\tTNR: 97.95283752267426\tTime: 1.224100\n","Val_loss: 0.183666\tTPR: 93.53448275862068\tTNR: 97.78726708074534\tTime: 11.918666\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 63.5951452255249\n","Train Epoch: 84\tLoss: 0.115598\tTPR: 97.8902953586498\tTNR: 97.95283752267426\tTime: 1.211811\n","Val_loss: 0.167280\tTPR: 94.39655172413794\tTNR: 97.80020703933747\tTime: 11.523475\n","\n","Validation loss decreased (0.173569 --> 0.167280).  Saving model\n","\n","Epoch Duration 63.18170976638794\n","Train Epoch: 85\tLoss: 0.123663\tTPR: 97.67932489451476\tTNR: 97.81031355273387\tTime: 1.237176\n","Val_loss: 0.213222\tTPR: 92.67241379310344\tTNR: 97.86490683229813\tTime: 12.236299\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 63.9534957408905\n","Train Epoch: 86\tLoss: 0.114133\tTPR: 98.10126582278481\tTNR: 98.16014511531485\tTime: 1.210525\n","Val_loss: 0.176707\tTPR: 93.96551724137932\tTNR: 97.851966873706\tTime: 11.499746\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 63.019118785858154\n","Train Epoch: 87\tLoss: 0.109371\tTPR: 99.15611814345992\tTNR: 98.21197201347499\tTime: 1.210737\n","Val_loss: 0.195070\tTPR: 93.31896551724138\tTNR: 97.95548654244305\tTime: 11.450459\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 63.02129364013672\n","Train Epoch: 88\tLoss: 0.117212\tTPR: 98.10126582278481\tTNR: 97.9657942472143\tTime: 1.212498\n","Val_loss: 0.190763\tTPR: 93.75\tTNR: 97.83902691511386\tTime: 11.480455\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 63.25360131263733\n","Train Epoch: 89\tLoss: 0.115859\tTPR: 97.67932489451476\tTNR: 98.06944804353459\tTime: 1.203332\n","Val_loss: 0.192353\tTPR: 94.39655172413794\tTNR: 97.8131469979296\tTime: 11.449334\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 62.92397618293762\n","Train Epoch: 90\tLoss: 0.130282\tTPR: 95.78059071729957\tTNR: 97.79735682819384\tTime: 1.216910\n","Val_loss: 0.176579\tTPR: 94.39655172413794\tTNR: 97.78726708074534\tTime: 11.780966\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 63.80093717575073\n","Train Epoch: 91\tLoss: 0.106981\tTPR: 99.15611814345992\tTNR: 98.14718839077482\tTime: 1.231204\n","Val_loss: 0.187734\tTPR: 93.53448275862068\tTNR: 97.90372670807453\tTime: 11.504968\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 62.964012145996094\n","Train Epoch: 92\tLoss: 0.111632\tTPR: 98.52320675105484\tTNR: 98.08240476807462\tTime: 1.201759\n","Val_loss: 0.203136\tTPR: 93.53448275862068\tTNR: 97.9684265010352\tTime: 11.508517\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 63.25600743293762\n","Train Epoch: 93\tLoss: 0.121525\tTPR: 97.0464135021097\tTNR: 98.13423166623477\tTime: 1.208156\n","Val_loss: 0.178059\tTPR: 95.04310344827587\tTNR: 97.91666666666666\tTime: 11.525027\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 63.482741832733154\n","Train Epoch: 94\tLoss: 0.114369\tTPR: 98.31223628691983\tTNR: 97.99170769629437\tTime: 1.210057\n","Val_loss: 0.187632\tTPR: 92.88793103448276\tTNR: 98.02018633540372\tTime: 11.456934\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 63.017465591430664\n","Train Epoch: 95\tLoss: 0.108270\tTPR: 98.10126582278481\tTNR: 98.2508421870951\tTime: 1.205259\n","Val_loss: 0.191993\tTPR: 93.96551724137932\tTNR: 98.03312629399586\tTime: 11.525618\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 63.785385847091675\n","Train Epoch: 96\tLoss: 0.110525\tTPR: 98.10126582278481\tTNR: 98.1083182171547\tTime: 1.229472\n","Val_loss: 0.167327\tTPR: 95.25862068965517\tTNR: 98.07194616977226\tTime: 11.480341\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 63.05044436454773\n","Train Epoch: 97\tLoss: 0.106869\tTPR: 98.73417721518987\tTNR: 98.08240476807462\tTime: 1.203043\n","Val_loss: 0.181678\tTPR: 94.39655172413794\tTNR: 97.99430641821945\tTime: 11.444808\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 62.8683557510376\n","Train Epoch: 98\tLoss: 0.109619\tTPR: 97.67932489451476\tTNR: 98.06944804353459\tTime: 1.217903\n","Val_loss: 0.182916\tTPR: 94.39655172413794\tTNR: 98.0072463768116\tTime: 11.559832\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 63.322779417037964\n","Train Epoch: 99\tLoss: 0.104726\tTPR: 98.94514767932489\tTNR: 98.28971236071521\tTime: 1.223094\n","Val_loss: 0.185448\tTPR: 94.61206896551724\tTNR: 97.99430641821945\tTime: 11.446450\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 62.94166874885559\n","Network(\n","  (lstm): LSTM(12, 256, num_layers=10, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=512, out_features=1, bias=True)\n",")\n","FS-13-WF-256-HS-10-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.057597\tTPR: 0.0\tTNR: 100.0\tTime: 1.438122\n","Val_loss: 1.017163\tTPR: 0.0\tTNR: 100.0\tTime: 12.001182\n","\n","Validation loss decreased (inf --> 1.017163).  Saving model\n","\n","Epoch Duration 73.41095161437988\n","Train Epoch: 1\tLoss: 1.027201\tTPR: 0.0\tTNR: 100.0\tTime: 1.421864\n","Val_loss: 0.982893\tTPR: 0.0\tTNR: 100.0\tTime: 11.927656\n","\n","Validation loss decreased (1.017163 --> 0.982893).  Saving model\n","\n","Epoch Duration 72.89117383956909\n","Train Epoch: 2\tLoss: 0.998577\tTPR: 0.0\tTNR: 100.0\tTime: 1.433187\n","Val_loss: 0.654047\tTPR: 36.637931034482754\tTNR: 97.5672877846791\tTime: 12.031768\n","\n","Validation loss decreased (0.982893 --> 0.654047).  Saving model\n","\n","Epoch Duration 73.65174865722656\n","Train Epoch: 3\tLoss: 0.723284\tTPR: 19.198312236286917\tTNR: 99.0671158331174\tTime: 1.444704\n","Val_loss: 0.405032\tTPR: 92.45689655172413\tTNR: 87.90113871635612\tTime: 11.969934\n","\n","Validation loss decreased (0.654047 --> 0.405032).  Saving model\n","\n","Epoch Duration 73.19275665283203\n","Train Epoch: 4\tLoss: 0.430371\tTPR: 90.71729957805907\tTNR: 89.20704845814979\tTime: 1.443078\n","Val_loss: 0.349959\tTPR: 94.82758620689656\tTNR: 89.58333333333334\tTime: 12.018504\n","\n","Validation loss decreased (0.405032 --> 0.349959).  Saving model\n","\n","Epoch Duration 73.95411539077759\n","Train Epoch: 5\tLoss: 0.370919\tTPR: 94.09282700421942\tTNR: 89.7512308888313\tTime: 1.437500\n","Val_loss: 0.339123\tTPR: 92.88793103448276\tTNR: 90.55383022774328\tTime: 11.962564\n","\n","Validation loss decreased (0.349959 --> 0.339123).  Saving model\n","\n","Epoch Duration 72.94822549819946\n","Train Epoch: 6\tLoss: 0.340691\tTPR: 93.88185654008439\tTNR: 90.86550919927441\tTime: 1.428201\n","Val_loss: 0.325802\tTPR: 94.39655172413794\tTNR: 90.98084886128365\tTime: 12.278163\n","\n","Validation loss decreased (0.339123 --> 0.325802).  Saving model\n","\n","Epoch Duration 73.11695456504822\n","Train Epoch: 7\tLoss: 0.316191\tTPR: 95.35864978902954\tTNR: 91.22829748639543\tTime: 1.431265\n","Val_loss: 0.305256\tTPR: 93.75\tTNR: 91.93840579710145\tTime: 11.958345\n","\n","Validation loss decreased (0.325802 --> 0.305256).  Saving model\n","\n","Epoch Duration 72.95441389083862\n","Train Epoch: 8\tLoss: 0.304647\tTPR: 94.51476793248945\tTNR: 91.86317698885722\tTime: 1.446646\n","Val_loss: 0.307446\tTPR: 94.18103448275862\tTNR: 91.92546583850931\tTime: 12.326760\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 73.44513535499573\n","Train Epoch: 9\tLoss: 0.293026\tTPR: 96.20253164556962\tTNR: 91.87613371339725\tTime: 1.515135\n","Val_loss: 0.304359\tTPR: 95.6896551724138\tTNR: 91.3172877846791\tTime: 12.051472\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 73.5011658668518\n","Train Epoch: 10\tLoss: 0.284769\tTPR: 95.9915611814346\tTNR: 92.148224928738\tTime: 1.441664\n","Val_loss: 0.301346\tTPR: 92.88793103448276\tTNR: 92.65010351966873\tTime: 12.050193\n","\n","Validation loss decreased (0.305256 --> 0.301346).  Saving model\n","\n","Epoch Duration 73.24351859092712\n","Train Epoch: 11\tLoss: 0.298263\tTPR: 93.88185654008439\tTNR: 92.93858512568023\tTime: 1.423026\n","Val_loss: 0.298000\tTPR: 94.39655172413794\tTNR: 92.40424430641822\tTime: 12.034341\n","\n","Validation loss decreased (0.301346 --> 0.298000).  Saving model\n","\n","Epoch Duration 73.84968042373657\n","Train Epoch: 12\tLoss: 0.259917\tTPR: 95.56962025316456\tTNR: 92.99041202384038\tTime: 1.418456\n","Val_loss: 0.278089\tTPR: 95.04310344827587\tTNR: 93.09006211180125\tTime: 12.021312\n","\n","Validation loss decreased (0.298000 --> 0.278089).  Saving model\n","\n","Epoch Duration 73.08390259742737\n","Train Epoch: 13\tLoss: 0.244928\tTPR: 97.25738396624473\tTNR: 92.93858512568023\tTime: 1.435184\n","Val_loss: 0.277638\tTPR: 93.96551724137932\tTNR: 93.36180124223603\tTime: 11.975413\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 73.61913299560547\n","Train Epoch: 14\tLoss: 0.249328\tTPR: 95.35864978902954\tTNR: 93.92329619072298\tTime: 1.428332\n","Val_loss: 0.274336\tTPR: 94.61206896551724\tTNR: 93.49120082815735\tTime: 12.082653\n","\n","Validation loss decreased (0.278089 --> 0.274336).  Saving model\n","\n","Epoch Duration 73.14580845832825\n","Train Epoch: 15\tLoss: 0.232253\tTPR: 96.41350210970464\tTNR: 93.76781549624255\tTime: 1.451857\n","Val_loss: 0.267537\tTPR: 93.31896551724138\tTNR: 93.8276397515528\tTime: 12.066727\n","\n","Validation loss decreased (0.274336 --> 0.267537).  Saving model\n","\n","Epoch Duration 73.53087043762207\n","Train Epoch: 16\tLoss: 0.255413\tTPR: 95.35864978902954\tTNR: 93.3920704845815\tTime: 1.444328\n","Val_loss: 0.251764\tTPR: 96.33620689655173\tTNR: 93.37474120082815\tTime: 12.050714\n","\n","Validation loss decreased (0.267537 --> 0.251764).  Saving model\n","\n","Epoch Duration 73.44386076927185\n","Train Epoch: 17\tLoss: 0.237539\tTPR: 95.56962025316456\tTNR: 93.58642135268204\tTime: 1.422976\n","Val_loss: 0.246426\tTPR: 94.61206896551724\tTNR: 94.42287784679088\tTime: 12.050604\n","\n","Validation loss decreased (0.251764 --> 0.246426).  Saving model\n","\n","Epoch Duration 73.96171307563782\n","Train Epoch: 18\tLoss: 0.213147\tTPR: 97.25738396624473\tTNR: 94.16947395698368\tTime: 1.437182\n","Val_loss: 0.261681\tTPR: 94.18103448275862\tTNR: 94.13819875776397\tTime: 12.106565\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 73.21578693389893\n","Train Epoch: 19\tLoss: 0.224876\tTPR: 95.14767932489451\tTNR: 94.49339207048459\tTime: 1.442153\n","Val_loss: 0.239544\tTPR: 93.75\tTNR: 95.2251552795031\tTime: 12.084042\n","\n","Validation loss decreased (0.246426 --> 0.239544).  Saving model\n","\n","Epoch Duration 73.55159091949463\n","Train Epoch: 20\tLoss: 0.208458\tTPR: 95.78059071729957\tTNR: 95.38740606374708\tTime: 1.446214\n","Val_loss: 0.237865\tTPR: 95.6896551724138\tTNR: 94.84989648033127\tTime: 12.067743\n","\n","Validation loss decreased (0.239544 --> 0.237865).  Saving model\n","\n","Epoch Duration 73.29873299598694\n","Train Epoch: 21\tLoss: 0.194456\tTPR: 97.8902953586498\tTNR: 94.94687742938585\tTime: 1.426673\n","Val_loss: 0.242220\tTPR: 93.96551724137932\tTNR: 95.1475155279503\tTime: 12.027783\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 73.58609366416931\n","Train Epoch: 22\tLoss: 0.190022\tTPR: 97.25738396624473\tTNR: 95.25783881834671\tTime: 1.461396\n","Val_loss: 0.216270\tTPR: 95.25862068965517\tTNR: 95.43219461697723\tTime: 12.085948\n","\n","Validation loss decreased (0.237865 --> 0.216270).  Saving model\n","\n","Epoch Duration 73.2318902015686\n","Train Epoch: 23\tLoss: 0.193280\tTPR: 96.20253164556962\tTNR: 95.78906452448821\tTime: 1.441622\n","Val_loss: 0.226954\tTPR: 95.25862068965517\tTNR: 95.50983436853002\tTime: 12.058751\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 73.5767560005188\n","Train Epoch: 24\tLoss: 0.187155\tTPR: 96.20253164556962\tTNR: 95.59471365638767\tTime: 1.425328\n","Val_loss: 0.228657\tTPR: 94.82758620689656\tTNR: 96.02743271221532\tTime: 12.041577\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 73.04955244064331\n","Train Epoch: 25\tLoss: 0.201338\tTPR: 95.56962025316456\tTNR: 96.00932884166883\tTime: 1.414456\n","Val_loss: 0.213426\tTPR: 95.04310344827587\tTNR: 95.7815734989648\tTime: 12.794010\n","\n","Validation loss decreased (0.216270 --> 0.213426).  Saving model\n","\n","Epoch Duration 73.98845553398132\n","Train Epoch: 26\tLoss: 0.180139\tTPR: 95.9915611814346\tTNR: 95.95750194350869\tTime: 1.472536\n","Val_loss: 0.207638\tTPR: 95.47413793103449\tTNR: 95.92391304347827\tTime: 12.145713\n","\n","Validation loss decreased (0.213426 --> 0.207638).  Saving model\n","\n","Epoch Duration 73.49570798873901\n","Train Epoch: 27\tLoss: 0.185435\tTPR: 95.56962025316456\tTNR: 95.86680487172843\tTime: 1.456788\n","Val_loss: 0.214509\tTPR: 93.53448275862068\tTNR: 96.15683229813664\tTime: 12.054523\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 73.44817805290222\n","Train Epoch: 28\tLoss: 0.166259\tTPR: 97.46835443037975\tTNR: 96.22959315884944\tTime: 1.446423\n","Val_loss: 0.200430\tTPR: 94.82758620689656\tTNR: 96.31211180124224\tTime: 12.113973\n","\n","Validation loss decreased (0.207638 --> 0.200430).  Saving model\n","\n","Epoch Duration 73.34217596054077\n","Train Epoch: 29\tLoss: 0.163768\tTPR: 96.62447257383965\tTNR: 96.2814200570096\tTime: 1.447248\n","Val_loss: 0.180909\tTPR: 95.90517241379311\tTNR: 96.28623188405797\tTime: 12.092896\n","\n","Validation loss decreased (0.200430 --> 0.180909).  Saving model\n","\n","Epoch Duration 73.53087329864502\n","Train Epoch: 30\tLoss: 0.170533\tTPR: 97.0464135021097\tTNR: 96.20367970976937\tTime: 1.468374\n","Val_loss: 0.204789\tTPR: 93.53448275862068\tTNR: 96.38975155279503\tTime: 12.157906\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 73.96021819114685\n","Train Epoch: 31\tLoss: 0.149684\tTPR: 98.52320675105484\tTNR: 96.60533817051049\tTime: 1.430454\n","Val_loss: 0.208144\tTPR: 93.53448275862068\tTNR: 96.44151138716356\tTime: 12.331234\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 73.43397283554077\n","Train Epoch: 32\tLoss: 0.158130\tTPR: 97.8902953586498\tTNR: 96.34620367970977\tTime: 1.450860\n","Val_loss: 0.186331\tTPR: 94.18103448275862\tTNR: 96.71325051759835\tTime: 12.140494\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 73.36495995521545\n","Train Epoch: 33\tLoss: 0.165170\tTPR: 96.83544303797468\tTNR: 96.3591604042498\tTime: 1.438347\n","Val_loss: 0.190999\tTPR: 94.82758620689656\tTNR: 96.23447204968944\tTime: 12.018690\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 72.80416822433472\n","Train Epoch: 34\tLoss: 0.148736\tTPR: 97.8902953586498\tTNR: 96.52759782327027\tTime: 1.421385\n","Val_loss: 0.175939\tTPR: 95.25862068965517\tTNR: 96.60973084886129\tTime: 11.984813\n","\n","Validation loss decreased (0.180909 --> 0.175939).  Saving model\n","\n","Epoch Duration 73.59948086738586\n","Train Epoch: 35\tLoss: 0.156638\tTPR: 97.0464135021097\tTNR: 96.60533817051049\tTime: 1.446067\n","Val_loss: 0.220401\tTPR: 92.67241379310344\tTNR: 96.76501035196688\tTime: 11.982929\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 73.00456380844116\n","Train Epoch: 36\tLoss: 0.152974\tTPR: 97.8902953586498\tTNR: 96.6442083441306\tTime: 1.420624\n","Val_loss: 0.196952\tTPR: 93.96551724137932\tTNR: 96.5320910973085\tTime: 12.035622\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 72.9988317489624\n","Train Epoch: 37\tLoss: 0.168198\tTPR: 95.35864978902954\tTNR: 96.48872764965016\tTime: 1.439735\n","Val_loss: 0.187125\tTPR: 93.96551724137932\tTNR: 97.02380952380952\tTime: 12.105711\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 72.91340231895447\n","Train Epoch: 38\tLoss: 0.154849\tTPR: 96.41350210970464\tTNR: 97.03291008033169\tTime: 1.426150\n","Val_loss: 0.193967\tTPR: 93.53448275862068\tTNR: 96.8944099378882\tTime: 11.987477\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 73.31718301773071\n","Train Epoch: 39\tLoss: 0.159625\tTPR: 95.56962025316456\tTNR: 97.00699663125162\tTime: 1.434667\n","Val_loss: 0.224122\tTPR: 92.67241379310344\tTNR: 96.55797101449275\tTime: 12.057088\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 73.03707385063171\n","Train Epoch: 40\tLoss: 0.147653\tTPR: 95.9915611814346\tTNR: 97.01995335579166\tTime: 1.421779\n","Val_loss: 0.204332\tTPR: 92.45689655172413\tTNR: 96.84265010351967\tTime: 12.013552\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 73.07089114189148\n","Train Epoch: 41\tLoss: 0.137701\tTPR: 98.10126582278481\tTNR: 97.04586680487172\tTime: 1.440373\n","Val_loss: 0.213785\tTPR: 93.75\tTNR: 97.07556935817804\tTime: 12.033423\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 72.63356947898865\n","Train Epoch: 42\tLoss: 0.146753\tTPR: 97.0464135021097\tTNR: 96.94221300855143\tTime: 1.433260\n","Val_loss: 0.221563\tTPR: 92.02586206896551\tTNR: 97.08850931677019\tTime: 12.949409\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 73.7534568309784\n","Train Epoch: 43\tLoss: 0.129567\tTPR: 98.52320675105484\tTNR: 97.2143042238922\tTime: 1.430803\n","Val_loss: 0.168625\tTPR: 93.96551724137932\tTNR: 97.3343685300207\tTime: 12.029902\n","\n","Validation loss decreased (0.175939 --> 0.168625).  Saving model\n","\n","Epoch Duration 72.99407863616943\n","Train Epoch: 44\tLoss: 0.137173\tTPR: 97.8902953586498\tTNR: 97.18839077481213\tTime: 1.441142\n","Val_loss: 0.198682\tTPR: 93.31896551724138\tTNR: 96.972049689441\tTime: 12.042104\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 73.24206209182739\n","Train Epoch: 45\tLoss: 0.135970\tTPR: 98.52320675105484\tTNR: 96.91629955947137\tTime: 1.432774\n","Val_loss: 0.212991\tTPR: 93.53448275862068\tTNR: 97.36024844720497\tTime: 12.063470\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 72.64403772354126\n","Train Epoch: 46\tLoss: 0.147365\tTPR: 96.83544303797468\tTNR: 97.26613112205234\tTime: 1.443994\n","Val_loss: 0.167330\tTPR: 95.6896551724138\tTNR: 97.14026915113871\tTime: 11.934031\n","\n","Validation loss decreased (0.168625 --> 0.167330).  Saving model\n","\n","Epoch Duration 72.69916343688965\n","Train Epoch: 47\tLoss: 0.131847\tTPR: 98.10126582278481\tTNR: 97.2143042238922\tTime: 1.468574\n","Val_loss: 0.190568\tTPR: 93.96551724137932\tTNR: 97.14026915113871\tTime: 12.016813\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 73.86954855918884\n","Train Epoch: 48\tLoss: 0.148573\tTPR: 96.83544303797468\tTNR: 97.08473697849183\tTime: 1.430788\n","Val_loss: 0.172139\tTPR: 94.39655172413794\tTNR: 97.07556935817804\tTime: 12.041165\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 72.86188459396362\n","Train Epoch: 49\tLoss: 0.129750\tTPR: 98.10126582278481\tTNR: 97.33091474475253\tTime: 1.430357\n","Val_loss: 0.195579\tTPR: 94.39655172413794\tTNR: 97.3343685300207\tTime: 12.036508\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 72.70255184173584\n","Train Epoch: 50\tLoss: 0.136307\tTPR: 97.0464135021097\tTNR: 97.48639543923296\tTime: 1.431426\n","Val_loss: 0.180431\tTPR: 94.82758620689656\tTNR: 97.2955486542443\tTime: 11.987038\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 72.69908213615417\n","Train Epoch: 51\tLoss: 0.139197\tTPR: 96.41350210970464\tTNR: 97.34387146929257\tTime: 1.409263\n","Val_loss: 0.191867\tTPR: 94.18103448275862\tTNR: 97.34730848861284\tTime: 12.021547\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 73.36677956581116\n","Train Epoch: 52\tLoss: 0.132358\tTPR: 97.67932489451476\tTNR: 97.33091474475253\tTime: 1.439323\n","Val_loss: 0.189343\tTPR: 94.39655172413794\tTNR: 97.16614906832298\tTime: 11.983960\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 73.01245880126953\n","Train Epoch: 53\tLoss: 0.135252\tTPR: 97.67932489451476\tTNR: 97.24021767297228\tTime: 1.414962\n","Val_loss: 0.191352\tTPR: 94.39655172413794\tTNR: 97.42494824016563\tTime: 12.033845\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 72.82281470298767\n","Train Epoch: 54\tLoss: 0.143048\tTPR: 96.83544303797468\tTNR: 97.39569836745271\tTime: 1.435496\n","Val_loss: 0.190368\tTPR: 94.39655172413794\tTNR: 97.39906832298136\tTime: 12.073092\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 72.68877029418945\n","Train Epoch: 55\tLoss: 0.131345\tTPR: 97.8902953586498\tTNR: 97.59004923555325\tTime: 1.393303\n","Val_loss: 0.198194\tTPR: 94.61206896551724\tTNR: 97.4120082815735\tTime: 11.988934\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 73.2471125125885\n","Train Epoch: 56\tLoss: 0.141006\tTPR: 95.9915611814346\tTNR: 97.499352163773\tTime: 1.434311\n","Val_loss: 0.189383\tTPR: 94.82758620689656\tTNR: 97.15320910973085\tTime: 12.321137\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 73.03977727890015\n","Train Epoch: 57\tLoss: 0.123984\tTPR: 98.73417721518987\tTNR: 97.39569836745271\tTime: 1.475396\n","Val_loss: 0.193565\tTPR: 94.82758620689656\tTNR: 97.4896480331263\tTime: 12.021675\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 72.77987384796143\n","Train Epoch: 58\tLoss: 0.136469\tTPR: 96.83544303797468\tTNR: 97.3568281938326\tTime: 1.422244\n","Val_loss: 0.203343\tTPR: 92.88793103448276\tTNR: 97.36024844720497\tTime: 12.038464\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 72.88173341751099\n","Train Epoch: 59\tLoss: 0.140942\tTPR: 97.0464135021097\tTNR: 97.2143042238922\tTime: 1.412101\n","Val_loss: 0.196763\tTPR: 93.96551724137932\tTNR: 97.59316770186336\tTime: 12.745745\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 73.49967646598816\n","Train Epoch: 60\tLoss: 0.126522\tTPR: 98.73417721518987\tTNR: 97.47343871469293\tTime: 1.441090\n","Val_loss: 0.195933\tTPR: 94.39655172413794\tTNR: 97.46376811594203\tTime: 11.967451\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 72.80535697937012\n","Train Epoch: 61\tLoss: 0.132514\tTPR: 98.31223628691983\tTNR: 97.48639543923296\tTime: 1.428815\n","Val_loss: 0.190034\tTPR: 94.61206896551724\tTNR: 97.50258799171843\tTime: 12.044134\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 73.06990718841553\n","Train Epoch: 62\tLoss: 0.126076\tTPR: 97.46835443037975\tTNR: 97.7455299300337\tTime: 1.418867\n","Val_loss: 0.207047\tTPR: 93.96551724137932\tTNR: 97.5284679089027\tTime: 11.950951\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 72.79944014549255\n","Train Epoch: 63\tLoss: 0.122787\tTPR: 98.52320675105484\tTNR: 97.56413578647319\tTime: 1.438467\n","Val_loss: 0.201002\tTPR: 94.39655172413794\tTNR: 97.58022774327122\tTime: 11.970417\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 72.79320430755615\n","Train Epoch: 64\tLoss: 0.130381\tTPR: 97.46835443037975\tTNR: 97.66778958279347\tTime: 1.412439\n","Val_loss: 0.213461\tTPR: 93.53448275862068\tTNR: 97.63198757763976\tTime: 12.106492\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 73.56402349472046\n","Train Epoch: 65\tLoss: 0.124184\tTPR: 97.25738396624473\tTNR: 97.68074630733351\tTime: 1.428738\n","Val_loss: 0.199342\tTPR: 93.96551724137932\tTNR: 97.63198757763976\tTime: 12.047224\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 73.05328726768494\n","Train Epoch: 66\tLoss: 0.131191\tTPR: 97.46835443037975\tTNR: 97.65483285825344\tTime: 1.425128\n","Val_loss: 0.208067\tTPR: 93.53448275862068\tTNR: 97.69668737060042\tTime: 12.107860\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=1024, out_features=1, bias=True)\n",")\n","FS-13-WF-512-HS-2-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.126104\tTPR: 68.35443037974683\tTNR: 25.498833894791396\tTime: 1.141292\n","Val_loss: 0.660318\tTPR: 65.51724137931035\tTNR: 94.91459627329193\tTime: 11.519185\n","\n","Validation loss decreased (inf --> 0.660318).  Saving model\n","\n","Epoch Duration 60.38412356376648\n","Train Epoch: 1\tLoss: 0.705893\tTPR: 66.24472573839662\tTNR: 94.76548328582535\tTime: 1.140050\n","Val_loss: 0.486836\tTPR: 77.15517241379311\tTNR: 94.50051759834368\tTime: 11.491378\n","\n","Validation loss decreased (0.660318 --> 0.486836).  Saving model\n","\n","Epoch Duration 61.43203520774841\n","Train Epoch: 2\tLoss: 0.540149\tTPR: 75.52742616033755\tTNR: 94.22130085514382\tTime: 1.158501\n","Val_loss: 0.391967\tTPR: 94.39655172413794\tTNR: 91.6796066252588\tTime: 11.475621\n","\n","Validation loss decreased (0.486836 --> 0.391967).  Saving model\n","\n","Epoch Duration 60.66302537918091\n","Train Epoch: 3\tLoss: 0.437788\tTPR: 84.59915611814345\tTNR: 92.91267167660016\tTime: 1.234128\n","Val_loss: 0.333656\tTPR: 94.18103448275862\tTNR: 91.17494824016563\tTime: 11.462423\n","\n","Validation loss decreased (0.391967 --> 0.333656).  Saving model\n","\n","Epoch Duration 60.81124496459961\n","Train Epoch: 4\tLoss: 0.370135\tTPR: 90.71729957805907\tTNR: 92.36848924591862\tTime: 1.168962\n","Val_loss: 0.299660\tTPR: 94.61206896551724\tTNR: 91.65372670807453\tTime: 11.226081\n","\n","Validation loss decreased (0.333656 --> 0.299660).  Saving model\n","\n","Epoch Duration 60.04298186302185\n","Train Epoch: 5\tLoss: 0.322545\tTPR: 94.72573839662446\tTNR: 92.3944026949987\tTime: 1.144419\n","Val_loss: 0.277777\tTPR: 94.82758620689656\tTNR: 92.09368530020704\tTime: 11.179871\n","\n","Validation loss decreased (0.299660 --> 0.277777).  Saving model\n","\n","Epoch Duration 59.072893142700195\n","Train Epoch: 6\tLoss: 0.286679\tTPR: 96.41350210970464\tTNR: 92.56284011401917\tTime: 1.122020\n","Val_loss: 0.261036\tTPR: 94.82758620689656\tTNR: 92.72774327122153\tTime: 11.985541\n","\n","Validation loss decreased (0.277777 --> 0.261036).  Saving model\n","\n","Epoch Duration 59.7332718372345\n","Train Epoch: 7\tLoss: 0.269250\tTPR: 97.0464135021097\tTNR: 93.15884944286084\tTime: 1.143749\n","Val_loss: 0.248088\tTPR: 94.61206896551724\tTNR: 93.20652173913044\tTime: 11.090395\n","\n","Validation loss decreased (0.261036 --> 0.248088).  Saving model\n","\n","Epoch Duration 58.678088665008545\n","Train Epoch: 8\tLoss: 0.254058\tTPR: 95.14767932489451\tTNR: 93.70303187354236\tTime: 1.127998\n","Val_loss: 0.240003\tTPR: 94.82758620689656\tTNR: 93.50414078674947\tTime: 11.065771\n","\n","Validation loss decreased (0.248088 --> 0.240003).  Saving model\n","\n","Epoch Duration 58.979676246643066\n","Train Epoch: 9\tLoss: 0.233406\tTPR: 96.62447257383965\tTNR: 93.69007514900233\tTime: 1.133842\n","Val_loss: 0.234089\tTPR: 94.82758620689656\tTNR: 94.20289855072464\tTime: 11.022580\n","\n","Validation loss decreased (0.240003 --> 0.234089).  Saving model\n","\n","Epoch Duration 58.2383873462677\n","Train Epoch: 10\tLoss: 0.233229\tTPR: 94.9367088607595\tTNR: 94.40269499870433\tTime: 1.114465\n","Val_loss: 0.223143\tTPR: 94.18103448275862\tTNR: 94.81107660455487\tTime: 10.953897\n","\n","Validation loss decreased (0.234089 --> 0.223143).  Saving model\n","\n","Epoch Duration 58.2404625415802\n","Train Epoch: 11\tLoss: 0.210330\tTPR: 97.46835443037975\tTNR: 94.58408914226484\tTime: 1.127277\n","Val_loss: 0.222449\tTPR: 93.96551724137932\tTNR: 95.03105590062113\tTime: 11.094558\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 58.10129737854004\n","Train Epoch: 12\tLoss: 0.206411\tTPR: 96.62447257383965\tTNR: 95.0375745011661\tTime: 1.126450\n","Val_loss: 0.222599\tTPR: 92.45689655172413\tTNR: 95.53571428571429\tTime: 10.974933\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 58.788360834121704\n","Train Epoch: 13\tLoss: 0.198143\tTPR: 97.0464135021097\tTNR: 95.20601192018657\tTime: 1.113893\n","Val_loss: 0.222132\tTPR: 90.94827586206897\tTNR: 95.62629399585921\tTime: 10.882102\n","\n","Validation loss decreased (0.223143 --> 0.222132).  Saving model\n","\n","Epoch Duration 58.096699953079224\n","Train Epoch: 14\tLoss: 0.195027\tTPR: 97.25738396624473\tTNR: 95.28375226742679\tTime: 1.106665\n","Val_loss: 0.229144\tTPR: 90.08620689655173\tTNR: 95.96273291925466\tTime: 11.031558\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 58.00586223602295\n","Train Epoch: 15\tLoss: 0.190318\tTPR: 96.83544303797468\tTNR: 95.52993003368748\tTime: 1.089668\n","Val_loss: 0.231292\tTPR: 89.87068965517241\tTNR: 96.14389233954451\tTime: 10.975017\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 57.63436770439148\n","Train Epoch: 16\tLoss: 0.179630\tTPR: 97.46835443037975\tTNR: 95.86680487172843\tTime: 1.109126\n","Val_loss: 0.234731\tTPR: 87.71551724137932\tTNR: 96.67443064182196\tTime: 10.988534\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 57.52300310134888\n","Train Epoch: 17\tLoss: 0.178246\tTPR: 97.0464135021097\tTNR: 95.86680487172843\tTime: 1.100026\n","Val_loss: 0.227906\tTPR: 89.65517241379311\tTNR: 96.4544513457557\tTime: 10.990568\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 58.53947567939758\n","Train Epoch: 18\tLoss: 0.174914\tTPR: 96.62447257383965\tTNR: 96.30733350608966\tTime: 1.104581\n","Val_loss: 0.241945\tTPR: 87.71551724137932\tTNR: 96.8944099378882\tTime: 10.982899\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 58.0323760509491\n","Train Epoch: 19\tLoss: 0.187834\tTPR: 94.09282700421942\tTNR: 96.1388960870692\tTime: 1.101358\n","Val_loss: 0.268858\tTPR: 86.42241379310344\tTNR: 97.19202898550725\tTime: 10.992919\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 57.72059631347656\n","Train Epoch: 20\tLoss: 0.162937\tTPR: 98.10126582278481\tTNR: 96.34620367970977\tTime: 1.102877\n","Val_loss: 0.215729\tTPR: 90.94827586206897\tTNR: 96.972049689441\tTime: 10.874371\n","\n","Validation loss decreased (0.222132 --> 0.215729).  Saving model\n","\n","Epoch Duration 57.967962980270386\n","Train Epoch: 21\tLoss: 0.164747\tTPR: 97.8902953586498\tTNR: 96.22959315884944\tTime: 1.116672\n","Val_loss: 0.265998\tTPR: 87.5\tTNR: 96.64855072463769\tTime: 10.917351\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 57.71849751472473\n","Train Epoch: 22\tLoss: 0.163011\tTPR: 95.9915611814346\tTNR: 96.6442083441306\tTime: 1.095257\n","Val_loss: 0.234886\tTPR: 89.22413793103449\tTNR: 97.14026915113871\tTime: 11.755423\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 58.539292335510254\n","Train Epoch: 23\tLoss: 0.165997\tTPR: 95.78059071729957\tTNR: 96.82560248769111\tTime: 1.104725\n","Val_loss: 0.252798\tTPR: 89.00862068965517\tTNR: 97.14026915113871\tTime: 11.288400\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 58.02437877655029\n","Train Epoch: 24\tLoss: 0.157941\tTPR: 96.62447257383965\tTNR: 96.85151593677118\tTime: 1.122516\n","Val_loss: 0.226745\tTPR: 89.4396551724138\tTNR: 97.19202898550725\tTime: 10.965766\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 57.694010734558105\n","Train Epoch: 25\tLoss: 0.158832\tTPR: 96.83544303797468\tTNR: 96.98108318217155\tTime: 1.104550\n","Val_loss: 0.218942\tTPR: 90.08620689655173\tTNR: 97.32142857142857\tTime: 10.917650\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 57.411866903305054\n","Train Epoch: 26\tLoss: 0.149608\tTPR: 97.46835443037975\tTNR: 96.96812645763151\tTime: 1.090131\n","Val_loss: 0.230977\tTPR: 89.65517241379311\tTNR: 96.95910973084885\tTime: 10.977892\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 57.3341760635376\n","Train Epoch: 27\tLoss: 0.147500\tTPR: 97.46835443037975\tTNR: 96.72194869137081\tTime: 1.107458\n","Val_loss: 0.236997\tTPR: 88.79310344827587\tTNR: 97.32142857142857\tTime: 10.910385\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 57.449045181274414\n","Train Epoch: 28\tLoss: 0.148770\tTPR: 97.0464135021097\tTNR: 96.90334283493132\tTime: 1.090206\n","Val_loss: 0.197193\tTPR: 93.96551724137932\tTNR: 97.06262939958592\tTime: 10.867163\n","\n","Validation loss decreased (0.215729 --> 0.197193).  Saving model\n","\n","Epoch Duration 58.09364438056946\n","Train Epoch: 29\tLoss: 0.145431\tTPR: 98.10126582278481\tTNR: 96.94221300855143\tTime: 1.101001\n","Val_loss: 0.226237\tTPR: 89.00862068965517\tTNR: 97.36024844720497\tTime: 10.850826\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 58.15174698829651\n","Train Epoch: 30\tLoss: 0.138678\tTPR: 97.8902953586498\tTNR: 97.22726094843223\tTime: 1.090166\n","Val_loss: 0.216397\tTPR: 91.8103448275862\tTNR: 97.24378881987577\tTime: 10.870974\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 57.29725480079651\n","Train Epoch: 31\tLoss: 0.147298\tTPR: 97.46835443037975\tTNR: 96.98108318217155\tTime: 1.111547\n","Val_loss: 0.217882\tTPR: 89.65517241379311\tTNR: 97.38612836438924\tTime: 10.882728\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 57.39517140388489\n","Train Epoch: 32\tLoss: 0.140774\tTPR: 98.52320675105484\tTNR: 97.16247732573206\tTime: 1.109496\n","Val_loss: 0.226373\tTPR: 88.57758620689656\tTNR: 97.3343685300207\tTime: 10.911846\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 57.59632611274719\n","Train Epoch: 33\tLoss: 0.138792\tTPR: 96.62447257383965\tTNR: 97.36978491837263\tTime: 1.094891\n","Val_loss: 0.221153\tTPR: 90.30172413793103\tTNR: 97.50258799171843\tTime: 10.908855\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 58.43600869178772\n","Train Epoch: 34\tLoss: 0.137976\tTPR: 98.10126582278481\tTNR: 97.31795802021249\tTime: 1.104688\n","Val_loss: 0.224023\tTPR: 90.08620689655173\tTNR: 97.47670807453416\tTime: 11.028836\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 58.074036836624146\n","Train Epoch: 35\tLoss: 0.132524\tTPR: 97.8902953586498\tTNR: 97.42161181653279\tTime: 1.099533\n","Val_loss: 0.271781\tTPR: 88.14655172413794\tTNR: 97.37318840579711\tTime: 10.982514\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 58.07942581176758\n","Train Epoch: 36\tLoss: 0.141677\tTPR: 96.62447257383965\tTNR: 97.53822233739311\tTime: 1.101433\n","Val_loss: 0.235931\tTPR: 88.14655172413794\tTNR: 97.73550724637681\tTime: 11.006273\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 57.734046459198\n","Train Epoch: 37\tLoss: 0.128867\tTPR: 97.25738396624473\tTNR: 97.44752526561285\tTime: 1.093005\n","Val_loss: 0.247548\tTPR: 87.71551724137932\tTNR: 97.51552795031056\tTime: 10.944050\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 57.65286135673523\n","Train Epoch: 38\tLoss: 0.134847\tTPR: 97.46835443037975\tTNR: 97.40865509199274\tTime: 1.094972\n","Val_loss: 0.232796\tTPR: 89.00862068965517\tTNR: 97.60610766045549\tTime: 11.084286\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 57.83012914657593\n","Train Epoch: 39\tLoss: 0.126004\tTPR: 99.57805907172997\tTNR: 97.53822233739311\tTime: 1.165843\n","Val_loss: 0.204600\tTPR: 92.67241379310344\tTNR: 97.59316770186336\tTime: 11.028660\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 58.39916396141052\n","Train Epoch: 40\tLoss: 0.127900\tTPR: 99.36708860759494\tTNR: 97.30500129567245\tTime: 1.090641\n","Val_loss: 0.251553\tTPR: 89.4396551724138\tTNR: 97.54140786749483\tTime: 10.954084\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 57.55774712562561\n","Train Epoch: 41\tLoss: 0.128195\tTPR: 98.73417721518987\tTNR: 97.51230888831304\tTime: 1.086083\n","Val_loss: 0.260565\tTPR: 87.93103448275862\tTNR: 97.851966873706\tTime: 11.020792\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 57.656782150268555\n","Train Epoch: 42\tLoss: 0.133769\tTPR: 97.67932489451476\tTNR: 97.53822233739311\tTime: 1.109214\n","Val_loss: 0.251994\tTPR: 89.00862068965517\tTNR: 97.70962732919256\tTime: 10.933306\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 57.531060457229614\n","Train Epoch: 43\tLoss: 0.141211\tTPR: 97.0464135021097\tTNR: 97.59004923555325\tTime: 1.099872\n","Val_loss: 0.276008\tTPR: 86.63793103448276\tTNR: 97.78726708074534\tTime: 10.969458\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 57.800461530685425\n","Train Epoch: 44\tLoss: 0.127941\tTPR: 97.46835443037975\tTNR: 97.79735682819384\tTime: 1.099066\n","Val_loss: 0.196892\tTPR: 92.24137931034483\tTNR: 97.54140786749483\tTime: 10.991276\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 58.44183301925659\n","Train Epoch: 45\tLoss: 0.129581\tTPR: 98.10126582278481\tTNR: 97.47343871469293\tTime: 1.106105\n","Val_loss: 0.216719\tTPR: 90.94827586206897\tTNR: 97.50258799171843\tTime: 10.905581\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 57.997583627700806\n","Train Epoch: 46\tLoss: 0.122118\tTPR: 98.73417721518987\tTNR: 97.7455299300337\tTime: 1.103000\n","Val_loss: 0.230792\tTPR: 89.4396551724138\tTNR: 97.5284679089027\tTime: 11.016989\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 57.74043083190918\n","Train Epoch: 47\tLoss: 0.130415\tTPR: 97.46835443037975\tTNR: 97.61596268463333\tTime: 1.106668\n","Val_loss: 0.263415\tTPR: 87.71551724137932\tTNR: 97.63198757763976\tTime: 10.973441\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 57.7604763507843\n","Train Epoch: 48\tLoss: 0.132894\tTPR: 97.46835443037975\tTNR: 97.52526561285308\tTime: 1.101450\n","Val_loss: 0.239162\tTPR: 87.71551724137932\tTNR: 97.76138716356108\tTime: 10.912569\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 512, num_layers=5, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=1024, out_features=1, bias=True)\n",")\n","FS-13-WF-512-HS-5-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.069752\tTPR: 39.24050632911392\tTNR: 51.10132158590308\tTime: 1.348015\n","Val_loss: 0.811624\tTPR: 51.724137931034484\tTNR: 96.79089026915115\tTime: 11.522947\n","\n","Validation loss decreased (inf --> 0.811624).  Saving model\n","\n","Epoch Duration 69.59292674064636\n","Train Epoch: 1\tLoss: 0.857825\tTPR: 42.82700421940928\tTNR: 98.08240476807462\tTime: 1.355240\n","Val_loss: 0.414304\tTPR: 84.69827586206897\tTNR: 91.07142857142857\tTime: 11.504425\n","\n","Validation loss decreased (0.811624 --> 0.414304).  Saving model\n","\n","Epoch Duration 69.51773023605347\n","Train Epoch: 2\tLoss: 0.450897\tTPR: 78.69198312236287\tTNR: 91.99274423425759\tTime: 1.363414\n","Val_loss: 0.299410\tTPR: 95.6896551724138\tTNR: 91.22670807453416\tTime: 11.448186\n","\n","Validation loss decreased (0.414304 --> 0.299410).  Saving model\n","\n","Epoch Duration 69.15550112724304\n","Train Epoch: 3\tLoss: 0.317430\tTPR: 94.51476793248945\tTNR: 91.2153407618554\tTime: 1.374786\n","Val_loss: 0.276873\tTPR: 95.25862068965517\tTNR: 91.97722567287785\tTime: 11.463435\n","\n","Validation loss decreased (0.299410 --> 0.276873).  Saving model\n","\n","Epoch Duration 69.20321249961853\n","Train Epoch: 4\tLoss: 0.276694\tTPR: 95.56962025316456\tTNR: 92.35553252137859\tTime: 1.376857\n","Val_loss: 0.256336\tTPR: 95.25862068965517\tTNR: 93.32298136645963\tTime: 11.594552\n","\n","Validation loss decreased (0.276873 --> 0.256336).  Saving model\n","\n","Epoch Duration 69.28315496444702\n","Train Epoch: 5\tLoss: 0.244186\tTPR: 96.20253164556962\tTNR: 93.31433013734129\tTime: 1.357068\n","Val_loss: 0.254625\tTPR: 93.96551724137932\tTNR: 94.61697722567288\tTime: 11.486908\n","\n","Validation loss decreased (0.256336 --> 0.254625).  Saving model\n","\n","Epoch Duration 70.18213629722595\n","Train Epoch: 6\tLoss: 0.229120\tTPR: 94.30379746835443\tTNR: 94.18243068152371\tTime: 1.391005\n","Val_loss: 0.254542\tTPR: 93.53448275862068\tTNR: 94.69461697722568\tTime: 11.456609\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 70.94116306304932\n","Train Epoch: 7\tLoss: 0.209942\tTPR: 94.72573839662446\tTNR: 94.54521896864473\tTime: 1.347167\n","Val_loss: 0.263881\tTPR: 93.96551724137932\tTNR: 95.09575569358178\tTime: 11.445682\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 68.70309376716614\n","Train Epoch: 8\tLoss: 0.198745\tTPR: 95.56962025316456\tTNR: 95.40036278828711\tTime: 1.343164\n","Val_loss: 0.250621\tTPR: 93.31896551724138\tTNR: 95.92391304347827\tTime: 11.552923\n","\n","Validation loss decreased (0.254625 --> 0.250621).  Saving model\n","\n","Epoch Duration 69.02246451377869\n","Train Epoch: 9\tLoss: 0.191081\tTPR: 94.51476793248945\tTNR: 95.8927183208085\tTime: 1.362094\n","Val_loss: 0.253591\tTPR: 93.75\tTNR: 95.62629399585921\tTime: 11.987381\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 70.26456928253174\n","Train Epoch: 10\tLoss: 0.183462\tTPR: 94.51476793248945\tTNR: 95.98341539258875\tTime: 1.374365\n","Val_loss: 0.250823\tTPR: 93.75\tTNR: 95.87215320910974\tTime: 11.616235\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 69.30610370635986\n","Train Epoch: 11\tLoss: 0.178981\tTPR: 94.72573839662446\tTNR: 96.3202902306297\tTime: 1.325659\n","Val_loss: 0.242437\tTPR: 94.18103448275862\tTNR: 95.57453416149069\tTime: 11.512006\n","\n","Validation loss decreased (0.250621 --> 0.242437).  Saving model\n","\n","Epoch Duration 69.20473504066467\n","Train Epoch: 12\tLoss: 0.175517\tTPR: 96.20253164556962\tTNR: 95.91863176988858\tTime: 1.343684\n","Val_loss: 0.246838\tTPR: 93.96551724137932\tTNR: 95.79451345755695\tTime: 11.513423\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 68.87498426437378\n","Train Epoch: 13\tLoss: 0.168396\tTPR: 97.25738396624473\tTNR: 95.91863176988858\tTime: 1.356564\n","Val_loss: 0.253621\tTPR: 92.45689655172413\tTNR: 96.72619047619048\tTime: 11.490001\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 68.81241202354431\n","Train Epoch: 14\tLoss: 0.155416\tTPR: 96.83544303797468\tTNR: 96.82560248769111\tTime: 1.396565\n","Val_loss: 0.238851\tTPR: 93.75\tTNR: 96.14389233954451\tTime: 11.650061\n","\n","Validation loss decreased (0.242437 --> 0.238851).  Saving model\n","\n","Epoch Duration 70.22011590003967\n","Train Epoch: 15\tLoss: 0.158425\tTPR: 97.46835443037975\tTNR: 96.29437678154963\tTime: 1.345168\n","Val_loss: 0.252783\tTPR: 92.24137931034483\tTNR: 96.60973084886129\tTime: 11.444867\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 68.8289086818695\n","Train Epoch: 16\tLoss: 0.163184\tTPR: 95.35864978902954\tTNR: 97.00699663125162\tTime: 1.324029\n","Val_loss: 0.236730\tTPR: 91.8103448275862\tTNR: 96.88146997929607\tTime: 11.393205\n","\n","Validation loss decreased (0.238851 --> 0.236730).  Saving model\n","\n","Epoch Duration 68.74250483512878\n","Train Epoch: 17\tLoss: 0.144658\tTPR: 97.67932489451476\tTNR: 96.9292562840114\tTime: 1.367341\n","Val_loss: 0.255834\tTPR: 92.02586206896551\tTNR: 96.68737060041408\tTime: 11.566430\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 68.80891752243042\n","Train Epoch: 18\tLoss: 0.143338\tTPR: 97.25738396624473\tTNR: 97.20134749935217\tTime: 1.341369\n","Val_loss: 0.226689\tTPR: 92.88793103448276\tTNR: 97.04968944099379\tTime: 11.677635\n","\n","Validation loss decreased (0.236730 --> 0.226689).  Saving model\n","\n","Epoch Duration 70.41511058807373\n","Train Epoch: 19\tLoss: 0.139732\tTPR: 97.0464135021097\tTNR: 97.3568281938326\tTime: 1.351006\n","Val_loss: 0.226715\tTPR: 93.53448275862068\tTNR: 96.9332298136646\tTime: 11.662746\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 69.38619470596313\n","Train Epoch: 20\tLoss: 0.137276\tTPR: 97.25738396624473\tTNR: 97.33091474475253\tTime: 1.340671\n","Val_loss: 0.230242\tTPR: 92.45689655172413\tTNR: 97.39906832298136\tTime: 11.559130\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 69.07758498191833\n","Train Epoch: 21\tLoss: 0.148120\tTPR: 95.78059071729957\tTNR: 97.46048199015289\tTime: 1.344298\n","Val_loss: 0.229186\tTPR: 92.88793103448276\tTNR: 97.2567287784679\tTime: 11.563683\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 69.142573595047\n","Train Epoch: 22\tLoss: 0.138895\tTPR: 97.46835443037975\tTNR: 97.27908784659238\tTime: 1.341046\n","Val_loss: 0.223375\tTPR: 92.88793103448276\tTNR: 97.26966873706004\tTime: 11.718542\n","\n","Validation loss decreased (0.226689 --> 0.223375).  Saving model\n","\n","Epoch Duration 69.83353066444397\n","Train Epoch: 23\tLoss: 0.133530\tTPR: 97.0464135021097\tTNR: 97.43456854107282\tTime: 1.485665\n","Val_loss: 0.197560\tTPR: 93.53448275862068\tTNR: 97.15320910973085\tTime: 11.566657\n","\n","Validation loss decreased (0.223375 --> 0.197560).  Saving model\n","\n","Epoch Duration 70.47923135757446\n","Train Epoch: 24\tLoss: 0.130346\tTPR: 98.31223628691983\tTNR: 97.30500129567245\tTime: 1.365461\n","Val_loss: 0.209903\tTPR: 93.96551724137932\tTNR: 97.42494824016563\tTime: 11.562742\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 69.25876593589783\n","Train Epoch: 25\tLoss: 0.138409\tTPR: 96.83544303797468\tTNR: 97.70665975641359\tTime: 1.359311\n","Val_loss: 0.202155\tTPR: 95.25862068965517\tTNR: 97.39906832298136\tTime: 11.615888\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 69.34803318977356\n","Train Epoch: 26\tLoss: 0.124338\tTPR: 99.15611814345992\tTNR: 97.44752526561285\tTime: 1.355256\n","Val_loss: 0.210088\tTPR: 93.75\tTNR: 97.4120082815735\tTime: 11.598276\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 69.40191984176636\n","Train Epoch: 27\tLoss: 0.124173\tTPR: 98.73417721518987\tTNR: 97.53822233739311\tTime: 1.347091\n","Val_loss: 0.210433\tTPR: 93.75\tTNR: 97.5672877846791\tTime: 11.588975\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 70.28260469436646\n","Train Epoch: 28\tLoss: 0.129706\tTPR: 95.78059071729957\tTNR: 97.8232702772739\tTime: 1.343704\n","Val_loss: 0.202602\tTPR: 93.96551724137932\tTNR: 97.54140786749483\tTime: 11.601170\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 69.30242133140564\n","Train Epoch: 29\tLoss: 0.125953\tTPR: 97.67932489451476\tTNR: 97.77144337911376\tTime: 1.349027\n","Val_loss: 0.215355\tTPR: 92.67241379310344\tTNR: 97.76138716356108\tTime: 11.607476\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 69.42808222770691\n","Train Epoch: 30\tLoss: 0.128686\tTPR: 96.20253164556962\tTNR: 97.87509717543405\tTime: 1.362570\n","Val_loss: 0.180857\tTPR: 95.25862068965517\tTNR: 97.60610766045549\tTime: 11.736966\n","\n","Validation loss decreased (0.197560 --> 0.180857).  Saving model\n","\n","Epoch Duration 69.793696641922\n","Train Epoch: 31\tLoss: 0.117754\tTPR: 98.73417721518987\tTNR: 97.8232702772739\tTime: 1.368090\n","Val_loss: 0.212138\tTPR: 93.31896551724138\tTNR: 97.63198757763976\tTime: 12.874343\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 71.06689429283142\n","Train Epoch: 32\tLoss: 0.122942\tTPR: 97.8902953586498\tTNR: 97.81031355273387\tTime: 1.439949\n","Val_loss: 0.202929\tTPR: 93.53448275862068\tTNR: 97.78726708074534\tTime: 11.705132\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 70.10085082054138\n","Train Epoch: 33\tLoss: 0.127022\tTPR: 97.25738396624473\tTNR: 97.88805389997408\tTime: 1.369059\n","Val_loss: 0.207293\tTPR: 93.96551724137932\tTNR: 97.9296066252588\tTime: 11.788993\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 70.07742691040039\n","Train Epoch: 34\tLoss: 0.121252\tTPR: 97.25738396624473\tTNR: 98.22492873801502\tTime: 1.359933\n","Val_loss: 0.181234\tTPR: 95.04310344827587\tTNR: 97.77432712215321\tTime: 11.732545\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 70.07134079933167\n","Train Epoch: 35\tLoss: 0.120415\tTPR: 98.10126582278481\tTNR: 97.6030059600933\tTime: 1.360897\n","Val_loss: 0.196387\tTPR: 95.47413793103449\tTNR: 97.70962732919256\tTime: 11.695614\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 69.85698890686035\n","Train Epoch: 36\tLoss: 0.115198\tTPR: 98.73417721518987\tTNR: 97.93988079813423\tTime: 1.364631\n","Val_loss: 0.179619\tTPR: 94.61206896551724\tTNR: 97.87784679089026\tTime: 11.700404\n","\n","Validation loss decreased (0.180857 --> 0.179619).  Saving model\n","\n","Epoch Duration 71.09260106086731\n","Train Epoch: 37\tLoss: 0.123027\tTPR: 96.83544303797468\tTNR: 98.0046644208344\tTime: 1.368814\n","Val_loss: 0.208088\tTPR: 93.31896551724138\tTNR: 97.95548654244305\tTime: 11.753987\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 70.15409421920776\n","Train Epoch: 38\tLoss: 0.109873\tTPR: 98.31223628691983\tTNR: 98.23788546255507\tTime: 1.358566\n","Val_loss: 0.201289\tTPR: 92.88793103448276\tTNR: 97.9684265010352\tTime: 11.657259\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 69.7563362121582\n","Train Epoch: 39\tLoss: 0.113764\tTPR: 97.67932489451476\tTNR: 98.14718839077482\tTime: 1.378224\n","Val_loss: 0.186211\tTPR: 94.61206896551724\tTNR: 98.0072463768116\tTime: 11.656398\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 69.67064309120178\n","Train Epoch: 40\tLoss: 0.112554\tTPR: 97.46835443037975\tTNR: 98.09536149261466\tTime: 1.362890\n","Val_loss: 0.203454\tTPR: 93.31896551724138\tTNR: 97.98136645962732\tTime: 11.939730\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 70.56667828559875\n","Train Epoch: 41\tLoss: 0.112843\tTPR: 97.67932489451476\tTNR: 98.34153925887536\tTime: 1.347291\n","Val_loss: 0.184651\tTPR: 94.61206896551724\tTNR: 97.86490683229813\tTime: 11.608359\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 69.3337664604187\n","Train Epoch: 42\tLoss: 0.106351\tTPR: 98.52320675105484\tTNR: 98.13423166623477\tTime: 1.340987\n","Val_loss: 0.186075\tTPR: 93.75\tTNR: 98.12370600414079\tTime: 11.660872\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 69.47398710250854\n","Train Epoch: 43\tLoss: 0.110999\tTPR: 97.67932489451476\tTNR: 98.26379891163513\tTime: 1.351012\n","Val_loss: 0.163637\tTPR: 95.04310344827587\tTNR: 98.11076604554866\tTime: 11.584579\n","\n","Validation loss decreased (0.179619 --> 0.163637).  Saving model\n","\n","Epoch Duration 69.57862639427185\n","Train Epoch: 44\tLoss: 0.108757\tTPR: 98.10126582278481\tTNR: 98.31562580979528\tTime: 1.385646\n","Val_loss: 0.183860\tTPR: 93.96551724137932\tTNR: 98.11076604554866\tTime: 11.779212\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 69.73805522918701\n","Train Epoch: 45\tLoss: 0.114902\tTPR: 97.67932489451476\tTNR: 98.28971236071521\tTime: 1.440099\n","Val_loss: 0.203923\tTPR: 93.75\tTNR: 98.12370600414079\tTime: 11.531824\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 69.78434777259827\n","Train Epoch: 46\tLoss: 0.107172\tTPR: 97.25738396624473\tTNR: 98.44519305519565\tTime: 1.349083\n","Val_loss: 0.198261\tTPR: 93.10344827586206\tTNR: 98.03312629399586\tTime: 11.555290\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 69.0524971485138\n","Train Epoch: 47\tLoss: 0.111779\tTPR: 98.10126582278481\tTNR: 98.2508421870951\tTime: 1.359818\n","Val_loss: 0.194196\tTPR: 93.53448275862068\tTNR: 98.13664596273291\tTime: 11.632361\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 69.07814764976501\n","Train Epoch: 48\tLoss: 0.102460\tTPR: 98.73417721518987\tTNR: 98.38040943249547\tTime: 1.361400\n","Val_loss: 0.201795\tTPR: 92.67241379310344\tTNR: 98.04606625258799\tTime: 11.764752\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 70.0646140575409\n","Train Epoch: 49\tLoss: 0.104453\tTPR: 98.94514767932489\tTNR: 98.36745270795542\tTime: 1.350677\n","Val_loss: 0.177357\tTPR: 93.75\tTNR: 98.16252587991718\tTime: 11.654221\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 70.55992555618286\n","Train Epoch: 50\tLoss: 0.103747\tTPR: 98.10126582278481\tTNR: 98.44519305519565\tTime: 1.353799\n","Val_loss: 0.186601\tTPR: 93.75\tTNR: 98.20134575569358\tTime: 11.634231\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 69.61369776725769\n","Train Epoch: 51\tLoss: 0.099655\tTPR: 98.31223628691983\tTNR: 98.45814977973568\tTime: 1.371881\n","Val_loss: 0.180172\tTPR: 93.31896551724138\tTNR: 98.17546583850931\tTime: 11.640602\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 69.63942861557007\n","Train Epoch: 52\tLoss: 0.101072\tTPR: 98.52320675105484\tTNR: 98.38040943249547\tTime: 1.350983\n","Val_loss: 0.189195\tTPR: 93.75\tTNR: 98.20134575569358\tTime: 11.665260\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 69.60448384284973\n","Train Epoch: 53\tLoss: 0.102305\tTPR: 97.8902953586498\tTNR: 98.36745270795542\tTime: 1.355093\n","Val_loss: 0.175393\tTPR: 93.96551724137932\tTNR: 98.04606625258799\tTime: 11.644265\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 69.7487518787384\n","Train Epoch: 54\tLoss: 0.102418\tTPR: 98.52320675105484\tTNR: 98.41927960611557\tTime: 1.346817\n","Val_loss: 0.177950\tTPR: 94.18103448275862\tTNR: 98.05900621118012\tTime: 11.717157\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 70.36292433738708\n","Train Epoch: 55\tLoss: 0.108803\tTPR: 98.31223628691983\tTNR: 98.18605856439491\tTime: 1.372096\n","Val_loss: 0.190085\tTPR: 94.61206896551724\tTNR: 98.2531055900621\tTime: 11.620778\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 69.72989439964294\n","Train Epoch: 56\tLoss: 0.099525\tTPR: 98.52320675105484\tTNR: 98.40632288157553\tTime: 1.369756\n","Val_loss: 0.200521\tTPR: 93.31896551724138\tTNR: 98.0072463768116\tTime: 11.711039\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 69.71571063995361\n","Train Epoch: 57\tLoss: 0.100382\tTPR: 99.15611814345992\tTNR: 98.28971236071521\tTime: 1.344623\n","Val_loss: 0.191522\tTPR: 94.39655172413794\tTNR: 98.14958592132506\tTime: 11.768629\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 70.05739235877991\n","Train Epoch: 58\tLoss: 0.107556\tTPR: 98.52320675105484\tTNR: 98.41927960611557\tTime: 1.390581\n","Val_loss: 0.179502\tTPR: 93.75\tTNR: 98.14958592132506\tTime: 11.636910\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 70.77762937545776\n","Train Epoch: 59\tLoss: 0.098352\tTPR: 98.73417721518987\tTNR: 98.41927960611557\tTime: 1.361977\n","Val_loss: 0.201545\tTPR: 93.53448275862068\tTNR: 98.24016563146998\tTime: 11.773443\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 70.02806639671326\n","Train Epoch: 60\tLoss: 0.105554\tTPR: 97.0464135021097\tTNR: 98.56180357605598\tTime: 1.366818\n","Val_loss: 0.199999\tTPR: 94.18103448275862\tTNR: 98.27898550724638\tTime: 11.644959\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 69.82765316963196\n","Train Epoch: 61\tLoss: 0.097065\tTPR: 99.36708860759494\tTNR: 98.50997667789582\tTime: 1.360660\n","Val_loss: 0.183982\tTPR: 93.96551724137932\tTNR: 98.26604554865425\tTime: 11.693339\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 69.87153625488281\n","Train Epoch: 62\tLoss: 0.098990\tTPR: 98.73417721518987\tTNR: 98.47110650427572\tTime: 1.370107\n","Val_loss: 0.183107\tTPR: 94.61206896551724\tTNR: 98.29192546583852\tTime: 11.778351\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 70.1716480255127\n","Train Epoch: 63\tLoss: 0.095928\tTPR: 99.15611814345992\tTNR: 98.52293340243587\tTime: 1.437193\n","Val_loss: 0.192388\tTPR: 94.61206896551724\tTNR: 98.29192546583852\tTime: 11.578203\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 512, num_layers=10, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=1024, out_features=1, bias=True)\n",")\n","FS-13-WF-512-HS-10-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.064118\tTPR: 0.8438818565400843\tTNR: 99.70199533557917\tTime: 1.771876\n","Val_loss: 0.990993\tTPR: 0.0\tTNR: 100.0\tTime: 12.461672\n","\n","Validation loss decreased (inf --> 0.990993).  Saving model\n","\n","Epoch Duration 87.91658091545105\n","Train Epoch: 1\tLoss: 1.005153\tTPR: 0.0\tTNR: 100.0\tTime: 1.796373\n","Val_loss: 0.462416\tTPR: 83.1896551724138\tTNR: 88.59989648033127\tTime: 12.562577\n","\n","Validation loss decreased (0.990993 --> 0.462416).  Saving model\n","\n","Epoch Duration 88.43500018119812\n","Train Epoch: 2\tLoss: 0.499823\tTPR: 78.69198312236287\tTNR: 91.25421093547551\tTime: 1.808248\n","Val_loss: 0.341190\tTPR: 94.18103448275862\tTNR: 90.45031055900621\tTime: 12.518018\n","\n","Validation loss decreased (0.462416 --> 0.341190).  Saving model\n","\n","Epoch Duration 89.1239812374115\n","Train Epoch: 3\tLoss: 0.363302\tTPR: 93.45991561181435\tTNR: 90.60637470847371\tTime: 1.804021\n","Val_loss: 0.310099\tTPR: 95.90517241379311\tTNR: 91.22670807453416\tTime: 12.471844\n","\n","Validation loss decreased (0.341190 --> 0.310099).  Saving model\n","\n","Epoch Duration 92.07199025154114\n","Train Epoch: 4\tLoss: 0.316333\tTPR: 95.14767932489451\tTNR: 91.25421093547551\tTime: 1.827770\n","Val_loss: 0.293213\tTPR: 96.12068965517241\tTNR: 92.52070393374741\tTime: 12.494141\n","\n","Validation loss decreased (0.310099 --> 0.293213).  Saving model\n","\n","Epoch Duration 88.47465133666992\n","Train Epoch: 5\tLoss: 0.285696\tTPR: 93.45991561181435\tTNR: 92.71832080849961\tTime: 1.843902\n","Val_loss: 0.280021\tTPR: 95.90517241379311\tTNR: 93.25828157349896\tTime: 12.583833\n","\n","Validation loss decreased (0.293213 --> 0.280021).  Saving model\n","\n","Epoch Duration 89.08611392974854\n","Train Epoch: 6\tLoss: 0.258141\tTPR: 95.56962025316456\tTNR: 93.76781549624255\tTime: 1.825652\n","Val_loss: 0.306836\tTPR: 93.31896551724138\tTNR: 93.63354037267081\tTime: 12.541381\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 88.66821193695068\n","Train Epoch: 7\tLoss: 0.257221\tTPR: 93.0379746835443\tTNR: 94.36382482508422\tTime: 1.757822\n","Val_loss: 0.279858\tTPR: 94.82758620689656\tTNR: 94.31935817805382\tTime: 12.603656\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 87.6731629371643\n","Train Epoch: 8\tLoss: 0.234877\tTPR: 95.9915611814346\tTNR: 94.0010365379632\tTime: 1.777128\n","Val_loss: 0.263244\tTPR: 94.18103448275862\tTNR: 94.7075569358178\tTime: 12.538492\n","\n","Validation loss decreased (0.280021 --> 0.263244).  Saving model\n","\n","Epoch Duration 88.30547833442688\n","Train Epoch: 9\tLoss: 0.222476\tTPR: 95.56962025316456\tTNR: 94.6747862140451\tTime: 1.805154\n","Val_loss: 0.244889\tTPR: 95.6896551724138\tTNR: 94.68167701863354\tTime: 12.461337\n","\n","Validation loss decreased (0.263244 --> 0.244889).  Saving model\n","\n","Epoch Duration 89.38099217414856\n","Train Epoch: 10\tLoss: 0.206400\tTPR: 95.56962025316456\tTNR: 94.92096398030579\tTime: 1.835146\n","Val_loss: 0.246472\tTPR: 95.47413793103449\tTNR: 94.96635610766046\tTime: 12.526993\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 87.96287107467651\n","Train Epoch: 11\tLoss: 0.179493\tTPR: 97.67932489451476\tTNR: 95.6076703809277\tTime: 1.751367\n","Val_loss: 0.233754\tTPR: 96.12068965517241\tTNR: 95.23809523809523\tTime: 12.641325\n","\n","Validation loss decreased (0.244889 --> 0.233754).  Saving model\n","\n","Epoch Duration 88.8547294139862\n","Train Epoch: 12\tLoss: 0.178624\tTPR: 96.62447257383965\tTNR: 96.10002591344909\tTime: 1.810473\n","Val_loss: 0.205389\tTPR: 96.76724137931035\tTNR: 96.24741200828157\tTime: 12.599351\n","\n","Validation loss decreased (0.233754 --> 0.205389).  Saving model\n","\n","Epoch Duration 88.91748213768005\n","Train Epoch: 13\tLoss: 0.170134\tTPR: 95.78059071729957\tTNR: 96.85151593677118\tTime: 1.849224\n","Val_loss: 0.214497\tTPR: 95.6896551724138\tTNR: 96.2603519668737\tTime: 12.606812\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 88.93557739257812\n","Train Epoch: 14\tLoss: 0.159283\tTPR: 96.83544303797468\tTNR: 96.48872764965016\tTime: 1.759597\n","Val_loss: 0.198065\tTPR: 96.55172413793103\tTNR: 96.2991718426501\tTime: 12.545692\n","\n","Validation loss decreased (0.205389 --> 0.198065).  Saving model\n","\n","Epoch Duration 88.3975944519043\n","Train Epoch: 15\tLoss: 0.145661\tTPR: 97.8902953586498\tTNR: 96.81264576315107\tTime: 1.814552\n","Val_loss: 0.201251\tTPR: 96.98275862068965\tTNR: 96.24741200828157\tTime: 12.565958\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 88.01390957832336\n","Train Epoch: 16\tLoss: 0.156031\tTPR: 96.20253164556962\tTNR: 96.55351127235035\tTime: 1.835764\n","Val_loss: 0.205217\tTPR: 95.6896551724138\tTNR: 96.37681159420289\tTime: 12.493411\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 88.1909670829773\n","Train Epoch: 17\tLoss: 0.150212\tTPR: 97.8902953586498\tTNR: 96.52759782327027\tTime: 1.748064\n","Val_loss: 0.194891\tTPR: 96.12068965517241\tTNR: 97.06262939958592\tTime: 12.623963\n","\n","Validation loss decreased (0.198065 --> 0.194891).  Saving model\n","\n","Epoch Duration 88.48923468589783\n","Train Epoch: 18\tLoss: 0.144453\tTPR: 97.46835443037975\tTNR: 97.00699663125162\tTime: 1.800210\n","Val_loss: 0.194818\tTPR: 96.12068965517241\tTNR: 97.01086956521739\tTime: 12.608702\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 88.26928949356079\n","Train Epoch: 19\tLoss: 0.134920\tTPR: 98.10126582278481\tTNR: 97.34387146929257\tTime: 1.791144\n","Val_loss: 0.198832\tTPR: 95.47413793103449\tTNR: 97.07556935817804\tTime: 12.646757\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 88.23487758636475\n","Train Epoch: 20\tLoss: 0.134964\tTPR: 97.67932489451476\tTNR: 97.22726094843223\tTime: 1.793407\n","Val_loss: 0.204073\tTPR: 94.82758620689656\tTNR: 96.80383022774328\tTime: 12.677063\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 88.78468036651611\n","Train Epoch: 21\tLoss: 0.138565\tTPR: 98.10126582278481\tTNR: 97.14952060119202\tTime: 1.768997\n","Val_loss: 0.213139\tTPR: 94.61206896551724\tTNR: 97.20496894409938\tTime: 12.636435\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 88.16469144821167\n","Train Epoch: 22\tLoss: 0.142998\tTPR: 95.9915611814346\tTNR: 97.46048199015289\tTime: 1.773480\n","Val_loss: 0.199962\tTPR: 95.6896551724138\tTNR: 97.10144927536231\tTime: 13.000674\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 88.64924240112305\n","Train Epoch: 23\tLoss: 0.129194\tTPR: 97.8902953586498\tTNR: 97.34387146929257\tTime: 1.760594\n","Val_loss: 0.198717\tTPR: 95.47413793103449\tTNR: 97.4896480331263\tTime: 12.661727\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 88.80984687805176\n","Train Epoch: 24\tLoss: 0.128805\tTPR: 98.31223628691983\tTNR: 97.51230888831304\tTime: 1.775171\n","Val_loss: 0.205389\tTPR: 94.82758620689656\tTNR: 97.2955486542443\tTime: 12.525543\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 88.14767861366272\n","Train Epoch: 25\tLoss: 0.139067\tTPR: 96.20253164556962\tTNR: 97.61596268463333\tTime: 1.750981\n","Val_loss: 0.191269\tTPR: 95.90517241379311\tTNR: 97.37318840579711\tTime: 12.630077\n","\n","Validation loss decreased (0.194891 --> 0.191269).  Saving model\n","\n","Epoch Duration 88.55264949798584\n","Train Epoch: 26\tLoss: 0.117444\tTPR: 98.31223628691983\tTNR: 97.66778958279347\tTime: 1.812490\n","Val_loss: 0.189275\tTPR: 96.33620689655173\tTNR: 97.4508281573499\tTime: 12.579439\n","\n","Validation loss decreased (0.191269 --> 0.189275).  Saving model\n","\n","Epoch Duration 89.13968658447266\n","Train Epoch: 27\tLoss: 0.126955\tTPR: 97.8902953586498\tTNR: 97.39569836745271\tTime: 1.829257\n","Val_loss: 0.191551\tTPR: 96.33620689655173\tTNR: 97.34730848861284\tTime: 12.628918\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 88.74548316001892\n","Train Epoch: 28\tLoss: 0.115280\tTPR: 98.52320675105484\tTNR: 97.73257320549365\tTime: 1.780999\n","Val_loss: 0.203040\tTPR: 94.39655172413794\tTNR: 97.4120082815735\tTime: 12.685670\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 88.28661704063416\n","Train Epoch: 29\tLoss: 0.111495\tTPR: 98.94514767932489\tTNR: 97.81031355273387\tTime: 1.779226\n","Val_loss: 0.198453\tTPR: 95.04310344827587\tTNR: 97.34730848861284\tTime: 12.638376\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 88.46210551261902\n","Train Epoch: 30\tLoss: 0.121018\tTPR: 98.10126582278481\tTNR: 97.862140450894\tTime: 1.769018\n","Val_loss: 0.199159\tTPR: 94.82758620689656\tTNR: 97.63198757763976\tTime: 12.744575\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 88.99566578865051\n","Train Epoch: 31\tLoss: 0.119990\tTPR: 97.67932489451476\tTNR: 98.05649131899456\tTime: 1.763104\n","Val_loss: 0.195818\tTPR: 95.47413793103449\tTNR: 97.46376811594203\tTime: 12.663679\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 88.43428206443787\n","Train Epoch: 32\tLoss: 0.116237\tTPR: 98.31223628691983\tTNR: 97.73257320549365\tTime: 1.783964\n","Val_loss: 0.193232\tTPR: 94.82758620689656\tTNR: 97.64492753623189\tTime: 12.691275\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 88.32131886482239\n","Train Epoch: 33\tLoss: 0.119895\tTPR: 98.52320675105484\tTNR: 97.87509717543405\tTime: 1.770760\n","Val_loss: 0.191872\tTPR: 95.04310344827587\tTNR: 97.64492753623189\tTime: 12.665417\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 88.4116621017456\n","Train Epoch: 34\tLoss: 0.107944\tTPR: 98.73417721518987\tTNR: 97.90101062451411\tTime: 1.785898\n","Val_loss: 0.186693\tTPR: 95.47413793103449\tTNR: 97.78726708074534\tTime: 12.665469\n","\n","Validation loss decreased (0.189275 --> 0.186693).  Saving model\n","\n","Epoch Duration 89.49774646759033\n","Train Epoch: 35\tLoss: 0.113514\tTPR: 97.67932489451476\tTNR: 98.12127494169474\tTime: 1.832784\n","Val_loss: 0.188826\tTPR: 95.04310344827587\tTNR: 97.86490683229813\tTime: 12.643259\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 88.49139714241028\n","Train Epoch: 36\tLoss: 0.131667\tTPR: 97.25738396624473\tTNR: 98.19901528893496\tTime: 1.795216\n","Val_loss: 0.183955\tTPR: 95.6896551724138\tTNR: 97.67080745341616\tTime: 12.651237\n","\n","Validation loss decreased (0.186693 --> 0.183955).  Saving model\n","\n","Epoch Duration 89.06333351135254\n","Train Epoch: 37\tLoss: 0.108951\tTPR: 98.52320675105484\tTNR: 98.01762114537445\tTime: 1.850960\n","Val_loss: 0.201733\tTPR: 94.18103448275862\tTNR: 97.83902691511386\tTime: 12.619239\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 89.06626081466675\n","Train Epoch: 38\tLoss: 0.115907\tTPR: 97.67932489451476\tTNR: 98.08240476807462\tTime: 1.783436\n","Val_loss: 0.194950\tTPR: 94.82758620689656\tTNR: 97.82608695652173\tTime: 12.641945\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 88.17753672599792\n","Train Epoch: 39\tLoss: 0.102629\tTPR: 99.36708860759494\tTNR: 98.06944804353459\tTime: 1.768704\n","Val_loss: 0.194490\tTPR: 95.04310344827587\tTNR: 97.76138716356108\tTime: 12.666787\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 88.3474497795105\n","Train Epoch: 40\tLoss: 0.107942\tTPR: 98.73417721518987\tTNR: 98.08240476807462\tTime: 1.787637\n","Val_loss: 0.197559\tTPR: 93.96551724137932\tTNR: 98.09782608695652\tTime: 12.611970\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 88.65878629684448\n","Train Epoch: 41\tLoss: 0.102352\tTPR: 98.94514767932489\tTNR: 98.30266908525525\tTime: 1.775514\n","Val_loss: 0.200825\tTPR: 93.75\tTNR: 97.9296066252588\tTime: 12.570672\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 88.55709505081177\n","Train Epoch: 42\tLoss: 0.102293\tTPR: 99.15611814345992\tTNR: 98.35449598341539\tTime: 1.767809\n","Val_loss: 0.188838\tTPR: 94.39655172413794\tTNR: 97.95548654244305\tTime: 12.654306\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 87.95632410049438\n","Train Epoch: 43\tLoss: 0.096284\tTPR: 99.36708860759494\tTNR: 98.32858253433531\tTime: 1.769019\n","Val_loss: 0.197863\tTPR: 94.39655172413794\tTNR: 97.94254658385093\tTime: 12.683858\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 88.33506560325623\n","Train Epoch: 44\tLoss: 0.104578\tTPR: 98.52320675105484\tTNR: 98.26379891163513\tTime: 1.777315\n","Val_loss: 0.191016\tTPR: 94.18103448275862\tTNR: 97.90372670807453\tTime: 12.901209\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 88.81333208084106\n","Train Epoch: 45\tLoss: 0.102394\tTPR: 98.73417721518987\tTNR: 98.27675563617517\tTime: 1.768366\n","Val_loss: 0.196810\tTPR: 94.39655172413794\tTNR: 97.98136645962732\tTime: 12.615167\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 88.06125664710999\n","Train Epoch: 46\tLoss: 0.097628\tTPR: 99.15611814345992\tTNR: 98.22492873801502\tTime: 1.762122\n","Val_loss: 0.195392\tTPR: 94.61206896551724\tTNR: 98.05900621118012\tTime: 12.582381\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 88.06022810935974\n","Train Epoch: 47\tLoss: 0.113090\tTPR: 98.10126582278481\tTNR: 98.18605856439491\tTime: 1.776900\n","Val_loss: 0.196412\tTPR: 94.61206896551724\tTNR: 98.0072463768116\tTime: 12.584325\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 88.15388774871826\n","Train Epoch: 48\tLoss: 0.109599\tTPR: 97.67932489451476\tTNR: 98.26379891163513\tTime: 1.771630\n","Val_loss: 0.198476\tTPR: 94.39655172413794\tTNR: 98.09782608695652\tTime: 12.616346\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 88.50437498092651\n","Train Epoch: 49\tLoss: 0.099994\tTPR: 99.36708860759494\tTNR: 98.23788546255507\tTime: 1.750470\n","Val_loss: 0.198003\tTPR: 94.39655172413794\tTNR: 98.0072463768116\tTime: 12.629259\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 87.98388600349426\n","Train Epoch: 50\tLoss: 0.102141\tTPR: 98.73417721518987\tTNR: 98.30266908525525\tTime: 1.757188\n","Val_loss: 0.181740\tTPR: 95.47413793103449\tTNR: 98.09782608695652\tTime: 12.597142\n","\n","Validation loss decreased (0.183955 --> 0.181740).  Saving model\n","\n","Epoch Duration 88.75254034996033\n","Train Epoch: 51\tLoss: 0.095811\tTPR: 99.36708860759494\tTNR: 98.34153925887536\tTime: 1.806921\n","Val_loss: 0.183523\tTPR: 95.47413793103449\tTNR: 98.0072463768116\tTime: 13.023593\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 88.8587658405304\n","Train Epoch: 52\tLoss: 0.106253\tTPR: 98.31223628691983\tTNR: 98.13423166623477\tTime: 1.759233\n","Val_loss: 0.194688\tTPR: 95.04310344827587\tTNR: 97.98136645962732\tTime: 12.582241\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 88.2785758972168\n","Train Epoch: 53\tLoss: 0.102496\tTPR: 98.94514767932489\tTNR: 98.12127494169474\tTime: 1.769758\n","Val_loss: 0.196375\tTPR: 94.18103448275862\tTNR: 98.22722567287785\tTime: 12.841465\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 88.45570588111877\n","Train Epoch: 54\tLoss: 0.098285\tTPR: 99.57805907172997\tTNR: 98.41927960611557\tTime: 1.810050\n","Val_loss: 0.200534\tTPR: 94.39655172413794\tTNR: 98.11076604554866\tTime: 12.585072\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 88.18213939666748\n","Train Epoch: 55\tLoss: 0.101435\tTPR: 98.31223628691983\tTNR: 98.40632288157553\tTime: 1.787579\n","Val_loss: 0.194570\tTPR: 94.18103448275862\tTNR: 98.16252587991718\tTime: 12.564700\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 88.51022577285767\n","Train Epoch: 56\tLoss: 0.101862\tTPR: 98.52320675105484\tTNR: 98.45814977973568\tTime: 1.773337\n","Val_loss: 0.218188\tTPR: 93.31896551724138\tTNR: 97.9296066252588\tTime: 12.636797\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 88.10378050804138\n","Train Epoch: 57\tLoss: 0.096876\tTPR: 99.36708860759494\tTNR: 98.36745270795542\tTime: 1.757447\n","Val_loss: 0.192982\tTPR: 94.82758620689656\tTNR: 98.08488612836439\tTime: 12.672379\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 88.51292419433594\n","Train Epoch: 58\tLoss: 0.100059\tTPR: 98.94514767932489\tTNR: 98.3933661570355\tTime: 1.773504\n","Val_loss: 0.198693\tTPR: 95.04310344827587\tTNR: 98.13664596273291\tTime: 13.355226\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 88.96584105491638\n","Train Epoch: 59\tLoss: 0.104011\tTPR: 98.73417721518987\tTNR: 98.40632288157553\tTime: 1.775364\n","Val_loss: 0.198493\tTPR: 94.39655172413794\tTNR: 98.2531055900621\tTime: 12.635070\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 88.17496132850647\n","Train Epoch: 60\tLoss: 0.092174\tTPR: 99.57805907172997\tTNR: 98.56180357605598\tTime: 1.766868\n","Val_loss: 0.188424\tTPR: 95.04310344827587\tTNR: 98.12370600414079\tTime: 12.910168\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 88.40693950653076\n","Train Epoch: 61\tLoss: 0.105312\tTPR: 98.10126582278481\tTNR: 98.45814977973568\tTime: 1.758863\n","Val_loss: 0.192495\tTPR: 95.04310344827587\tTNR: 98.27898550724638\tTime: 12.777832\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 88.59583830833435\n","Train Epoch: 62\tLoss: 0.096314\tTPR: 98.73417721518987\tTNR: 98.61363047421612\tTime: 1.782162\n","Val_loss: 0.207628\tTPR: 93.10344827586206\tTNR: 98.20134575569358\tTime: 12.625920\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 88.82168126106262\n","Train Epoch: 63\tLoss: 0.092291\tTPR: 99.57805907172997\tTNR: 98.66545737237627\tTime: 1.768826\n","Val_loss: 0.199710\tTPR: 94.82758620689656\tTNR: 98.29192546583852\tTime: 12.708215\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 88.34362649917603\n","Train Epoch: 64\tLoss: 0.102098\tTPR: 98.31223628691983\tTNR: 98.61363047421612\tTime: 1.771855\n","Val_loss: 0.208237\tTPR: 94.18103448275862\tTNR: 98.24016563146998\tTime: 12.730996\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 88.59296083450317\n","Train Epoch: 65\tLoss: 0.097708\tTPR: 98.94514767932489\tTNR: 98.48406322881576\tTime: 1.788643\n","Val_loss: 0.208009\tTPR: 93.96551724137932\tTNR: 98.27898550724638\tTime: 13.398266\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 89.196608543396\n","Train Epoch: 66\tLoss: 0.092187\tTPR: 99.15611814345992\tTNR: 98.65250064783623\tTime: 1.783771\n","Val_loss: 0.205788\tTPR: 93.75\tTNR: 98.20134575569358\tTime: 12.731378\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 88.47360563278198\n","Train Epoch: 67\tLoss: 0.102408\tTPR: 98.52320675105484\tTNR: 98.57476030059601\tTime: 1.781115\n","Val_loss: 0.225896\tTPR: 93.53448275862068\tTNR: 98.21428571428571\tTime: 12.699956\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 88.55259704589844\n","Train Epoch: 68\tLoss: 0.094699\tTPR: 98.73417721518987\tTNR: 98.52293340243587\tTime: 1.774478\n","Val_loss: 0.202288\tTPR: 94.82758620689656\tTNR: 98.27898550724638\tTime: 12.735133\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 88.64352703094482\n","Train Epoch: 69\tLoss: 0.096669\tTPR: 98.52320675105484\tTNR: 98.60067374967608\tTime: 1.768731\n","Val_loss: 0.201180\tTPR: 95.04310344827587\tTNR: 98.31780538302277\tTime: 12.719202\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 89.00355291366577\n","Train Epoch: 70\tLoss: 0.091040\tTPR: 98.94514767932489\tTNR: 98.6784140969163\tTime: 1.772181\n","Val_loss: 0.205405\tTPR: 94.39655172413794\tTNR: 98.18840579710145\tTime: 12.765682\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 1024, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=2048, out_features=1, bias=True)\n",")\n","FS-13-WF-1024-HS-2-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.051553\tTPR: 42.19409282700422\tTNR: 62.295931588494426\tTime: 1.312895\n","Val_loss: 0.433423\tTPR: 85.12931034482759\tTNR: 92.08074534161491\tTime: 11.999661\n","\n","Validation loss decreased (inf --> 0.433423).  Saving model\n","\n","Epoch Duration 68.3056812286377\n","Train Epoch: 1\tLoss: 0.480422\tTPR: 77.42616033755274\tTNR: 93.62529152630215\tTime: 1.321081\n","Val_loss: 0.319161\tTPR: 94.18103448275862\tTNR: 91.52432712215321\tTime: 11.996513\n","\n","Validation loss decreased (0.433423 --> 0.319161).  Saving model\n","\n","Epoch Duration 68.42456293106079\n","Train Epoch: 2\tLoss: 0.351731\tTPR: 90.71729957805907\tTNR: 93.00336874838041\tTime: 1.339742\n","Val_loss: 0.273853\tTPR: 96.12068965517241\tTNR: 92.15838509316771\tTime: 11.979654\n","\n","Validation loss decreased (0.319161 --> 0.273853).  Saving model\n","\n","Epoch Duration 68.81208825111389\n","Train Epoch: 3\tLoss: 0.292511\tTPR: 95.14767932489451\tTNR: 92.29074889867842\tTime: 1.330174\n","Val_loss: 0.251573\tTPR: 96.12068965517241\tTNR: 93.24534161490683\tTime: 11.869822\n","\n","Validation loss decreased (0.273853 --> 0.251573).  Saving model\n","\n","Epoch Duration 68.23716425895691\n","Train Epoch: 4\tLoss: 0.250407\tTPR: 95.56962025316456\tTNR: 93.44389738274165\tTime: 1.309702\n","Val_loss: 0.231867\tTPR: 96.33620689655173\tTNR: 93.7111801242236\tTime: 11.932597\n","\n","Validation loss decreased (0.251573 --> 0.231867).  Saving model\n","\n","Epoch Duration 68.59776782989502\n","Train Epoch: 5\tLoss: 0.230738\tTPR: 95.14767932489451\tTNR: 94.22130085514382\tTime: 1.341516\n","Val_loss: 0.222882\tTPR: 95.90517241379311\tTNR: 94.30641821946169\tTime: 11.947081\n","\n","Validation loss decreased (0.231867 --> 0.222882).  Saving model\n","\n","Epoch Duration 68.13496732711792\n","Train Epoch: 6\tLoss: 0.209735\tTPR: 94.9367088607595\tTNR: 95.05053122570614\tTime: 1.328191\n","Val_loss: 0.218882\tTPR: 91.8103448275862\tTNR: 95.27691511387164\tTime: 12.101678\n","\n","Validation loss decreased (0.222882 --> 0.218882).  Saving model\n","\n","Epoch Duration 68.46427798271179\n","Train Epoch: 7\tLoss: 0.196313\tTPR: 96.62447257383965\tTNR: 95.21896864472662\tTime: 1.392314\n","Val_loss: 0.214829\tTPR: 92.24137931034483\tTNR: 95.97567287784679\tTime: 11.894988\n","\n","Validation loss decreased (0.218882 --> 0.214829).  Saving model\n","\n","Epoch Duration 68.465744972229\n","Train Epoch: 8\tLoss: 0.193141\tTPR: 96.20253164556962\tTNR: 95.52993003368748\tTime: 1.308684\n","Val_loss: 0.215307\tTPR: 90.30172413793103\tTNR: 96.51915113871635\tTime: 11.861291\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 67.59323382377625\n","Train Epoch: 9\tLoss: 0.178042\tTPR: 96.62447257383965\tTNR: 95.90567504534853\tTime: 1.288108\n","Val_loss: 0.232395\tTPR: 89.22413793103449\tTNR: 96.3379917184265\tTime: 11.822464\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 67.67690706253052\n","Train Epoch: 10\tLoss: 0.178110\tTPR: 97.8902953586498\tTNR: 96.0352422907489\tTime: 1.300252\n","Val_loss: 0.244952\tTPR: 87.5\tTNR: 97.03674948240165\tTime: 11.908476\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 67.4736008644104\n","Train Epoch: 11\tLoss: 0.167604\tTPR: 97.0464135021097\tTNR: 96.3591604042498\tTime: 1.301916\n","Val_loss: 0.254121\tTPR: 87.5\tTNR: 97.15320910973085\tTime: 11.884404\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 68.08322191238403\n","Train Epoch: 12\tLoss: 0.164295\tTPR: 97.0464135021097\tTNR: 96.68307851775072\tTime: 1.319993\n","Val_loss: 0.284250\tTPR: 86.85344827586206\tTNR: 97.10144927536231\tTime: 11.891440\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 67.20417475700378\n","Train Epoch: 13\tLoss: 0.155077\tTPR: 97.25738396624473\tTNR: 96.81264576315107\tTime: 1.290291\n","Val_loss: 0.339249\tTPR: 86.42241379310344\tTNR: 97.4508281573499\tTime: 11.793628\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 67.45304656028748\n","Train Epoch: 14\tLoss: 0.145561\tTPR: 98.10126582278481\tTNR: 97.04586680487172\tTime: 1.287949\n","Val_loss: 0.346875\tTPR: 85.5603448275862\tTNR: 97.10144927536231\tTime: 11.820832\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 67.22531914710999\n","Train Epoch: 15\tLoss: 0.148958\tTPR: 96.62447257383965\tTNR: 97.42161181653279\tTime: 1.280122\n","Val_loss: 0.336535\tTPR: 82.54310344827587\tTNR: 97.91666666666666\tTime: 11.861228\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 67.17464995384216\n","Train Epoch: 16\tLoss: 0.141098\tTPR: 96.41350210970464\tTNR: 97.69370303187355\tTime: 1.304016\n","Val_loss: 0.399366\tTPR: 80.17241379310344\tTNR: 97.851966873706\tTime: 11.856865\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 67.92258191108704\n","Train Epoch: 17\tLoss: 0.139339\tTPR: 97.25738396624473\tTNR: 97.69370303187355\tTime: 1.301440\n","Val_loss: 0.270772\tTPR: 85.99137931034483\tTNR: 97.91666666666666\tTime: 11.833658\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 67.12094020843506\n","Train Epoch: 18\tLoss: 0.131069\tTPR: 97.67932489451476\tTNR: 97.51230888831304\tTime: 1.285870\n","Val_loss: 0.326138\tTPR: 85.99137931034483\tTNR: 97.83902691511386\tTime: 11.794374\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 67.22530484199524\n","Train Epoch: 19\tLoss: 0.127592\tTPR: 98.10126582278481\tTNR: 97.71961648095362\tTime: 1.280488\n","Val_loss: 0.303177\tTPR: 86.20689655172413\tTNR: 97.64492753623189\tTime: 11.981979\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 67.2245500087738\n","Train Epoch: 20\tLoss: 0.126509\tTPR: 98.73417721518987\tTNR: 97.62891940917336\tTime: 1.304609\n","Val_loss: 0.266206\tTPR: 89.4396551724138\tTNR: 97.58022774327122\tTime: 12.502821\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 68.71123671531677\n","Train Epoch: 21\tLoss: 0.133970\tTPR: 97.25738396624473\tTNR: 97.6030059600933\tTime: 1.322471\n","Val_loss: 0.280322\tTPR: 89.4396551724138\tTNR: 97.59316770186336\tTime: 11.929224\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 67.59352517127991\n","Train Epoch: 22\tLoss: 0.127874\tTPR: 97.46835443037975\tTNR: 97.9269240735942\tTime: 1.294795\n","Val_loss: 0.306601\tTPR: 85.99137931034483\tTNR: 97.82608695652173\tTime: 12.025082\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 67.80336260795593\n","Train Epoch: 23\tLoss: 0.126168\tTPR: 97.67932489451476\tTNR: 97.99170769629437\tTime: 1.271296\n","Val_loss: 0.277193\tTPR: 88.14655172413794\tTNR: 97.78726708074534\tTime: 11.923567\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 67.73861169815063\n","Train Epoch: 24\tLoss: 0.125769\tTPR: 98.10126582278481\tTNR: 97.8232702772739\tTime: 1.299983\n","Val_loss: 0.291557\tTPR: 86.42241379310344\tTNR: 97.9296066252588\tTime: 11.867941\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 67.50091910362244\n","Train Epoch: 25\tLoss: 0.116539\tTPR: 98.94514767932489\tTNR: 97.9657942472143\tTime: 1.290051\n","Val_loss: 0.279237\tTPR: 89.22413793103449\tTNR: 97.80020703933747\tTime: 11.888157\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 67.86233878135681\n","Train Epoch: 26\tLoss: 0.118441\tTPR: 98.10126582278481\tTNR: 97.90101062451411\tTime: 1.295965\n","Val_loss: 0.248546\tTPR: 89.87068965517241\tTNR: 97.95548654244305\tTime: 11.795250\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 67.02647805213928\n","Train Epoch: 27\tLoss: 0.113564\tTPR: 98.73417721518987\tTNR: 98.05649131899456\tTime: 1.292371\n","Val_loss: 0.261212\tTPR: 89.65517241379311\tTNR: 97.78726708074534\tTime: 11.789735\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 1024, num_layers=5, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=2048, out_features=1, bias=True)\n",")\n","FS-13-WF-1024-HS-5-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.073923\tTPR: 93.67088607594937\tTNR: 7.4112464369007505\tTime: 1.947988\n","Val_loss: 0.453155\tTPR: 72.62931034482759\tTNR: 92.90890269151139\tTime: 14.008157\n","\n","Validation loss decreased (inf --> 0.453155).  Saving model\n","\n","Epoch Duration 97.41828036308289\n","Train Epoch: 1\tLoss: 0.493134\tTPR: 66.87763713080169\tTNR: 94.29904120238403\tTime: 1.970854\n","Val_loss: 0.292858\tTPR: 94.61206896551724\tTNR: 91.99016563146998\tTime: 13.995630\n","\n","Validation loss decreased (0.453155 --> 0.292858).  Saving model\n","\n","Epoch Duration 98.44468808174133\n","Train Epoch: 2\tLoss: 0.295110\tTPR: 96.83544303797468\tTNR: 91.37082145633583\tTime: 1.973411\n","Val_loss: 0.242800\tTPR: 95.90517241379311\tTNR: 93.43944099378882\tTime: 13.969576\n","\n","Validation loss decreased (0.292858 --> 0.242800).  Saving model\n","\n","Epoch Duration 98.27225112915039\n","Train Epoch: 3\tLoss: 0.231965\tTPR: 96.41350210970464\tTNR: 93.58642135268204\tTime: 1.978249\n","Val_loss: 0.236183\tTPR: 93.31896551724138\tTNR: 94.69461697722568\tTime: 13.982115\n","\n","Validation loss decreased (0.242800 --> 0.236183).  Saving model\n","\n","Epoch Duration 98.10990881919861\n","Train Epoch: 4\tLoss: 0.210986\tTPR: 94.30379746835443\tTNR: 95.10235812386628\tTime: 1.966047\n","Val_loss: 0.235796\tTPR: 93.53448275862068\tTNR: 95.62629399585921\tTime: 14.045816\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 97.26795697212219\n","Train Epoch: 5\tLoss: 0.181746\tTPR: 97.25738396624473\tTNR: 95.62062710546773\tTime: 1.945766\n","Val_loss: 0.264003\tTPR: 90.73275862068965\tTNR: 96.38975155279503\tTime: 13.979062\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 96.47709321975708\n","Train Epoch: 6\tLoss: 0.176857\tTPR: 96.20253164556962\tTNR: 96.47577092511013\tTime: 1.914478\n","Val_loss: 0.216831\tTPR: 94.18103448275862\tTNR: 96.31211180124224\tTime: 13.993773\n","\n","Validation loss decreased (0.236183 --> 0.216831).  Saving model\n","\n","Epoch Duration 97.57515478134155\n","Train Epoch: 7\tLoss: 0.169236\tTPR: 95.78059071729957\tTNR: 96.76081886499092\tTime: 1.978907\n","Val_loss: 0.236520\tTPR: 95.04310344827587\tTNR: 96.31211180124224\tTime: 13.944629\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 97.3266396522522\n","Train Epoch: 8\tLoss: 0.155640\tTPR: 98.94514767932489\tTNR: 96.15185281160923\tTime: 1.919156\n","Val_loss: 0.303993\tTPR: 86.85344827586206\tTNR: 96.84265010351967\tTime: 14.198549\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 96.39206099510193\n","Train Epoch: 9\tLoss: 0.171509\tTPR: 93.88185654008439\tTNR: 97.53822233739311\tTime: 1.915488\n","Val_loss: 0.276904\tTPR: 88.79310344827587\tTNR: 97.46376811594203\tTime: 13.925778\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 95.91163158416748\n","Train Epoch: 10\tLoss: 0.154517\tTPR: 96.62447257383965\tTNR: 97.09769370303188\tTime: 1.928037\n","Val_loss: 0.274041\tTPR: 90.51724137931035\tTNR: 97.43788819875776\tTime: 14.339134\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 96.26577115058899\n","Train Epoch: 11\tLoss: 0.146074\tTPR: 97.46835443037975\tTNR: 97.11065042757191\tTime: 1.998305\n","Val_loss: 0.255132\tTPR: 91.37931034482759\tTNR: 97.4508281573499\tTime: 13.906278\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 96.08233547210693\n","Train Epoch: 12\tLoss: 0.138529\tTPR: 97.8902953586498\tTNR: 97.14952060119202\tTime: 1.930025\n","Val_loss: 0.233334\tTPR: 91.8103448275862\tTNR: 97.19202898550725\tTime: 13.932708\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 96.20458912849426\n","Train Epoch: 13\tLoss: 0.128522\tTPR: 98.73417721518987\tTNR: 97.30500129567245\tTime: 1.927559\n","Val_loss: 0.203366\tTPR: 95.25862068965517\tTNR: 97.07556935817804\tTime: 13.868494\n","\n","Validation loss decreased (0.216831 --> 0.203366).  Saving model\n","\n","Epoch Duration 97.31957483291626\n","Train Epoch: 14\tLoss: 0.133704\tTPR: 98.73417721518987\tTNR: 96.86447266131123\tTime: 1.975929\n","Val_loss: 0.231557\tTPR: 92.24137931034483\tTNR: 97.69668737060042\tTime: 14.033200\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 97.05920815467834\n","Train Epoch: 15\tLoss: 0.127254\tTPR: 97.0464135021097\tTNR: 97.75848665457373\tTime: 1.925031\n","Val_loss: 0.228621\tTPR: 92.24137931034483\tTNR: 97.87784679089026\tTime: 13.979344\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 96.19274115562439\n","Train Epoch: 16\tLoss: 0.130960\tTPR: 96.41350210970464\tTNR: 97.91396734905416\tTime: 1.946736\n","Val_loss: 0.197901\tTPR: 93.10344827586206\tTNR: 97.9296066252588\tTime: 13.983396\n","\n","Validation loss decreased (0.203366 --> 0.197901).  Saving model\n","\n","Epoch Duration 97.77531695365906\n","Train Epoch: 17\tLoss: 0.118423\tTPR: 97.8902953586498\tTNR: 97.88805389997408\tTime: 1.980647\n","Val_loss: 0.229719\tTPR: 93.31896551724138\tTNR: 97.9684265010352\tTime: 14.051725\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 97.3956253528595\n","Train Epoch: 18\tLoss: 0.126337\tTPR: 96.62447257383965\tTNR: 97.84918372635398\tTime: 1.948659\n","Val_loss: 0.175546\tTPR: 94.82758620689656\tTNR: 97.94254658385093\tTime: 14.058969\n","\n","Validation loss decreased (0.197901 --> 0.175546).  Saving model\n","\n","Epoch Duration 98.02947926521301\n","Train Epoch: 19\tLoss: 0.124762\tTPR: 97.0464135021097\tTNR: 98.13423166623477\tTime: 1.958636\n","Val_loss: 0.180024\tTPR: 94.82758620689656\tTNR: 97.98136645962732\tTime: 14.126859\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 96.99243140220642\n","Train Epoch: 20\tLoss: 0.119488\tTPR: 97.8902953586498\tTNR: 97.83622700181395\tTime: 1.945209\n","Val_loss: 0.203197\tTPR: 94.82758620689656\tTNR: 98.0072463768116\tTime: 14.259424\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 97.36568927764893\n","Train Epoch: 21\tLoss: 0.111519\tTPR: 98.52320675105484\tTNR: 97.97875097175434\tTime: 1.943069\n","Val_loss: 0.192869\tTPR: 94.82758620689656\tTNR: 98.08488612836439\tTime: 14.054894\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 97.17462921142578\n","Train Epoch: 22\tLoss: 0.116927\tTPR: 97.0464135021097\tTNR: 98.04353459445451\tTime: 1.946709\n","Val_loss: 0.161933\tTPR: 95.47413793103449\tTNR: 97.87784679089026\tTime: 14.229688\n","\n","Validation loss decreased (0.175546 --> 0.161933).  Saving model\n","\n","Epoch Duration 98.19030714035034\n","Train Epoch: 23\tLoss: 0.107651\tTPR: 99.36708860759494\tTNR: 97.88805389997408\tTime: 1.979071\n","Val_loss: 0.161290\tTPR: 94.61206896551724\tTNR: 97.9296066252588\tTime: 14.025202\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 97.53370881080627\n","Train Epoch: 24\tLoss: 0.118394\tTPR: 98.31223628691983\tTNR: 98.05649131899456\tTime: 1.952548\n","Val_loss: 0.180828\tTPR: 94.82758620689656\tTNR: 98.09782608695652\tTime: 14.084615\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 96.96365332603455\n","Train Epoch: 25\tLoss: 0.100996\tTPR: 99.15611814345992\tTNR: 98.27675563617517\tTime: 1.948002\n","Val_loss: 0.179818\tTPR: 94.39655172413794\tTNR: 98.22722567287785\tTime: 14.193140\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 96.93411755561829\n","Train Epoch: 26\tLoss: 0.104520\tTPR: 98.73417721518987\tTNR: 98.21197201347499\tTime: 1.945664\n","Val_loss: 0.201636\tTPR: 94.39655172413794\tTNR: 98.16252587991718\tTime: 14.679641\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 98.22780060768127\n","Train Epoch: 27\tLoss: 0.104159\tTPR: 98.73417721518987\tTNR: 98.40632288157553\tTime: 2.033617\n","Val_loss: 0.171372\tTPR: 95.25862068965517\tTNR: 98.33074534161491\tTime: 14.194380\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 98.29967880249023\n","Train Epoch: 28\tLoss: 0.107926\tTPR: 98.73417721518987\tTNR: 98.13423166623477\tTime: 1.971584\n","Val_loss: 0.209557\tTPR: 93.31896551724138\tTNR: 98.39544513457557\tTime: 14.147316\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 97.24987697601318\n","Train Epoch: 29\tLoss: 0.102515\tTPR: 98.31223628691983\tTNR: 98.47110650427572\tTime: 1.953987\n","Val_loss: 0.211005\tTPR: 93.53448275862068\tTNR: 98.34368530020704\tTime: 14.306831\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 97.45723557472229\n","Train Epoch: 30\tLoss: 0.101176\tTPR: 98.10126582278481\tTNR: 98.58771702513604\tTime: 1.962693\n","Val_loss: 0.203622\tTPR: 92.88793103448276\tTNR: 98.47308488612836\tTime: 14.498073\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 98.13346147537231\n","Train Epoch: 31\tLoss: 0.102989\tTPR: 97.67932489451476\tTNR: 98.49701995335579\tTime: 1.968912\n","Val_loss: 0.181398\tTPR: 94.18103448275862\tTNR: 98.55072463768117\tTime: 14.270403\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 97.53492617607117\n","Train Epoch: 32\tLoss: 0.097975\tTPR: 98.10126582278481\tTNR: 98.49701995335579\tTime: 1.968753\n","Val_loss: 0.175654\tTPR: 94.39655172413794\tTNR: 98.29192546583852\tTime: 14.256332\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 97.46605587005615\n","Train Epoch: 33\tLoss: 0.093769\tTPR: 99.57805907172997\tTNR: 98.45814977973568\tTime: 1.941511\n","Val_loss: 0.194779\tTPR: 92.67241379310344\tTNR: 98.51190476190477\tTime: 14.206019\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 97.60234427452087\n","Train Epoch: 34\tLoss: 0.093161\tTPR: 98.73417721518987\tTNR: 98.70432754599638\tTime: 1.942902\n","Val_loss: 0.178915\tTPR: 95.25862068965517\tTNR: 98.49896480331263\tTime: 14.170932\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 97.44265365600586\n","Train Epoch: 35\tLoss: 0.096905\tTPR: 98.73417721518987\tTNR: 98.61363047421612\tTime: 1.958896\n","Val_loss: 0.200499\tTPR: 94.61206896551724\tTNR: 98.49896480331263\tTime: 14.294766\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 97.87881088256836\n","Train Epoch: 36\tLoss: 0.097156\tTPR: 98.52320675105484\tTNR: 98.6784140969163\tTime: 1.952381\n","Val_loss: 0.216825\tTPR: 93.31896551724138\tTNR: 98.5248447204969\tTime: 14.203156\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 97.86613416671753\n","Train Epoch: 37\tLoss: 0.096417\tTPR: 98.73417721518987\tTNR: 98.75615444415652\tTime: 1.943172\n","Val_loss: 0.236854\tTPR: 93.10344827586206\tTNR: 98.36956521739131\tTime: 14.228675\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 97.66823697090149\n","Train Epoch: 38\tLoss: 0.095530\tTPR: 98.73417721518987\tTNR: 98.6784140969163\tTime: 1.948826\n","Val_loss: 0.134896\tTPR: 96.12068965517241\tTNR: 98.42132505175984\tTime: 14.262032\n","\n","Validation loss decreased (0.161933 --> 0.134896).  Saving model\n","\n","Epoch Duration 98.76817202568054\n","Train Epoch: 39\tLoss: 0.095523\tTPR: 98.31223628691983\tTNR: 98.54884685151593\tTime: 1.976912\n","Val_loss: 0.161918\tTPR: 94.61206896551724\tTNR: 98.55072463768117\tTime: 14.209382\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 98.19779753684998\n","Train Epoch: 40\tLoss: 0.095505\tTPR: 98.31223628691983\tTNR: 98.6784140969163\tTime: 1.946993\n","Val_loss: 0.182576\tTPR: 95.04310344827587\tTNR: 98.66718426501035\tTime: 14.185962\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 97.20442986488342\n","Train Epoch: 41\tLoss: 0.096634\tTPR: 98.31223628691983\tTNR: 98.78206789323659\tTime: 1.956333\n","Val_loss: 0.186317\tTPR: 95.04310344827587\tTNR: 98.62836438923395\tTime: 14.130961\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 96.88711977005005\n","Train Epoch: 42\tLoss: 0.089026\tTPR: 99.15611814345992\tTNR: 98.71728427053641\tTime: 1.950252\n","Val_loss: 0.183743\tTPR: 95.47413793103449\tTNR: 98.49896480331263\tTime: 14.588157\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 97.59559988975525\n","Train Epoch: 43\tLoss: 0.088476\tTPR: 99.36708860759494\tTNR: 98.70432754599638\tTime: 1.944775\n","Val_loss: 0.200882\tTPR: 94.61206896551724\tTNR: 98.55072463768117\tTime: 14.150156\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 97.37220311164856\n","Train Epoch: 44\tLoss: 0.087468\tTPR: 99.57805907172997\tTNR: 98.74319771961649\tTime: 1.922853\n","Val_loss: 0.210085\tTPR: 93.53448275862068\tTNR: 98.53778467908903\tTime: 14.180173\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 96.96584367752075\n","Train Epoch: 45\tLoss: 0.091963\tTPR: 98.73417721518987\tTNR: 98.75615444415652\tTime: 1.944367\n","Val_loss: 0.214346\tTPR: 94.61206896551724\tTNR: 98.57660455486543\tTime: 14.146771\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 96.96492218971252\n","Train Epoch: 46\tLoss: 0.091555\tTPR: 99.15611814345992\tTNR: 98.69137082145633\tTime: 1.939718\n","Val_loss: 0.211132\tTPR: 93.96551724137932\tTNR: 98.65424430641822\tTime: 14.080822\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 97.48281240463257\n","Train Epoch: 47\tLoss: 0.089084\tTPR: 98.94514767932489\tTNR: 98.83389479139673\tTime: 1.944783\n","Val_loss: 0.240189\tTPR: 93.96551724137932\tTNR: 98.11076604554866\tTime: 14.072193\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 96.68391752243042\n","Train Epoch: 48\tLoss: 0.099216\tTPR: 99.57805907172997\tTNR: 98.32858253433531\tTime: 1.938911\n","Val_loss: 0.247984\tTPR: 93.10344827586206\tTNR: 98.5636645962733\tTime: 14.022230\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 96.68092489242554\n","Train Epoch: 49\tLoss: 0.093009\tTPR: 98.52320675105484\tTNR: 98.71728427053641\tTime: 1.932296\n","Val_loss: 0.251478\tTPR: 92.67241379310344\tTNR: 98.69306418219462\tTime: 14.134478\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 97.47286701202393\n","Train Epoch: 50\tLoss: 0.094162\tTPR: 97.8902953586498\tTNR: 98.83389479139673\tTime: 1.958566\n","Val_loss: 0.202718\tTPR: 94.61206896551724\tTNR: 98.68012422360249\tTime: 13.981670\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 96.62648582458496\n","Train Epoch: 51\tLoss: 0.091038\tTPR: 98.52320675105484\tTNR: 98.8209380668567\tTime: 1.939291\n","Val_loss: 0.247908\tTPR: 93.75\tTNR: 98.65424430641822\tTime: 14.068791\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 96.4538152217865\n","Train Epoch: 52\tLoss: 0.089598\tTPR: 98.94514767932489\tTNR: 98.74319771961649\tTime: 1.944026\n","Val_loss: 0.241865\tTPR: 93.53448275862068\tTNR: 98.74482401656314\tTime: 14.322323\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 97.38113069534302\n","Train Epoch: 53\tLoss: 0.086853\tTPR: 98.73417721518987\tTNR: 98.89867841409692\tTime: 1.944166\n","Val_loss: 0.242712\tTPR: 93.96551724137932\tTNR: 98.74482401656314\tTime: 14.034628\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 96.47976088523865\n","Train Epoch: 54\tLoss: 0.082391\tTPR: 100.0\tTNR: 98.88572168955689\tTime: 1.927843\n","Val_loss: 0.246527\tTPR: 93.96551724137932\tTNR: 98.69306418219462\tTime: 13.953905\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 96.12008762359619\n","Train Epoch: 55\tLoss: 0.082661\tTPR: 99.57805907172997\tTNR: 98.89867841409692\tTime: 1.929919\n","Val_loss: 0.237323\tTPR: 93.96551724137932\tTNR: 98.66718426501035\tTime: 13.886374\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 96.5293972492218\n","Train Epoch: 56\tLoss: 0.087160\tTPR: 99.15611814345992\tTNR: 98.87276496501684\tTime: 1.918677\n","Val_loss: 0.232590\tTPR: 93.96551724137932\tTNR: 98.69306418219462\tTime: 14.032732\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 96.42328262329102\n","Train Epoch: 57\tLoss: 0.085505\tTPR: 99.15611814345992\tTNR: 98.89867841409692\tTime: 1.935722\n","Val_loss: 0.219056\tTPR: 93.75\tTNR: 98.61542443064182\tTime: 13.873510\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 95.81768107414246\n","Train Epoch: 58\tLoss: 0.101023\tTPR: 97.8902953586498\tTNR: 98.61363047421612\tTime: 1.921396\n","Val_loss: 0.244132\tTPR: 93.96551724137932\tTNR: 98.71894409937887\tTime: 14.529805\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 1024, num_layers=10, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=2048, out_features=1, bias=True)\n",")\n","FS-13-WF-1024-HS-10-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.073694\tTPR: 100.0\tTNR: 0.0\tTime: 3.032792\n","Val_loss: 0.608273\tTPR: 57.11206896551724\tTNR: 94.88871635610766\tTime: 17.845883\n","\n","Validation loss decreased (inf --> 0.608273).  Saving model\n","\n","Epoch Duration 150.92786955833435\n","Train Epoch: 1\tLoss: 0.677018\tTPR: 48.52320675105485\tTNR: 96.5016843741902\tTime: 3.085752\n","Val_loss: 0.349595\tTPR: 94.82758620689656\tTNR: 89.40217391304348\tTime: 17.873831\n","\n","Validation loss decreased (0.608273 --> 0.349595).  Saving model\n","\n","Epoch Duration 151.7892324924469\n","Train Epoch: 2\tLoss: 0.361153\tTPR: 95.56962025316456\tTNR: 89.3236589790101\tTime: 3.113981\n","Val_loss: 0.310686\tTPR: 92.02586206896551\tTNR: 92.05486542443064\tTime: 17.887138\n","\n","Validation loss decreased (0.349595 --> 0.310686).  Saving model\n","\n","Epoch Duration 151.79140520095825\n","Train Epoch: 3\tLoss: 0.300956\tTPR: 93.88185654008439\tTNR: 92.56284011401917\tTime: 3.843320\n","Val_loss: 0.298018\tTPR: 92.24137931034483\tTNR: 93.41356107660455\tTime: 17.829010\n","\n","Validation loss decreased (0.310686 --> 0.298018).  Saving model\n","\n","Epoch Duration 152.33061528205872\n","Train Epoch: 4\tLoss: 0.255636\tTPR: 96.41350210970464\tTNR: 92.95154185022027\tTime: 4.067793\n","Val_loss: 0.309930\tTPR: 90.94827586206897\tTNR: 94.39699792960663\tTime: 17.769894\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 149.4939284324646\n","Train Epoch: 5\tLoss: 0.219641\tTPR: 94.09282700421942\tTNR: 94.98574760300596\tTime: 3.018783\n","Val_loss: 0.284393\tTPR: 89.65517241379311\tTNR: 96.06625258799171\tTime: 17.915542\n","\n","Validation loss decreased (0.298018 --> 0.284393).  Saving model\n","\n","Epoch Duration 150.85358572006226\n","Train Epoch: 6\tLoss: 0.210949\tTPR: 92.82700421940928\tTNR: 96.21663643430941\tTime: 3.681873\n","Val_loss: 0.244175\tTPR: 95.04310344827587\tTNR: 95.43219461697723\tTime: 17.899896\n","\n","Validation loss decreased (0.284393 --> 0.244175).  Saving model\n","\n","Epoch Duration 152.97999262809753\n","Train Epoch: 7\tLoss: 0.172330\tTPR: 98.94514767932489\tTNR: 95.14122829748639\tTime: 3.076870\n","Val_loss: 0.234717\tTPR: 92.02586206896551\tTNR: 97.08850931677019\tTime: 17.904297\n","\n","Validation loss decreased (0.244175 --> 0.234717).  Saving model\n","\n","Epoch Duration 151.70051431655884\n","Train Epoch: 8\tLoss: 0.153100\tTPR: 97.67932489451476\tTNR: 96.72194869137081\tTime: 4.374610\n","Val_loss: 0.254137\tTPR: 91.37931034482759\tTNR: 97.11438923395445\tTime: 17.831527\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 149.8030343055725\n","Train Epoch: 9\tLoss: 0.145643\tTPR: 97.25738396624473\tTNR: 97.0717802539518\tTime: 3.015366\n","Val_loss: 0.217561\tTPR: 93.75\tTNR: 97.38612836438924\tTime: 17.704174\n","\n","Validation loss decreased (0.234717 --> 0.217561).  Saving model\n","\n","Epoch Duration 150.41432905197144\n","Train Epoch: 10\tLoss: 0.122602\tTPR: 99.15611814345992\tTNR: 97.43456854107282\tTime: 3.066976\n","Val_loss: 0.232037\tTPR: 92.67241379310344\tTNR: 97.55434782608695\tTime: 17.739013\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 147.80043005943298\n","Train Epoch: 11\tLoss: 0.125869\tTPR: 98.10126582278481\tTNR: 97.57709251101322\tTime: 3.004027\n","Val_loss: 0.196883\tTPR: 95.25862068965517\tTNR: 97.46376811594203\tTime: 17.701484\n","\n","Validation loss decreased (0.217561 --> 0.196883).  Saving model\n","\n","Epoch Duration 150.33675909042358\n","Train Epoch: 12\tLoss: 0.117987\tTPR: 98.94514767932489\tTNR: 97.59004923555325\tTime: 3.079063\n","Val_loss: 0.203148\tTPR: 94.61206896551724\tTNR: 97.51552795031056\tTime: 17.792228\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 147.96842908859253\n","Train Epoch: 13\tLoss: 0.120767\tTPR: 98.31223628691983\tTNR: 97.75848665457373\tTime: 3.010879\n","Val_loss: 0.201779\tTPR: 93.53448275862068\tTNR: 97.64492753623189\tTime: 17.813791\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 147.309641122818\n","Train Epoch: 14\tLoss: 0.134062\tTPR: 96.41350210970464\tTNR: 97.66778958279347\tTime: 3.020131\n","Val_loss: 0.194415\tTPR: 94.82758620689656\tTNR: 97.47670807453416\tTime: 17.772314\n","\n","Validation loss decreased (0.196883 --> 0.194415).  Saving model\n","\n","Epoch Duration 151.06369280815125\n","Train Epoch: 15\tLoss: 0.107765\tTPR: 99.36708860759494\tTNR: 97.83622700181395\tTime: 3.525719\n","Val_loss: 0.201683\tTPR: 94.18103448275862\tTNR: 97.51552795031056\tTime: 17.934536\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 148.8147304058075\n","Train Epoch: 16\tLoss: 0.114333\tTPR: 98.94514767932489\tTNR: 97.7844001036538\tTime: 3.009427\n","Val_loss: 0.186166\tTPR: 95.90517241379311\tTNR: 97.9296066252588\tTime: 17.855729\n","\n","Validation loss decreased (0.194415 --> 0.186166).  Saving model\n","\n","Epoch Duration 151.14599752426147\n","Train Epoch: 17\tLoss: 0.117466\tTPR: 98.31223628691983\tTNR: 98.03057786991448\tTime: 3.478662\n","Val_loss: 0.197978\tTPR: 94.61206896551724\tTNR: 97.851966873706\tTime: 17.809079\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 150.04969358444214\n","Train Epoch: 18\tLoss: 0.114130\tTPR: 97.46835443037975\tTNR: 98.03057786991448\tTime: 3.034319\n","Val_loss: 0.214099\tTPR: 93.96551724137932\tTNR: 97.9296066252588\tTime: 17.874027\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 148.05864572525024\n","Train Epoch: 19\tLoss: 0.101144\tTPR: 99.57805907172997\tTNR: 98.22492873801502\tTime: 3.009350\n","Val_loss: 0.177553\tTPR: 94.39655172413794\tTNR: 97.72256728778468\tTime: 17.851259\n","\n","Validation loss decreased (0.186166 --> 0.177553).  Saving model\n","\n","Epoch Duration 150.98239302635193\n","Train Epoch: 20\tLoss: 0.109366\tTPR: 98.94514767932489\tTNR: 97.97875097175434\tTime: 3.066519\n","Val_loss: 0.182859\tTPR: 95.6896551724138\tTNR: 97.98136645962732\tTime: 17.880443\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 148.69458174705505\n","Train Epoch: 21\tLoss: 0.103103\tTPR: 99.15611814345992\tTNR: 98.16014511531485\tTime: 3.027503\n","Val_loss: 0.191193\tTPR: 96.12068965517241\tTNR: 97.94254658385093\tTime: 17.883188\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 147.90620136260986\n","Train Epoch: 22\tLoss: 0.111270\tTPR: 98.52320675105484\tTNR: 98.01762114537445\tTime: 3.023898\n","Val_loss: 0.199787\tTPR: 94.61206896551724\tTNR: 97.95548654244305\tTime: 17.892533\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 148.20705127716064\n","Train Epoch: 23\tLoss: 0.100307\tTPR: 99.15611814345992\tTNR: 98.18605856439491\tTime: 3.053497\n","Val_loss: 0.209790\tTPR: 93.10344827586206\tTNR: 98.07194616977226\tTime: 17.819815\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 147.69262409210205\n","Train Epoch: 24\tLoss: 0.097858\tTPR: 98.94514767932489\tTNR: 98.50997667789582\tTime: 3.009821\n","Val_loss: 0.239449\tTPR: 94.18103448275862\tTNR: 97.9296066252588\tTime: 17.894863\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 148.14625906944275\n","Train Epoch: 25\tLoss: 0.098964\tTPR: 99.36708860759494\tTNR: 98.21197201347499\tTime: 3.022038\n","Val_loss: 0.203060\tTPR: 95.04310344827587\tTNR: 98.18840579710145\tTime: 17.962489\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 147.74311637878418\n","Train Epoch: 26\tLoss: 0.096480\tTPR: 98.94514767932489\tTNR: 98.52293340243587\tTime: 3.016855\n","Val_loss: 0.214644\tTPR: 95.47413793103449\tTNR: 98.08488612836439\tTime: 18.409420\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 148.2943742275238\n","Train Epoch: 27\tLoss: 0.098465\tTPR: 99.36708860759494\tTNR: 98.36745270795542\tTime: 3.025513\n","Val_loss: 0.234356\tTPR: 94.18103448275862\tTNR: 98.08488612836439\tTime: 17.905777\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 147.77407240867615\n","Train Epoch: 28\tLoss: 0.093388\tTPR: 99.36708860759494\tTNR: 98.38040943249547\tTime: 3.010049\n","Val_loss: 0.234740\tTPR: 94.18103448275862\tTNR: 98.04606625258799\tTime: 17.989269\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 147.74349093437195\n","Train Epoch: 29\tLoss: 0.097248\tTPR: 99.15611814345992\tTNR: 98.40632288157553\tTime: 3.075285\n","Val_loss: 0.247541\tTPR: 92.24137931034483\tTNR: 98.14958592132506\tTime: 17.860280\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 147.94385981559753\n","Train Epoch: 30\tLoss: 0.098213\tTPR: 98.73417721518987\tTNR: 98.5358901269759\tTime: 3.025513\n","Val_loss: 0.213462\tTPR: 93.53448275862068\tTNR: 98.34368530020704\tTime: 17.872386\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 147.67709040641785\n","Train Epoch: 31\tLoss: 0.090857\tTPR: 99.36708860759494\tTNR: 98.70432754599638\tTime: 3.024261\n","Val_loss: 0.193828\tTPR: 94.39655172413794\tTNR: 98.2531055900621\tTime: 17.862131\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 147.8956344127655\n","Train Epoch: 32\tLoss: 0.089465\tTPR: 100.0\tTNR: 98.61363047421612\tTime: 3.018665\n","Val_loss: 0.221128\tTPR: 93.31896551724138\tTNR: 98.04606625258799\tTime: 17.893400\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 147.54414129257202\n","Train Epoch: 33\tLoss: 0.089113\tTPR: 99.78902953586498\tTNR: 98.58771702513604\tTime: 3.019548\n","Val_loss: 0.217211\tTPR: 95.04310344827587\tTNR: 98.17546583850931\tTime: 17.817874\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 147.8223066329956\n","Train Epoch: 34\tLoss: 0.090120\tTPR: 99.36708860759494\tTNR: 98.44519305519565\tTime: 3.028580\n","Val_loss: 0.254160\tTPR: 93.96551724137932\tTNR: 98.26604554865425\tTime: 18.021020\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 147.54153394699097\n","Train Epoch: 35\tLoss: 0.091077\tTPR: 99.78902953586498\tTNR: 98.56180357605598\tTime: 2.991802\n","Val_loss: 0.185697\tTPR: 94.61206896551724\tTNR: 98.0072463768116\tTime: 17.868250\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 147.70053005218506\n","Train Epoch: 36\tLoss: 0.096298\tTPR: 99.36708860759494\tTNR: 98.47110650427572\tTime: 3.022747\n","Val_loss: 0.199882\tTPR: 94.61206896551724\tTNR: 98.42132505175984\tTime: 17.927749\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 147.6356086730957\n","Train Epoch: 37\tLoss: 0.092800\tTPR: 98.10126582278481\tTNR: 98.71728427053641\tTime: 3.084743\n","Val_loss: 0.204775\tTPR: 93.10344827586206\tTNR: 98.12370600414079\tTime: 17.836844\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 147.87592720985413\n","Train Epoch: 38\tLoss: 0.088486\tTPR: 99.78902953586498\tTNR: 98.71728427053641\tTime: 3.024619\n","Val_loss: 0.258559\tTPR: 92.45689655172413\tTNR: 98.18840579710145\tTime: 17.848771\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 147.86519122123718\n","Train Epoch: 39\tLoss: 0.086727\tTPR: 98.94514767932489\tTNR: 98.71728427053641\tTime: 3.021049\n","Val_loss: 0.265918\tTPR: 91.59482758620689\tTNR: 98.27898550724638\tTime: 17.857206\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eobXF2Zmz5IJ"},"source":[""],"execution_count":null,"outputs":[]}]}