{"cells":[{"cell_type":"markdown","metadata":{"id":"FVe4m9BcQgv7"},"source":["# Directory"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14763,"status":"ok","timestamp":1637581728553,"user":{"displayName":"Yong Kuk Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05925217294532758280"},"user_tz":-60},"id":"bHfztK9GQk94","outputId":"0fa196b2-e47e-4988-d60d-50a7db11b50b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":342,"status":"ok","timestamp":1637581730704,"user":{"displayName":"Yong Kuk Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05925217294532758280"},"user_tz":-60},"id":"uyaLNUQ3Qnnh","outputId":"6ac4cf71-7474-403f-8379-71af1ecdfe42"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Deep_learning/Deep Learning\n"]}],"source":["%cd /content/drive/MyDrive/Deep_learning/Deep\\ Learning"]},{"cell_type":"markdown","metadata":{"id":"l-6pQj7zQoc9"},"source":["# Libararies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5g_eD6eiQsUS"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, IterableDataset\n","\n","# calculate train time, writing train data to files etc.\n","import os\n","import sys\n","import logging\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","\n","from random import randint\n","from collections import defaultdict\n","from pathlib import Path\n","from scipy import signal\n","from scipy.signal import find_peaks\n","from scipy.interpolate import interp1d,UnivariateSpline\n","from sklearn.preprocessing import MinMaxScaler\n","from numpy import NaN, Inf, arange, isscalar, asarray, array\n","\n","import pdb"]},{"cell_type":"markdown","metadata":{"id":"O4v4l7XuQ019"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YrNpeb2GQ2KS"},"outputs":[],"source":["class CoolDataset(IterableDataset):\n","\n","    def __init__(self, dir_path: str, seq_length: str, input_size: str, samples_per_events: str, convolution=True):\n","\n","        # Opens .csv file and read headers\n","        # Needs to decide what inputs to have and work on HS or FO\n","\n","        super().__init__()\n","\n","        self.files = tuple(Path(dir_path).glob(\"**/*.csv\"))\n","        self.seq_length = seq_length\n","        self.input_size = input_size\n","        self.SAMPLES_PER_EVENT = samples_per_events\n","        self.window = signal.gaussian(8, std=3)\n","        self.convolution = convolution\n","        self.scaler = MinMaxScaler(feature_range=(0,1))\n","\n","        assert seq_length % 2 == 0, \"Please pass an even seq length\"\n","\n","    def __iter__(self):\n","\n","        # Initialise Counter for events and files\n","        self.file_nr = 0\n","        self.event_in_file = 0\n","        self._sample_nr = 0\n","\n","        return self\n","\n","    def __next__(self):\n","        # Reads the current file and looks for event\n","        df, fname = self.read_file(self.files[self.file_nr])  # could be cached so you dont read it anew every iteration\n","        events = df[df['FS'] == 1]  # true where an event occurs, false everywhere else, use as mask\n","\n","        if events.shape[0] \u003e 0:\n","            if self._sample_nr \u003c self.SAMPLES_PER_EVENT:\n","                # just give back the current event again, with different sampling, until we have generated\n","                # SAMPLES_PER_EVENT such samples\n","\n","                event_frame = events.iloc[self.event_in_file].name\n","                indx_data, input_data, output_data = self.sample_seq_around_event_frame(df, event_frame)\n","                self._sample_nr += 1\n","            else:\n","                self.event_in_file += 1  # work on the next event in this file\n","                self._sample_nr = 0  # reset for the next event\n","\n","                # check whether we are done with this file\n","                # otherwise we return the next event on the beginning of the next iteration\n","                if self.event_in_file \u003e= len(events):\n","                    self.file_nr += 1\n","                    # If there still are files to run, it resets the variables\n","                    if self.file_nr \u003c len(self.files):\n","                        logging.info(\"File is complete. Going to new file...\")\n","                        self.event_in_file = 0\n","                        self._sample_nr = 0\n","                        return next(self)\n","                    else:\n","                        # processed the last file, we are done\n","                        logging.info(\"File is complete. All files done. Stopping...\")\n","                        raise StopIteration\n","                elif self.event_in_file \u003c len(events):\n","                    event_frame = events.iloc[self.event_in_file].name\n","                    indx_data, input_data, output_data = self.sample_seq_around_event_frame(df, event_frame)\n","                    self._sample_nr += 1\n","        else:\n","            logging.info(\"No events detected\")\n","            self.file_nr += 1\n","            self.event_in_file = 0\n","            self._sample_nr = 0\n","            return next(self)\n","\n","        return indx_data, input_data, output_data, fname\n","\n","    def sample_seq_around_event_frame(self, df, event_idx):\n","\n","        if event_idx \u003e= 4:\n","            start_idx = event_idx - randint(4, self.seq_length / 7.5)\n","            if start_idx \u003e 0:\n","                end_idx = start_idx + self.seq_length\n","                if end_idx \u003c= len(df):\n","                    indx = df.iloc[start_idx:end_idx]['ID']\n","                    input = df.iloc[start_idx:end_idx, 1:self.input_size + 1]\n","                    output = df.iloc[start_idx:end_idx]['FS']\n","                elif end_idx \u003e len(df):\n","                    end_idx = len(df)\n","                    start_idx = end_idx - self.seq_length\n","                    indx = df.iloc[start_idx:end_idx]['ID']\n","                    input = df.iloc[start_idx:end_idx, 1:self.input_size + 1]\n","                    output = df.iloc[start_idx:end_idx]['FS']\n","            elif start_idx \u003c= 4:\n","                start_idx = event_idx\n","                end_idx = start_idx + self.seq_length\n","                indx = df.iloc[start_idx:end_idx]['ID']\n","                input = df.iloc[start_idx:end_idx, 1:self.input_size + 1]\n","                output = df.iloc[start_idx:end_idx]['FS']\n","                if end_idx \u003c= len(df):\n","                    indx = df.iloc[start_idx:end_idx]['ID']\n","                    input = df.iloc[start_idx:end_idx, 1:self.input_size + 1]\n","                    output = df.iloc[start_idx:end_idx]['FS']\n","                elif end_idx \u003e len(df):\n","                    end_idx = len(df)\n","                    start_idx = end_idx - self.seq_length\n","                    indx = df.iloc[start_idx:end_idx]['ID']\n","                    input = df.iloc[start_idx:end_idx, 1:self.input_size + 1]\n","                    output = df.iloc[start_idx:end_idx]['FS']\n","\n","        if self.convolution:\n","            output = signal.convolve(output, self.window, mode='same')\n","        input = self.scaler.fit_transform(input)\n","        indx = indx.to_numpy()\n","        \n","        assert input.shape[0] == output.shape[0] == self.seq_length\n","        return torch.tensor(indx),torch.tensor(input), torch.tensor(output)\n","\n","    def read_file(self, f):\n","        df = pd.read_csv(open(f, \"r\"))\n","        fname = os.path.basename(f)\n","        if fname[0:2] == 'RT':\n","            df = df.drop([#'ID',\n","                          'class',\n","                          #'RTOE_X', 'RTOE_Y', 'RTOE_Z', 'V_RTOE_X', 'V_RTOE_Y', 'V_RTOE_Z',\n","                          'RHLX_X', 'RHLX_Y', 'RHLX_Z', 'V_RHLX_X', 'V_RHLX_Y', 'V_RHLX_Z',\n","                          #'RHEE_X', 'RHEE_Y', 'RHEE_Z', 'V_RHEE_X', 'V_RHEE_Y', 'V_RHEE_Z',\n","                          'RPMT5_X', 'RPMT5_Y', 'RPMT5_Z', 'V_RPMT5_X', 'V_RPMT5_Y', 'V_RPMT5_Z'\n","                          ], axis=1)\n","        elif fname[0:2] == 'LT':\n","            df = df.drop([#'ID',\n","                          'class',\n","                          #'LTOE_X', 'LTOE_Y', 'LTOE_Z', 'V_LTOE_X', 'V_LTOE_Y', 'V_LTOE_Z',\n","                          'LHLX_X', 'LHLX_Y', 'LHLX_Z', 'V_LHLX_X', 'V_LHLX_Y', 'V_LHLX_Z',\n","                          #'LHEE_X', 'LHEE_Y', 'LHEE_Z', 'V_LHEE_X', 'V_LHEE_Y', 'V_LHEE_Z',\n","                          'LPMT5_X', 'LPMT5_Y', 'LPMT5_Z', 'V_LPMT5_X', 'V_LPMT5_Y', 'V_LPMT5_Z',\n","                          ], axis=1)\n","        return df, fname"]},{"cell_type":"markdown","metadata":{"id":"L3zHwEfZQ4Px"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LjBwE7oPQ5Gv"},"outputs":[],"source":["class Network(nn.Module):\n","    # TO DO\n","    def __init__(self, config):\n","        super(Network, self).__init__()\n","\n","        # Model construct Configuration\n","        self.batch_size  = config.batch_size\n","        self.num_layers  = config.num_layers\n","        self.hidden_size = config.hidden_size\n","        self.device      = config.device\n","\n","        self.lstm = nn.LSTM(config.input_size, self.hidden_size, self.num_layers, dropout=config.drop_out, batch_first=True,\n","                            bidirectional=True)\n","        self.linear = nn.Linear(self.hidden_size * 2, config.output_size, bias=True)\n","        torch.nn.init.xavier_uniform_(self.linear.weight)\n","\n","    def forward(self, x):\n","        hidden, cell = self.init_hidden()\n","        out, _ = self.lstm(x, (hidden, cell))\n","        logits = self.linear(out)\n","\n","        return logits[:, :, -1]\n","\n","    def init_hidden(self):\n","        weight = next((self.parameters())).data\n","        hidden, cell = (weight.new(self.num_layers * 2, self.batch_size, self.hidden_size).zero_().to(self.device),\n","                        weight.new(self.num_layers * 2, self.batch_size, self.hidden_size).zero_().to(self.device))\n","        return hidden, cell"]},{"cell_type":"markdown","metadata":{"id":"Oe0Yx2HjRBw2"},"source":["# Peak Detection"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rSt3MhKdRC5O"},"outputs":[],"source":["class peak_detection:\n","\n","    def peak_comp(self, annotated, predicted, filename):\n","        dist = []\n","\n","        if len(predicted) == 0 and len(annotated) == 0:\n","            print(f\"{filename}_no events detection\")\n","            return -1\n","        elif len(annotated == 0):\n","            pdb.set_trace()\n","\n","            return(len(annotated))\n","        elif len(predicted) == 0:\n","            return(len(predicted))\n","        for a in predicted:\n","            x = (np.abs(annotated -a) \u003c 16)\n","            dist = dist + x\n","            pred_peaks_close_to_true += x.sum()\n","            pred_peaks_not_close_to_true += len(x) - x\n","        if not len(dist):\n","            print(f\"{filename}\")\n","            return -1\n","        return min(dist)\n","\n","    def peakdetect(self, v, delta, x=None):\n","        maxtab = []\n","        mintab = []\n","\n","        if x is None:\n","            x = arange(len(v))\n","\n","        v = asarray(v)\n","\n","        if len(v) != len(x):\n","            sys.exit('Input vectors v and x must have same length')\n","\n","        if not isscalar(delta):\n","            sys.exit('Input argument delta must be a scalar')\n","\n","        if delta \u003c= 0:\n","            sys.exit('Input argument delta must be positive')\n","\n","        mn, mx = Inf, -Inf\n","        mnpos, mxpos = NaN, NaN\n","\n","        lookformax = True\n","\n","        for i in arange(len(v)):\n","            this = v[i]\n","            if this \u003e mx:\n","                mx = this\n","                mxpos = x[i]\n","            if this \u003c mn:\n","                mn = this\n","                mnpos = x[i]\n","\n","            if lookformax:\n","                if this \u003c mx - delta:\n","                    maxtab.append((mxpos, mx))\n","                    mn = this\n","                    mnpos = x[i]\n","                    lookformax = False\n","            else:\n","                if this \u003e mn + delta:\n","                    mintab.append((mnpos, mn))\n","                    mx = this\n","                    mxpos = x[i]\n","                    lookformax = True\n","\n","        return array(maxtab), array(mintab)\n","\n","    def eval_prediction(self, y_pred, y_true, filename, i, plot=False, shift=0):\n","\n","        sdist = []\n","\n","        # Interpolating the predicted signal\n","        y_pred_interp1d = interp1d(self.x, y_pred)\n","        y_pred_final = y_pred_interp1d(self.xnew)\n","\n","        try:\n","\n","            # peak_detection\n","            peakind_true,_ = find_peaks(y_true, height=0.5)\n","            peakind,_ = find_peaks(y_pred_final, height=0.5)\n","\n","            if 'peakind' in locals():\n","\n","                # peak_detection\n","                peakind_pred = [x for x in peakind]\n","                peakind_pred = self.xnew[peakind_pred]\n","\n","\n","            if any(peakind_pred):\n","                for k in peakind_pred:\n","                    if plot:\n","                        plt.axvline(x=k)\n","\n","            sdist.append(self.peak_comp(self, peakind_true, [k + shift for k in peakind_pred], filename[:-4]))\n","\n","            if plot:\n","                plt.plot(y_pred)\n","                plt.plot(y_true)\n","                plt.title(f\"True vs Predicted {filename[:-4]} - {i}\")\n","                axes = plt.gca()\n","                axes.set_xlim([0, y_true.shape[0]])\n","                my_file = f\"{filename[:-4]} - {i}\"\n","                plt.savefig(os.path.join(self.png_dir, my_file))\n","                plt.close()\n","\n","        except:\n","            print(f\"{filename} - No Plots, please check the plots\")\n","            edist = -1\n","            sdist.append(edist)\n","\n","        return sdist\n","\n","    def plot_stats(self, sdist):\n","        plt.title(\"Distance Error Histogram\")\n","        plt.hist(sdist, 100, [0, 100])\n","        filtered = [k for k in sdist if k \u003e= 0]\n","\n","        def off_by(threshold, filtered):\n","            ob = [k for k in filtered if k \u003c= threshold]\n","            nel = float(len(filtered))\n","            print(\"\u003c= %d: %f\" % (threshold, len(ob) / float(nel)))\n","\n","        print(\"Error distribution:\")\n","        off_by(1, filtered)\n","        off_by(3, filtered)\n","        off_by(5, filtered)\n","        off_by(10, filtered)\n","        off_by(60, filtered)\n","        print(\"Mean distance: %f\" % (np.mean(filtered)))\n","        mean_distance = [np.mean(filtered)]\n","        plt.legend(mean_distance)\n","        plt.savefig(os.path.join(self.png_dir, f\"{self.globaliter}_distance_error.png\"))\n","        plt.close()\n","        return np.mean(filtered)"]},{"cell_type":"markdown","metadata":{"id":"nuYhU-MyRKrP"},"source":["# Trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jhkdEc4SQZTE"},"outputs":[],"source":["class Trainer:\n","\n","    def __init__(self, model, config, name):\n","\n","        # System configuration\n","        self.device = config.device\n","\n","        # Model Construction\n","        self.model = Network(config).float()\n","        self.model.load_state_dict(model)\n","        self.model.to(self.device)\n","        print(self.model)\n","\n","        # Peak detection and Evaluation\n","        self.eval_prediction = peak_detection.eval_prediction\n","        self.peak_comp = peak_detection.peak_comp\n","        self.peak_detect = peak_detection.peakdetect\n","        self.plot_stats = peak_detection.plot_stats\n","        self.x = np.linspace(0, 150, num=150, endpoint=True)\n","        self.xnew = np.linspace(0, 150, num=512, endpoint=True)\n","        self.weight = np.ones(150) * 12\n","        self.output_dir = config.output_dir\n","        self.png_dir = config.png_dir\n","        self.roc_dir = config.roc_dir\n","        self.globaliter = 0\n","\n","        # DataLoader\n","        self.test_loader = DataLoader(\n","            CoolDataset(r'/content/drive/MyDrive/Deep_learning/Deep Learning/Data/iteration3/Test'f\"/{name}\", config.seq_length,config.input_size,config.samples_per_event, convolution=True), batch_size=config.batch_size, drop_last=True,\n","            shuffle=False)\n","\n","    def test(self):\n","        self.model.eval()\n","        with torch.no_grad():\n","            for indx, data, target, filename in self.test_loader:\n","\n","                error_dist = []\n","                filename_end = []\n","                TPR_temp_final = []\n","                TNR_temp_final = []\n","                data, target = data.to(self.device), target.to(self.device)\n","\n","                predictions = self.model(data.float())\n","                pred = torch.sigmoid(predictions)\n","\n","                correct_indx_positive = pred[target \u003e 0.5]  # Should have batch_size * 1's\n","                correct_indx_negative = pred[target \u003c= 0.5]  # Should have (batch_size*seq_length-batch_size) * 0'\n","\n","                TPR_temp = len(correct_indx_positive[correct_indx_positive \u003e 0.5]) / len( correct_indx_positive)\n","                TNR_temp = len(correct_indx_negative[correct_indx_negative \u003c= 0.5]) / len( correct_indx_negative)\n","\n","                TPR_temp = TPR_temp * 100\n","                TNR_temp = TNR_temp * 100\n","                # TPR_temp_final.append(TPR_temp)\n","                # TNR_temp_final.append(TNR_temp)\n","                \n","                for i in range(0, pred.shape[0]):\n","\n","                    dist = (self.eval_prediction(self, pred[i], target[i], filename[i], i))\n","                    for j in range(0, len(dist)):\n","                        error_dist.append(dist[j])\n","                        filename_end.append(filename[i])\n","\n","                dist_file  = np.column_stack((error_dist, filename_end))\n","\n","                mean_dist  = self.plot_stats(self, error_dist)\n","\n","                mean_name_dist  = \"mean_dist\"\n","\n","                mean_dist_file  = np.column_stack((mean_dist, mean_name_dist))\n","\n","                dist_file  = np.row_stack((dist_file, mean_dist_file))\n","\n","                df_dist = pd.DataFrame(data=dist_file, )\n","\n","                df_dist.columns  = [\"Error in distance\", \"FileName\"]\n","\n","                df_dist.to_csv(os.path.join(self.output_dir, f\"{self.globaliter}_error_file.csv\"))\n","\n","                # for i in range(0, predictions.shape[0]):\n","                #     indx_pred_target = np.transpose(np.row_stack((indx[i], pred[i], target[i])))\n","                #     df = pd.DataFrame(data=indx_pred_target, )\n","                #     df.columns = [\"indx\", \"pred\", \"true_output\"]\n","                #     df.to_csv(os.path.join(self.output_dir, f\"{filename[i]}\"))\n","\n","                self.globaliter += 1\n","            return TPR_temp, TNR_temp"]},{"cell_type":"markdown","metadata":{"id":"5A-IrpodRNQf"},"source":["# Main"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"VI9DAKmmRPwl"},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on the CPU\n","IC-256-HS-5-NL-0.001-LR-0.3-DO-1-FScheckpoint.pt\n","Network(\n","  (lstm): LSTM(12, 256, num_layers=5, batch_first=True, dropout=0.3, bidirectional=True)\n","  (linear): Linear(in_features=512, out_features=1, bias=True)\n",")\n"]},{"name":"stderr","output_type":"stream","text":["\n","PYDEV DEBUGGER WARNING:\n","sys.settrace() should not be used when the debugger is being used.\n","This may cause the debugger to stop working correctly.\n","If this is needed, please check: \n","http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n","to see how to restore the debug tracing back correctly.\n","Call Location:\n","  File \"/usr/lib/python3.7/bdb.py\", line 332, in set_trace\n","    sys.settrace(self.trace_dispatch)\n","\n"]},{"name":"stdout","output_type":"stream","text":["\u003e \u003cipython-input-8-536421b385f7\u003e(12)peak_comp()\n","-\u003e return(len(annotated))\n","1\n","*** SyntaxError: invalid syntax\n","array([12])\n","1\n","1\n","--KeyboardInterrupt--\n"]},{"name":"stderr","output_type":"stream","text":["\n","PYDEV DEBUGGER WARNING:\n","sys.settrace() should not be used when the debugger is being used.\n","This may cause the debugger to stop working correctly.\n","If this is needed, please check: \n","http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n","to see how to restore the debug tracing back correctly.\n","Call Location:\n","  File \"/usr/lib/python3.7/bdb.py\", line 357, in set_quit\n","    sys.settrace(None)\n","\n"]},{"name":"stdout","output_type":"stream","text":["RT_EVT059_09.csv - No Plots, please check the plots\n","\u003e \u003cipython-input-8-536421b385f7\u003e(12)peak_comp()\n","-\u003e return(len(annotated))\n","RT_EVT059_09.csv - No Plots, please check the plots\n","\u003e \u003cipython-input-8-536421b385f7\u003e(12)peak_comp()\n","-\u003e return(len(annotated))\n","RT_EVT060_12.csv - No Plots, please check the plots\n","\u003e \u003cipython-input-8-536421b385f7\u003e(12)peak_comp()\n","-\u003e return(len(annotated))\n","RT_EVT060_12.csv - No Plots, please check the plots\n","\u003e \u003cipython-input-8-536421b385f7\u003e(12)peak_comp()\n","-\u003e return(len(annotated))\n","RT_EVT059_07.csv - No Plots, please check the plots\n","\u003e \u003cipython-input-8-536421b385f7\u003e(12)peak_comp()\n","-\u003e return(len(annotated))\n","--KeyboardInterrupt--\n","--KeyboardInterrupt--\n","--KeyboardInterrupt--\n","RT_EVT059_07.csv - No Plots, please check the plots\n","\u003e \u003cipython-input-8-536421b385f7\u003e(12)peak_comp()\n","-\u003e return(len(annotated))\n","RT_EVT061_13.csv - No Plots, please check the plots\n","\u003e \u003cipython-input-8-536421b385f7\u003e(12)peak_comp()\n","-\u003e return(len(annotated))\n","RT_EVT061_13.csv - No Plots, please check the plots\n","\u003e \u003cipython-input-8-536421b385f7\u003e(12)peak_comp()\n","-\u003e return(len(annotated))\n","RT_EVT061_06.csv - No Plots, please check the plots\n","\u003e \u003cipython-input-8-536421b385f7\u003e(12)peak_comp()\n","-\u003e return(len(annotated))\n"]}],"source":["class Config:\n","\n","    def __init__(self, **kwargs):\n","        for key, value in kwargs.items():\n","            setattr(self, key, value)\n","\n","def main(loaded_model, model_config, name):\n","\n","    trainer = Trainer(loaded_model, model_config, name)\n","    TPR_temp, TNR_temp = trainer.test()\n","    return TPR_temp, TNR_temp\n","\n","if __name__ == '__main__':\n","\n","    if torch.cuda.is_available():\n","        device = torch.device(\"cuda\")\n","        print(\"Running on the GPU\")\n","    else:\n","        device = torch.device(\"cpu\")\n","        print(\"Running on the CPU\")\n","\n","    # Calling Models\n","    names    = [\"ForeFoot\",\"MidFoot\",\"Heel\"]\n","\n","    model_dir = r'/content/drive/MyDrive/Deep_learning/Deep Learning/Results/LSTM/IC/2markers/TOEHEE/v1/models'\n","    model_files = tuple(Path(f\"{model_dir}/CheckPoint_DS/\").glob(\"**/*pt\"))\n","\n","    for name in names:\n","      ROC_Final = []\n","      TPR_Final = []\n","      TNR_Final = []\n","      roc_dir       = f\"{model_dir}/roc_TS/{name}/\"\n","      if not os.path.exists(roc_dir):\n","          os.makedirs(roc_dir)\n","\n","      for i in range(len(model_files)):\n","          model_name = os.path.basename((model_files[i]))\n","          loaded_model = torch.load(f\"{model_dir}/CheckPoint_DS/\" + model_name,map_location=torch.device(device))\n","\n","          output_dir    = f\"{model_dir}/FPR/{name}/Results_final{i}/csv\"\n","          png_dir       = f\"{model_dir}/FPR/{name}/Results_final{i}/png\"\n","          print(model_name)\n","\n","          # Directory Settings\n","          if not os.path.exists(output_dir):\n","              os.makedirs(output_dir)\n","              os.makedirs(png_dir)\n","\n","          model_config = Config(\n","\n","              # General Configuration\n","              device=device,\n","              batch_size=32,\n","              seq_length=150,\n","              samples_per_event = 1,\n","              output_size = 1,\n","\n","              # LSTM\n","              input_size=12,\n","              hidden_size=256,\n","              num_layers=5,\n","              lr=0.001,\n","              drop_out=0.3,\n","\n","              output_dir=output_dir,\n","              png_dir=png_dir,\n","              roc_dir = roc_dir\n","          )\n","\n","          # ROC = \n","          TPR,TNR = main(loaded_model, model_config, name)\n","          TPR_Final.append(TPR)\n","          TNR_Final.append(TNR)\n","      ROC = pd.DataFrame({f\"TPR_{name}\": TPR_Final,f\"TNR_{name}\":TNR_Final})\n","      ROC.to_csv(os.path.join(roc_dir, f\"{name}_ROC.csv\"),index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_tCQeG-q__-w"},"outputs":[],"source":[""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOQTQVSDyUgi3/q0NJp2z0x","collapsed_sections":[],"machine_shape":"hm","name":"IC_3_TestingModel.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}