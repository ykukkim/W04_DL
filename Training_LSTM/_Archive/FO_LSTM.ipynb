{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FO_LSTM","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOFhlaMJkRyCGufrngzTSL5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"oaAC0JBCN02j","colab_type":"text"},"source":["# Google Drive Mount\n"]},{"cell_type":"code","metadata":{"id":"LpqemH7GOMqY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600926641956,"user_tz":-120,"elapsed":33813,"user":{"displayName":"Yong Kuk Kim","photoUrl":"","userId":"05925217294532758280"}},"outputId":"eecc8904-29e4-4c83-a8a3-123389ce7440"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OnXtG1mqN31P","colab_type":"text"},"source":["# Direcoty & Libraries"]},{"cell_type":"code","metadata":{"id":"3-rgOqyrOZ-X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600926655547,"user_tz":-120,"elapsed":633,"user":{"displayName":"Yong Kuk Kim","photoUrl":"","userId":"05925217294532758280"}},"outputId":"28e10b3c-bb60-497b-bfd3-ae3dbaf8ed85"},"source":["%cd /content/drive/My\\ Drive/Colab\\ Notebooks"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IUH1g9xyOaba","colab_type":"code","colab":{}},"source":["#Importing Libraries and Packages\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, IterableDataset\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# calculate train time, writing train data to files etc.\n","import os \n","import logging\n","import pandas as pd\n","import numpy as np\n","import time\n","from pathlib import Path\n","from random import randint\n","from scipy import signal\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc\n","\n","import pdb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1--dGDwEN-P4","colab_type":"text"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"id":"vEx9hj5FOdcE","colab_type":"code","colab":{}},"source":["# Data split\n","class Split_data:\n","    def __init__(self, dir_path: str):\n","\n","        self.files = tuple(Path(dir_path).glob(\"**/*.csv\"))\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def splitset(self,split_ratio,random_seed,shuffle_dataset = True):\n","        dataset_size = len(self.files)\n","        indices = list(range(dataset_size))\n","        split = int(np.floor(split_ratio * len(self.files)))\n","        if shuffle_dataset:\n","            np.random.seed(random_seed)\n","            np.random.shuffle(indices)\n","        train_indices, val_indices = indices[split:], indices[:split]\n","        return train_indices,val_indices\n","\n","# Extracting data from csv files\n","class CoolDataset(IterableDataset):\n","\n","    def __init__(self, dir_path: str, seq_length: str, input_size: str, samples_per_events: str, indices, convolution=False):\n","\n","        super().__init__()\n","        self.files = tuple(Path(dir_path).glob(\"**/*.csv\"))\n","        self.indices = indices\n","        self.seq_length = seq_length\n","        self.input_size = input_size\n","        self.SAMPLES_PER_EVENT = samples_per_events\n","        self.window = signal.gaussian(8, std=3)\n","        self.convolution = convolution\n","\n","        assert seq_length % 2 == 0, \"Please pass an even seq length\"\n","\n","    def __iter__(self):\n","\n","        # Initialise Counter for events and files\n","        self.file_nr = 0\n","        self.event_in_file = 0\n","        self._sample_nr = 0\n","\n","        return self\n","\n","    def __next__(self):\n","        # Reads the current file and looks for event\n","        df = self.read_file(self.files[self.indices[self.file_nr]])  # could be cached so you dont read it anew every iteration\n","        events = df[df[\"FO\"] ==1]\n","        if events.shape[0] > 0:\n","            if self._sample_nr < self.SAMPLES_PER_EVENT:\n","                # just give back the current event again, with different sampling, until we have generated\n","                # SAMPLES_PER_EVENT such samples\n","                # pdb.set_trace()\n","                if self._sample_nr == 0:\n","                    event_frame = events.iloc[self.event_in_file].name\n","                if self._sample_nr == 1:\n","                    event_frame = events.iloc[self.event_in_file].name\n","                if self._sample_nr == 2:\n","                    event_frame = events.iloc[self.event_in_file].name\n","                if self._sample_nr == 3:\n","                    event_frame = events.iloc[self.event_in_file].name\n","                if self._sample_nr == 4:\n","                    event_frame = events.iloc[self.event_in_file].name + 1\n","                if self._sample_nr == 5:\n","                    event_frame = events.iloc[self.event_in_file].name + 1\n","                if self._sample_nr == 6:\n","                    event_frame = events.iloc[self.event_in_file].name - 1\n","                if self._sample_nr == 7:\n","                    event_frame = events.iloc[self.event_in_file].name - 1\n","                if self._sample_nr == 8:\n","                    event_frame = events.iloc[self.event_in_file].name - 2\n","                if self._sample_nr == 9:\n","                    event_frame = events.iloc[self.event_in_file].name + 2\n","                 \n","                input_data, output_data = self.sample_seq_around_event_frame(df, event_frame)\n","                self._sample_nr += 1\n","            # else:\n","            elif self._sample_nr == self.SAMPLES_PER_EVENT:\n","                \n","                # pdb.set_trace()\n","                self.event_in_file += 1  # work on the next event in this file\n","                self._sample_nr = 0  # reset for the next event\n","                \n","                # check whether we are done with this file\n","                # otherwise we return the next event on the beginning of the next iteration\n","                if self.event_in_file >= len(events):\n","                    self.file_nr += 1\n","                    # If there still are files to run, it resets the variables\n","                    if self.file_nr < len(self.indices):\n","                        # pdb.set_trace()\n","                        logging.info(\"File is complete. Going to new file...\")\n","                        self.event_in_file = 0\n","                        self._sample_nr = 0\n","                        return next(self)\n","                    else:\n","                        # processed the last file, we are done\n","                        logging.info(\"File is complete. All files done. Stopping...\")\n","                        raise StopIteration\n","                elif self.event_in_file < len(events):\n","\n","                    # pdb.set_trace()\n","\n","                    event_frame = events.iloc[self.event_in_file].name\n","                    input_data, output_data = self.sample_seq_around_event_frame(df, event_frame)\n","                    self._sample_nr += 1\n","        else:\n","            logging.info(\"No events detected\")\n","            # pdb.set_trace()\n","            self.file_nr += 1\n","            self.event_in_file = 0\n","            self._sample_nr = 0\n","            return next(self)\n","\n","        return input_data, output_data\n","\n","    def sample_seq_around_event_frame(self, df, event_idx):\n","\n","        # Returns inputs with event data\n","        start_idx = event_idx - randint(10, self.seq_length / 2)\n","        if start_idx > 0:\n","            end_idx = start_idx + self.seq_length\n","            if end_idx <= len(df):\n","                input = df.iloc[start_idx:end_idx, 0:self.input_size].to_numpy()\n","                output = df.iloc[start_idx:end_idx]['FO'].to_numpy()\n","            elif end_idx > len(df):\n","                end_idx = len(df)\n","                start_idx = end_idx - self.seq_length\n","                input = df.iloc[start_idx:end_idx, 0:self.input_size].to_numpy()\n","                output = df.iloc[start_idx:end_idx]['FO'].to_numpy()\n","        elif start_idx <= 0:\n","            start_idx = event_idx\n","            end_idx = start_idx + self.seq_length\n","            input = df.iloc[start_idx:end_idx, 0:self.input_size].to_numpy()\n","            output = df.iloc[start_idx:end_idx]['FO'].to_numpy()\n","            if end_idx <= len(df):\n","                input = df.iloc[start_idx:end_idx, 0:self.input_size].to_numpy()\n","                output = df.iloc[start_idx:end_idx]['FO'].to_numpy()\n","            elif end_idx > len(df):\n","                end_idx = len(df)\n","                start_idx = end_idx - self.seq_length\n","                input = df.iloc[start_idx:end_idx, 0:self.input_size].to_numpy()\n","                output = df.iloc[start_idx:end_idx]['FO'].to_numpy()\n","\n","        # Converted to Tensor\n","        if self.convolution:\n","            output = signal.convolve(output, self.window, mode='same')\n","\n","        input_data = input\n","        output_data = output\n","\n","        assert input_data.shape[0] == output_data.shape[0] == self.seq_length\n","\n","        return input_data, output_data\n","\n","    def read_file(self, f):\n","\n","        df = pd.read_csv(open(f, \"r\"))\n","        fname = os.path.basename(f)\n","        if fname[0:2] == 'RT':\n","            df = df.drop(['Unnamed: 0','ID',\n","                          'High_RTOE_X','RTOE_X','RTOE_Y','RTOE_Z','V_RTOE_X','V_RTOE_Y','V_RTOE_Z',\n","                          'High_RHEE_X',#'RHEE_X','RHEE_Y','RHEE_Z','V_RHEE_X','V_RHEE_Y','V_RHEE_Z',\n","                          'High_RANK_X','RANK_X','RANK_Y','RANK_Z','V_RANK_X','V_RANK_Y','V_RANK_Z',\n","                          'High_RHLX_X',#'RHLX_X','RHLX_Y','RHLX_Z','V_RHLX_X','V_RHLX_Y','V_RHLX_Z',\n","                          'High_RPMT5_X','RPMT5_X','RPMT5_Y','RPMT5_Z','V_RPMT5_X','V_RPMT5_Y','V_RPMT5_Z'], axis=1)#'RPMT5_X','RPMT5_Y','RPMT5_Z','V_RPMT5_X','V_RPMT5_Y','V_RPMT5_Z'\n","        elif fname[0:2] == 'LT':\n","            df = df.drop(['Unnamed: 0','ID',\n","                          'High_LTOE_X','LTOE_X','LTOE_Y','LTOE_Z','V_LTOE_X','V_LTOE_Y','V_LTOE_Z',\n","                          'High_LHEE_X',#LHEE_X','LHEE_Y','LHEE_Z','V_LHEE_X','V_LHEE_Y','V_LHEE_Z',\n","                          'High_LANK_X','LANK_X','LANK_Y','LANK_Z','V_LANK_X','V_LANK_Y','V_LANK_Z',\n","                          'High_LHLX_X',#'LHLX_X','LHLX_Y','LHLX_Z','V_LHLX_X','V_LHLX_Y','V_LHLX_Z',\n","                          'High_LPMT5_X','LPMT5_X','LPMT5_Y','LPMT5_Z','V_LPMT5_X','V_LPMT5_Y','V_LPMT5_Z'], axis=1)#'LPMT5_X','LPMT5_Y','LPMT5_Z','V_LPMT5_X','V_LPMT5_Y','V_LPMT5_Z'\n","        return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LrouCpqEOAUc","colab_type":"text"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"iPq_8WdYOloE","colab_type":"code","colab":{}},"source":["class Network(nn.Module):\n","    # TO DO\n","    def __init__(self, config):\n","        super(Network, self).__init__()\n","\n","        # Model construct Configuration\n","        self.input_size = config.input_size\n","        self.hidden_size = config.hidden_size\n","        self.output_size = config.output_size\n","        self.batch_size = config.batch_size\n","        self.num_layers = config.num_layers\n","        self.drop_out = config.drop_out\n","        self.seq_length = config.seq_length\n","        self.device = config.device\n","        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, dropout = self.drop_out, batch_first=True,bidirectional=True)\n","        self.linear = nn.Linear(self.hidden_size*2, self.output_size,bias= True)\n","        torch.nn.init.xavier_uniform_(self.linear.weight)\n","\n","    def forward(self, x):\n","\n","        hidden, cell = self.init_hidden()\n","        out, _ = self.lstm(x, (hidden, cell))\n","        logits = self.linear(out)\n","\n","        return logits[:, :, -1]\n","\n","    def init_hidden(self):\n","\n","        weight = next((self.parameters())).data\n","        hidden, cell = (weight.new(self.num_layers*2, self.batch_size, self.hidden_size).zero_().to(self.device),\n","                        weight.new(self.num_layers*2, self.batch_size, self.hidden_size).zero_().to(self.device))\n","        return hidden, cell\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DwDmwFJboh8f","colab_type":"text"},"source":["# Early Stop"]},{"cell_type":"code","metadata":{"id":"mnRV3u22oiK6","colab_type":"code","colab":{}},"source":["class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    # def __init__(self, patience: str,, delta: str, Name: str, verbose=False):\n","    def __init__(self, patience: str, delta: str, Name: str,  verbose = False,):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.Name = Name\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}\\n')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model\\n')\n","        torch.save(model.state_dict(), f\"Models/2markers/FO/HLXHEE/v1/{self.Name}-FScheckpoint.pt\",_use_new_zipfile_serialization=False)\n","        self.val_loss_min = val_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-df0ApraOCUQ","colab_type":"text"},"source":["# Training and Validation"]},{"cell_type":"code","metadata":{"id":"Cf2k1ArgOofi","colab_type":"code","colab":{}},"source":["class Trainer:\n","\n","    def __init__(self,input_size, batch_size,seq_length,hidden_size,num_layers,drop_out,lr,epoch,config):\n","\n","        # System configuration\n","        self.device = config.device\n","        self.log_interval = config.log_interval\n","        self.output_size = config.output_size\n","        self.seed = config.seed\n","        self.validation_split = config.validation_split\n","        self.convolution = config.convolution\n","        torch.manual_seed(self.seed)\n","\n","        # Hyper Parameters\n","        config.input_size = input_size\n","        config.batch_size = batch_size\n","        config.hidden_size = hidden_size\n","        config.seq_length = seq_length\n","        config.num_layers = num_layers\n","        config.drop_out = drop_out\n","        config.lr = lr\n","\n","        # Model Construction\n","        self.model = Network(config).to(self.device)\n","        self.model = self.model.to(self.device)\n","        print(self.model)\n","\n","        # Optimizer and Loss\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n","        self.pos_weight = torch.ones([config.weight_length])  \n","        self.pos_weight_factor = self.pos_weight * config.weight_factor\n","        self.criterion = nn.BCEWithLogitsLoss(pos_weight= self.pos_weight_factor).to(self.device)\n","       \n","        # Initialise the early_stopping object\n","        self.Name = f\"FO-{config.weight_factor}-WF-{hidden_size}-HS-{num_layers}-NL-{lr}-LR-{epoch}-epochs\"\n","        self.early_stopping = EarlyStopping(patience=model_config.patience, verbose=True,delta = model_config.delta,Name = self.Name)\n","        print(self.Name)\n","\n","        # DataLoader\n","        dataset = Split_data(r\"data/iteration1/train/\")\n","        train_idx, val_idx = dataset.splitset(self.validation_split,self.seed)\n","        self.train_loader = DataLoader(CoolDataset(r\"data/iteration1/train/\", config.seq_length, config.input_size, config.samples_per_event, train_idx,convolution=self.convolution), batch_size=config.batch_size, drop_last=True, shuffle=False)\n","        self.val_loader = DataLoader(CoolDataset(r\"data/iteration1/train/\", config.seq_length, config.input_size, config.samples_per_event, val_idx,convolution=self.convolution), batch_size=config.batch_size, drop_last=True, shuffle=False)\n","\n","        self.globaliter = 0     \n","        train_log_dir = 'logs/tensorboard_FO/2markers/train/HLXHEE'+ self.Name\n","        val_log_dir = 'logs/tensorboard_FO/2markers/val/HLXHEE' + self.Name\n","        self.train_summary_writer = SummaryWriter(train_log_dir)\n","        self.val_summary_writer =  SummaryWriter(val_log_dir)\n","\n","    def train(self,epoch):\n","      \n","      self.model.train()\n","      start = time.time()\n","      with self.train_summary_writer:\n","        for batch_idx, (data, target) in enumerate(self.train_loader):\n","              \n","              self.optimizer.zero_grad()\n","\n","              data, target = data.to(self.device), target.to(self.device)\n","              predictions = self.model(data.float())\n","              loss = self.criterion(predictions.float(), target.float())\n","              loss.backward()\n","              \n","              self.optimizer.step()\n","              pred = torch.sigmoid(predictions.detach())\n","              correct_indx_positive = pred[target > 0.5]  # Should have batch_size * 1's\n","              correct_indx_negative = pred[target <= 0.5]  # Should have (batch_size*seq_length-batch_size) * 0'\n","\n","              TPR = len(correct_indx_positive[correct_indx_positive > 0.5]) / len(correct_indx_positive)\n","              TNR = len(correct_indx_negative[correct_indx_negative <= 0.5]) / len(correct_indx_negative)\n","              TPR = TPR * 100\n","              TNR = TNR * 100\n","\n","\n","              self.globaliter += 1\n","              \n","              if batch_idx % self.log_interval == 0:\n","\n","                  print('Train Epoch: {}\\tLoss: {:.6f}\\tTPR: {}\\tTNR: {}\\tTime: {:.6f}'.format(epoch,loss.item(), TPR, TNR, (time.time() - start)))\n","                  self.train_summary_writer.add_scalar('Loss', loss.item(),self.globaliter)\n","  \n","    def val(self):\n","        \n","        self.model.eval()\n","        val_loss = 0\n","        start = time.time()\n","        with self.val_summary_writer:\n","          with torch.no_grad():\n","            for data, target in self.val_loader:\n","\n","                  data, target = data.to(self.device), target.to(self.device)\n","\n","                  predictions = self.model(data.float())\n","\n","                  val_loss = self.criterion(predictions.float(), target.float())\n","\n","                  pred = torch.sigmoid(predictions.detach())\n","                  correct_indx_positive = pred[target > 0.5]  # Should have batch_size * 1's\n","                  correct_indx_negative = pred[target <= 0.5]  # Should have (batch_size*seq_length-batch_size) * 0'\n","\n","                  TPR = len(correct_indx_positive[correct_indx_positive > 0.5]) / len(correct_indx_positive)\n","                  TNR = len(correct_indx_negative[correct_indx_negative <= 0.5]) / len(correct_indx_negative)\n","                  TPR = TPR * 100\n","                  TNR = TNR * 100\n","\n","\n","            print('Val_loss: {:.6f}\\tTPR: {}\\tTNR: {}\\tTime: {:.6f}\\n'.format(val_loss.item(), TPR, TNR, (time.time() - start)))\n","            self.val_summary_writer.add_scalar('val_loss', val_loss.item(),self.globaliter)\n","            return val_loss, TPR, TNR, self.Name"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5hBKti3JOEp_","colab_type":"text"},"source":["# Hyperparmeter Setting"]},{"cell_type":"code","metadata":{"id":"xvjgWhf-N0fr","colab_type":"code","colab":{}},"source":["def main(hparam, model_config):\n","    for input_size in hparam['input_size']:\n","        for batch_size in hparam['batch_size']:\n","            for seq_length in hparam['seq_length']:\n","                for hidden_size in hparam['hidden_size']:\n","                    for lr in hparam['lr']:\n","                        for num_layers in hparam['num_layers']:\n","                            for drop_out in hparam['drop_out']:\n","                                for epochs in hparam['epochs']:\n","                                    trainer = Trainer(input_size, batch_size, seq_length, hidden_size, num_layers, drop_out, lr, epochs, model_config)\n","                                    TPR = dict()\n","                                    TNR = dict()\n","                                    for epoch in range(epochs):\n","                                        epoch_start = time.time()\n","                                        trainer.train(epoch)\n","                                        # pdb.set_trace()\n","                                        val_loss, TPR[epoch], TNR[epoch],Name = trainer.val()\n","                                        trainer.early_stopping(val_loss, trainer.model)\n","                                        if trainer.early_stopping.early_stop:\n","                                            print(\"Early stopping\")\n","                                            break\n","                                        print(f\"Epoch Duration {time.time() - epoch_start}\")\n","                                    # csv file save\n","                                    ROC = pd.DataFrame({'TPR':pd.Series(TPR),'TNR':pd.Series(TNR)})\n","                                    ROC.to_csv(f\"Models/2markers/FO/HLXHEE/v1/{Name}-ROC.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U89ullE8O6Rm","colab_type":"text"},"source":["# Main"]},{"cell_type":"code","metadata":{"id":"UnlPvKxYOwXK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600959384390,"user_tz":-120,"elapsed":31284467,"user":{"displayName":"Yong Kuk Kim","photoUrl":"","userId":"05925217294532758280"}},"outputId":"a3cc2e8b-5855-4463-ae45-84fc2f7e1ec6"},"source":["class Config:\n","\n","    def __init__(self, **kwargs):\n","        for key, value in kwargs.items():\n","            setattr(self, key, value)\n","            \n","if __name__ == '__main__':\n","    \n","    if torch.cuda.is_available():\n","      device = torch.device(\"cuda\") \n","      print(\"Running on the GPU\")\n","    else:\n","      device = torch.device(\"cpu\")\n","      print(\"Running on the CPU\")\n","\n","\n","    model_config = Config(\n","        device=device,\n","        # Early Stop\n","        patience=20,\n","        delta=0.001,\n","        log_interval=1000,\n","        # Dataset Configuration\n","        validation_split=0.2,\n","        seed=2,\n","        samples_per_event=1,\n","        convolution = True,\n","        output_size=1,\n","        # Weight loss\n","        weight_length=128,\n","        weight_factor=13,\n","    )\n","\n","    hparam = {\n","        \n","        'input_size': [12],   # 2 markers:12 3 markers: 18, 4 markers: 24, 5 markers:30, 6 markers:36, 7 markers:42, 8 markers:48\n","        'batch_size': [64],\n","        'seq_length': [128],\n","        'hidden_size': [256,512,1024],\n","        'num_layers': [2,5,10],\n","        'drop_out' : [0.5],\n","        'lr': [0.00001],\n","        'epochs': [100],\n","    }\n","\n","    main(hparam, model_config)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Running on the GPU\n","Network(\n","  (lstm): LSTM(12, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=512, out_features=1, bias=True)\n",")\n","FO-13-WF-256-HS-2-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.033759\tTPR: 72.23382045929019\tTNR: 56.90392843251652\tTime: 16.219748\n","Val_loss: 0.863723\tTPR: 63.44969199178645\tTNR: 92.00519143413368\tTime: 94.184358\n","\n","Validation loss decreased (inf --> 0.863723).  Saving model\n","\n","Epoch Duration 483.7441711425781\n","Train Epoch: 1\tLoss: 0.874351\tTPR: 68.3083511777302\tTNR: 91.01618122977347\tTime: 0.912091\n","Val_loss: 0.744291\tTPR: 67.14876033057851\tTNR: 91.17799688635185\tTime: 7.506114\n","\n","Validation loss decreased (0.863723 --> 0.744291).  Saving model\n","\n","Epoch Duration 39.89317989349365\n","Train Epoch: 2\tLoss: 0.780639\tTPR: 68.23770491803278\tTNR: 92.34164070612668\tTime: 0.919925\n","Val_loss: 0.641811\tTPR: 72.23382045929019\tTNR: 91.81900687151561\tTime: 7.271188\n","\n","Validation loss decreased (0.744291 --> 0.641811).  Saving model\n","\n","Epoch Duration 38.53040266036987\n","Train Epoch: 3\tLoss: 0.680179\tTPR: 67.4468085106383\tTNR: 92.86454286454287\tTime: 0.864847\n","Val_loss: 0.576185\tTPR: 75.65922920892496\tTNR: 91.44044681127419\tTime: 7.221125\n","\n","Validation loss decreased (0.641811 --> 0.576185).  Saving model\n","\n","Epoch Duration 38.27830743789673\n","Train Epoch: 4\tLoss: 0.611584\tTPR: 72.86012526096033\tTNR: 91.79307662388176\tTime: 0.884669\n","Val_loss: 0.519508\tTPR: 79.18367346938776\tTNR: 91.04128797714878\tTime: 7.159910\n","\n","Validation loss decreased (0.576185 --> 0.519508).  Saving model\n","\n","Epoch Duration 38.409032106399536\n","Train Epoch: 5\tLoss: 0.554533\tTPR: 77.58985200845666\tTNR: 90.82782743878741\tTime: 0.869164\n","Val_loss: 0.460868\tTPR: 83.82978723404256\tTNR: 91.67314167314167\tTime: 7.536268\n","\n","Validation loss decreased (0.519508 --> 0.460868).  Saving model\n","\n","Epoch Duration 38.537376165390015\n","Train Epoch: 6\tLoss: 0.498333\tTPR: 85.38622129436325\tTNR: 90.84662258524568\tTime: 0.902683\n","Val_loss: 0.427168\tTPR: 87.07627118644068\tTNR: 91.39896373056995\tTime: 7.344901\n","\n","Validation loss decreased (0.460868 --> 0.427168).  Saving model\n","\n","Epoch Duration 38.5089955329895\n","Train Epoch: 7\tLoss: 0.462040\tTPR: 86.25792811839324\tTNR: 91.24238891048063\tTime: 0.882272\n","Val_loss: 0.405615\tTPR: 88.49372384937239\tTNR: 90.18667358050298\tTime: 7.197562\n","\n","Validation loss decreased (0.427168 --> 0.405615).  Saving model\n","\n","Epoch Duration 37.581342458724976\n","Train Epoch: 8\tLoss: 0.428722\tTPR: 89.21775898520085\tTNR: 89.44163751781319\tTime: 0.881159\n","Val_loss: 0.377508\tTPR: 93.72384937238493\tTNR: 89.7459165154265\tTime: 7.182125\n","\n","Validation loss decreased (0.405615 --> 0.377508).  Saving model\n","\n","Epoch Duration 37.97161507606506\n","Train Epoch: 9\tLoss: 0.402736\tTPR: 92.17758985200845\tTNR: 89.1566265060241\tTime: 0.876753\n","Val_loss: 0.371940\tTPR: 93.55509355509356\tTNR: 88.9249124627156\tTime: 7.600557\n","\n","Validation loss decreased (0.377508 --> 0.371940).  Saving model\n","\n","Epoch Duration 38.643412590026855\n","Train Epoch: 10\tLoss: 0.380867\tTPR: 94.00428265524626\tTNR: 89.7346278317152\tTime: 0.881614\n","Val_loss: 0.350927\tTPR: 92.67782426778243\tTNR: 89.78480684469795\tTime: 7.123276\n","\n","Validation loss decreased (0.371940 --> 0.350927).  Saving model\n","\n","Epoch Duration 37.68447160720825\n","Train Epoch: 11\tLoss: 0.372805\tTPR: 92.85714285714286\tTNR: 89.1524105754277\tTime: 0.880012\n","Val_loss: 0.333553\tTPR: 93.09623430962343\tTNR: 90.52372310085559\tTime: 7.201451\n","\n","Validation loss decreased (0.350927 --> 0.333553).  Saving model\n","\n","Epoch Duration 37.97364068031311\n","Train Epoch: 12\tLoss: 0.348194\tTPR: 93.65750528541226\tTNR: 90.24485036921881\tTime: 0.874463\n","Val_loss: 0.324155\tTPR: 94.24307036247335\tTNR: 90.5736112909491\tTime: 7.140737\n","\n","Validation loss decreased (0.333553 --> 0.324155).  Saving model\n","\n","Epoch Duration 38.01179265975952\n","Train Epoch: 13\tLoss: 0.352291\tTPR: 93.81443298969072\tTNR: 88.76346178798495\tTime: 0.881873\n","Val_loss: 0.316607\tTPR: 94.73684210526315\tTNR: 90.78657509394843\tTime: 7.348992\n","\n","Validation loss decreased (0.324155 --> 0.316607).  Saving model\n","\n","Epoch Duration 37.94458246231079\n","Train Epoch: 14\tLoss: 0.322156\tTPR: 92.88793103448276\tTNR: 90.94202898550725\tTime: 0.895969\n","Val_loss: 0.314031\tTPR: 93.55509355509356\tTNR: 91.0517442614447\tTime: 7.217266\n","\n","Validation loss decreased (0.316607 --> 0.314031).  Saving model\n","\n","Epoch Duration 37.83983516693115\n","Train Epoch: 15\tLoss: 0.319930\tTPR: 95.37815126050421\tTNR: 90.02073613271125\tTime: 0.869763\n","Val_loss: 0.310220\tTPR: 93.18181818181817\tTNR: 91.08718214841723\tTime: 7.104125\n","\n","Validation loss decreased (0.314031 --> 0.310220).  Saving model\n","\n","Epoch Duration 37.37787055969238\n","Train Epoch: 16\tLoss: 0.315982\tTPR: 93.52818371607515\tTNR: 90.52249448982238\tTime: 0.849957\n","Val_loss: 0.298662\tTPR: 93.4873949579832\tTNR: 92.2239502332815\tTime: 7.221959\n","\n","Validation loss decreased (0.310220 --> 0.298662).  Saving model\n","\n","Epoch Duration 37.42464900016785\n","Train Epoch: 17\tLoss: 0.312931\tTPR: 93.4873949579832\tTNR: 91.05754276827372\tTime: 0.871321\n","Val_loss: 0.295596\tTPR: 93.83983572895276\tTNR: 92.10902011680727\tTime: 7.390397\n","\n","Validation loss decreased (0.298662 --> 0.295596).  Saving model\n","\n","Epoch Duration 37.618215799331665\n","Train Epoch: 18\tLoss: 0.310170\tTPR: 95.9266802443992\tTNR: 90.23503441111545\tTime: 0.925550\n","Val_loss: 0.284319\tTPR: 93.93305439330544\tTNR: 92.63676432460461\tTime: 7.118280\n","\n","Validation loss decreased (0.295596 --> 0.284319).  Saving model\n","\n","Epoch Duration 37.72168040275574\n","Train Epoch: 19\tLoss: 0.289127\tTPR: 94.29175475687104\tTNR: 91.64399533618345\tTime: 0.869781\n","Val_loss: 0.295059\tTPR: 91.94214876033058\tTNR: 92.47535028541775\tTime: 7.123455\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 37.59614324569702\n","Train Epoch: 20\tLoss: 0.286558\tTPR: 94.9579831932773\tTNR: 91.83514774494557\tTime: 0.867059\n","Val_loss: 0.288886\tTPR: 92.42105263157895\tTNR: 92.93767007904627\tTime: 7.226007\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 37.67030644416809\n","Train Epoch: 21\tLoss: 0.291813\tTPR: 93.56846473029046\tTNR: 92.17898832684824\tTime: 0.882611\n","Val_loss: 0.279313\tTPR: 91.94915254237289\tTNR: 93.14766839378238\tTime: 7.253739\n","\n","Validation loss decreased (0.284319 --> 0.279313).  Saving model\n","\n","Epoch Duration 37.79116129875183\n","Train Epoch: 22\tLoss: 0.274751\tTPR: 95.13742071881607\tTNR: 92.65448892343568\tTime: 0.928104\n","Val_loss: 0.275072\tTPR: 90.10526315789474\tTNR: 94.06505118569393\tTime: 7.144140\n","\n","Validation loss decreased (0.279313 --> 0.275072).  Saving model\n","\n","Epoch Duration 37.80600118637085\n","Train Epoch: 23\tLoss: 0.275300\tTPR: 95.77167019027483\tTNR: 92.25288249773287\tTime: 0.864426\n","Val_loss: 0.277590\tTPR: 90.27484143763213\tTNR: 93.82044306257286\tTime: 7.130133\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 37.601579666137695\n","Train Epoch: 24\tLoss: 0.267144\tTPR: 95.58823529411765\tTNR: 93.18299637117677\tTime: 0.877290\n","Val_loss: 0.256293\tTPR: 88.8646288209607\tTNR: 94.87975174553918\tTime: 7.163177\n","\n","Validation loss decreased (0.275072 --> 0.256293).  Saving model\n","\n","Epoch Duration 37.57550096511841\n","Train Epoch: 25\tLoss: 0.275817\tTPR: 92.78350515463917\tTNR: 92.91553133514986\tTime: 0.884599\n","Val_loss: 0.276914\tTPR: 87.57894736842105\tTNR: 94.28534404561358\tTime: 7.144047\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 37.80499577522278\n","Train Epoch: 26\tLoss: 0.252357\tTPR: 97.67441860465115\tTNR: 92.64153387744527\tTime: 0.870996\n","Val_loss: 0.295688\tTPR: 88.50102669404517\tTNR: 93.95197923426346\tTime: 7.135957\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 38.20688533782959\n","Train Epoch: 27\tLoss: 0.249151\tTPR: 95.77167019027483\tTNR: 93.14678067107138\tTime: 0.873315\n","Val_loss: 0.280697\tTPR: 85.41226215644821\tTNR: 95.25845316750875\tTime: 7.157853\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 37.475167989730835\n","Train Epoch: 28\tLoss: 0.242578\tTPR: 98.92933618843684\tTNR: 92.97087378640776\tTime: 0.877205\n","Val_loss: 0.295497\tTPR: 85.44698544698545\tTNR: 94.65698353002205\tTime: 7.161367\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 37.453126430511475\n","Train Epoch: 29\tLoss: 0.247680\tTPR: 96.17021276595744\tTNR: 93.08469308469309\tTime: 0.872957\n","Val_loss: 0.288055\tTPR: 85.59322033898306\tTNR: 95.2720207253886\tTime: 7.222139\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 37.44599795341492\n","Train Epoch: 30\tLoss: 0.255367\tTPR: 97.74590163934425\tTNR: 92.54932502596054\tTime: 0.868033\n","Val_loss: 0.297816\tTPR: 85.62628336755647\tTNR: 94.93835171966256\tTime: 7.134041\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 37.559611320495605\n","Train Epoch: 31\tLoss: 0.247695\tTPR: 97.26890756302521\tTNR: 93.701399688958\tTime: 0.869019\n","Val_loss: 0.271151\tTPR: 85.1063829787234\tTNR: 95.63584563584564\tTime: 7.270550\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 37.45705032348633\n","Train Epoch: 32\tLoss: 0.237998\tTPR: 96.84873949579831\tTNR: 93.71435977190255\tTime: 0.871361\n","Val_loss: 0.291523\tTPR: 86.25792811839324\tTNR: 95.24549812151834\tTime: 7.128730\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 37.29830980300903\n","Train Epoch: 33\tLoss: 0.240699\tTPR: 97.89915966386555\tTNR: 92.92379471228615\tTime: 0.858397\n","Val_loss: 0.266797\tTPR: 88.21052631578948\tTNR: 94.97213943242193\tTime: 7.138103\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 37.32054400444031\n","Train Epoch: 34\tLoss: 0.246442\tTPR: 94.6058091286307\tTNR: 93.42412451361868\tTime: 0.870457\n","Val_loss: 0.287960\tTPR: 84.76394849785407\tTNR: 95.92285788247477\tTime: 7.100722\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 38.14379906654358\n","Train Epoch: 35\tLoss: 0.241041\tTPR: 95.82463465553236\tTNR: 93.6470893297031\tTime: 0.861401\n","Val_loss: 0.272285\tTPR: 88.0\tTNR: 95.20539069586627\tTime: 7.083211\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 37.28631234169006\n","Train Epoch: 36\tLoss: 0.219901\tTPR: 98.28693790149893\tTNR: 93.8252427184466\tTime: 0.870916\n","Val_loss: 0.283690\tTPR: 87.11018711018711\tTNR: 95.43509272467902\tTime: 7.098540\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 37.63982033729553\n","Train Epoch: 37\tLoss: 0.233687\tTPR: 98.13278008298755\tTNR: 93.28145265888456\tTime: 0.862674\n","Val_loss: 0.308597\tTPR: 86.44763860369609\tTNR: 95.3277092796885\tTime: 7.117090\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 37.24970245361328\n","Train Epoch: 38\tLoss: 0.228805\tTPR: 96.21848739495799\tTNR: 94.23276308968377\tTime: 0.856175\n","Val_loss: 0.303767\tTPR: 85.21560574948666\tTNR: 95.70408825438027\tTime: 7.113281\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 37.635170221328735\n","Train Epoch: 39\tLoss: 0.224110\tTPR: 97.7035490605428\tTNR: 93.67301957733697\tTime: 0.857862\n","Val_loss: 0.299390\tTPR: 85.10204081632654\tTNR: 95.80628408205662\tTime: 7.050873\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 37.283097982406616\n","Train Epoch: 40\tLoss: 0.229822\tTPR: 96.2655601659751\tTNR: 93.96887159533074\tTime: 0.861269\n","Val_loss: 0.278883\tTPR: 85.86723768736617\tTNR: 96.0906148867314\tTime: 7.014997\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 37.290687084198\n","Train Epoch: 41\tLoss: 0.217853\tTPR: 96.63865546218487\tTNR: 95.08812856402281\tTime: 0.864700\n","Val_loss: 0.278012\tTPR: 86.61087866108787\tTNR: 95.79984443868291\tTime: 7.089740\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 37.20406436920166\n","Train Epoch: 42\tLoss: 0.212885\tTPR: 97.67441860465115\tTNR: 94.45524031610312\tTime: 0.873766\n","Val_loss: 0.289896\tTPR: 85.26315789473684\tTNR: 96.55306466243358\tTime: 7.685295\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 38.18519330024719\n","Train Epoch: 43\tLoss: 0.209312\tTPR: 97.23404255319149\tTNR: 94.78114478114477\tTime: 0.857572\n","Val_loss: 0.229125\tTPR: 91.14470842332614\tTNR: 96.3643420882391\tTime: 7.085497\n","\n","Validation loss decreased (0.256293 --> 0.229125).  Saving model\n","\n","Epoch Duration 37.09018659591675\n","Train Epoch: 44\tLoss: 0.204580\tTPR: 97.89915966386555\tTNR: 94.77708657335407\tTime: 0.874474\n","Val_loss: 0.293235\tTPR: 86.9022869022869\tTNR: 96.17429645960316\tTime: 7.097049\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 37.27503514289856\n","Train Epoch: 45\tLoss: 0.217320\tTPR: 97.3360655737705\tTNR: 94.67808930425753\tTime: 0.849013\n","Val_loss: 0.273398\tTPR: 89.6049896049896\tTNR: 95.85008429516276\tTime: 7.072323\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 37.14436054229736\n","Train Epoch: 46\tLoss: 0.207275\tTPR: 97.46300211416491\tTNR: 94.93457701774841\tTime: 0.862508\n","Val_loss: 0.318961\tTPR: 82.4634655532359\tTNR: 96.57720731232983\tTime: 7.108096\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 37.28436279296875\n","Train Epoch: 47\tLoss: 0.210530\tTPR: 96.24217118997912\tTNR: 95.21586931155193\tTime: 0.869709\n","Val_loss: 0.258352\tTPR: 88.65546218487394\tTNR: 96.29341627786417\tTime: 7.049317\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 37.19079804420471\n","Train Epoch: 48\tLoss: 0.198041\tTPR: 97.47899159663865\tTNR: 94.82892690513219\tTime: 0.854886\n","Val_loss: 0.267053\tTPR: 89.40677966101694\tTNR: 96.23056994818653\tTime: 7.041966\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 37.04672026634216\n","Train Epoch: 49\tLoss: 0.213681\tTPR: 96.51639344262296\tTNR: 94.67808930425753\tTime: 0.861145\n","Val_loss: 0.256643\tTPR: 87.55364806866953\tTNR: 96.72534299767021\tTime: 7.100772\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 37.27340865135193\n","Train Epoch: 50\tLoss: 0.200564\tTPR: 97.25158562367865\tTNR: 95.1159476616142\tTime: 0.840244\n","Val_loss: 0.279135\tTPR: 88.02521008403362\tTNR: 96.37117677553137\tTime: 7.114402\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 37.46848106384277\n","Train Epoch: 51\tLoss: 0.211448\tTPR: 96.72131147540983\tTNR: 94.898753894081\tTime: 0.865522\n","Val_loss: 0.275327\tTPR: 87.88501026694045\tTNR: 95.73004542504867\tTime: 7.123579\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 38.45389795303345\n","Train Epoch: 52\tLoss: 0.197277\tTPR: 97.44680851063829\tTNR: 95.20849520849521\tTime: 0.857894\n","Val_loss: 0.240751\tTPR: 89.81288981288982\tTNR: 96.5244455971988\tTime: 7.101585\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 37.546247720718384\n","Train Epoch: 53\tLoss: 0.205138\tTPR: 96.42857142857143\tTNR: 95.36029030585796\tTime: 0.873433\n","Val_loss: 0.259235\tTPR: 87.86610878661088\tTNR: 96.4998703655691\tTime: 7.182013\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 37.73858165740967\n","Train Epoch: 54\tLoss: 0.204677\tTPR: 96.21848739495799\tTNR: 95.25660964230171\tTime: 0.875218\n","Val_loss: 0.277619\tTPR: 85.86278586278586\tTNR: 96.43366619115548\tTime: 7.259963\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 37.78762984275818\n","Train Epoch: 55\tLoss: 0.188251\tTPR: 97.02127659574468\tTNR: 95.57109557109557\tTime: 0.860409\n","Val_loss: 0.271369\tTPR: 86.31578947368422\tTNR: 96.86406634702604\tTime: 7.215365\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 37.64537978172302\n","Train Epoch: 56\tLoss: 0.195489\tTPR: 97.25158562367865\tTNR: 95.68596968519239\tTime: 0.882000\n","Val_loss: 0.284955\tTPR: 86.10526315789474\tTNR: 96.7215239082545\tTime: 7.206706\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 37.63594698905945\n","Train Epoch: 57\tLoss: 0.187362\tTPR: 97.64453961456103\tTNR: 95.84466019417476\tTime: 0.868454\n","Val_loss: 0.252324\tTPR: 88.63157894736841\tTNR: 96.39756382013735\tTime: 7.231140\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 37.798861026763916\n","Train Epoch: 58\tLoss: 0.193974\tTPR: 96.38297872340425\tTNR: 95.38979538979538\tTime: 0.870190\n","Val_loss: 0.264779\tTPR: 87.88501026694045\tTNR: 96.11940298507463\tTime: 7.268401\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 37.75461935997009\n","Train Epoch: 59\tLoss: 0.186387\tTPR: 97.91231732776617\tTNR: 95.85116037858161\tTime: 0.870730\n","Val_loss: 0.253812\tTPR: 87.57894736842105\tTNR: 96.66969029415576\tTime: 7.284372\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 38.49768257141113\n","Train Epoch: 60\tLoss: 0.196669\tTPR: 97.05882352941177\tTNR: 95.6324520476931\tTime: 0.875049\n","Val_loss: 0.282471\tTPR: 86.04651162790698\tTNR: 96.90374400829123\tTime: 7.174364\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 37.65046286582947\n","Train Epoch: 61\tLoss: 0.179132\tTPR: 97.44680851063829\tTNR: 95.94664594664594\tTime: 0.864599\n","Val_loss: 0.265512\tTPR: 87.11018711018711\tTNR: 96.58928803008689\tTime: 7.266561\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 38.14586782455444\n","Train Epoch: 62\tLoss: 0.194969\tTPR: 96.51639344262296\tTNR: 95.61266874350987\tTime: 0.904313\n","Val_loss: 0.274179\tTPR: 86.6943866943867\tTNR: 96.65413046297498\tTime: 7.411828\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 38.445159673690796\n","Train Epoch: 63\tLoss: 0.186409\tTPR: 96.84873949579831\tTNR: 95.86573354069466\tTime: 0.886699\n","Val_loss: 0.256994\tTPR: 87.86610878661088\tTNR: 96.73321234119783\tTime: 7.350509\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 256, num_layers=5, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=512, out_features=1, bias=True)\n",")\n","FO-13-WF-256-HS-5-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.080619\tTPR: 99.57716701902748\tTNR: 0.2202357818370255\tTime: 1.056925\n","Val_loss: 1.039340\tTPR: 16.432865731462925\tTNR: 99.64903158715715\tTime: 7.652010\n","\n","Validation loss decreased (inf --> 1.039340).  Saving model\n","\n","Epoch Duration 43.059422731399536\n","Train Epoch: 1\tLoss: 1.030408\tTPR: 13.485477178423237\tTNR: 99.5201037613489\tTime: 1.029987\n","Val_loss: 0.926730\tTPR: 45.53014553014553\tTNR: 98.52159253015174\tTime: 7.756414\n","\n","Validation loss decreased (1.039340 --> 0.926730).  Saving model\n","\n","Epoch Duration 43.423006772994995\n","Train Epoch: 2\tLoss: 0.945073\tTPR: 39.58762886597938\tTNR: 99.09173478655767\tTime: 1.046969\n","Val_loss: 0.715737\tTPR: 56.72268907563025\tTNR: 95.83981337480559\tTime: 7.771447\n","\n","Validation loss decreased (0.926730 --> 0.715737).  Saving model\n","\n","Epoch Duration 43.25815796852112\n","Train Epoch: 3\tLoss: 0.760206\tTPR: 56.448202959830866\tTNR: 96.37258712268428\tTime: 1.093532\n","Val_loss: 0.506307\tTPR: 73.65145228215768\tTNR: 91.38780804150454\tTime: 7.644033\n","\n","Validation loss decreased (0.715737 --> 0.506307).  Saving model\n","\n","Epoch Duration 44.033544063568115\n","Train Epoch: 4\tLoss: 0.548810\tTPR: 68.28752642706131\tTNR: 92.61562378546444\tTime: 1.009152\n","Val_loss: 0.401951\tTPR: 91.8918918918919\tTNR: 87.00557644922837\tTime: 7.604187\n","\n","Validation loss decreased (0.506307 --> 0.401951).  Saving model\n","\n","Epoch Duration 43.041598320007324\n","Train Epoch: 5\tLoss: 0.421544\tTPR: 89.00414937759335\tTNR: 87.58754863813229\tTime: 1.045865\n","Val_loss: 0.347328\tTPR: 92.96375266524521\tTNR: 89.68017609737149\tTime: 7.782317\n","\n","Validation loss decreased (0.401951 --> 0.347328).  Saving model\n","\n","Epoch Duration 43.34517288208008\n","Train Epoch: 6\tLoss: 0.370660\tTPR: 94.78079331941545\tTNR: 87.78685336444964\tTime: 1.034868\n","Val_loss: 0.339569\tTPR: 93.83983572895276\tTNR: 89.02011680726801\tTime: 7.561533\n","\n","Validation loss decreased (0.347328 --> 0.339569).  Saving model\n","\n","Epoch Duration 43.01117730140686\n","Train Epoch: 7\tLoss: 0.352508\tTPR: 96.28865979381443\tTNR: 87.94602309588686\tTime: 1.035318\n","Val_loss: 0.304107\tTPR: 94.64668094218416\tTNR: 90.67961165048544\tTime: 7.612020\n","\n","Validation loss decreased (0.339569 --> 0.304107).  Saving model\n","\n","Epoch Duration 43.284250259399414\n","Train Epoch: 8\tLoss: 0.337304\tTPR: 97.30290456431536\tTNR: 89.29961089494164\tTime: 1.030483\n","Val_loss: 0.289319\tTPR: 96.57387580299786\tTNR: 90.57605177993527\tTime: 7.546709\n","\n","Validation loss decreased (0.304107 --> 0.289319).  Saving model\n","\n","Epoch Duration 42.94615459442139\n","Train Epoch: 9\tLoss: 0.319875\tTPR: 93.44608879492601\tTNR: 90.45213110506542\tTime: 1.035418\n","Val_loss: 0.295081\tTPR: 95.48254620123203\tTNR: 90.8890330953926\tTime: 7.775875\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 43.41903281211853\n","Train Epoch: 10\tLoss: 0.299427\tTPR: 96.82875264270614\tTNR: 90.36144578313254\tTime: 1.053905\n","Val_loss: 0.273964\tTPR: 95.60669456066945\tTNR: 91.72932330827066\tTime: 7.620887\n","\n","Validation loss decreased (0.289319 --> 0.273964).  Saving model\n","\n","Epoch Duration 44.34703350067139\n","Train Epoch: 11\tLoss: 0.294689\tTPR: 94.98956158663883\tTNR: 91.28743679502139\tTime: 1.058975\n","Val_loss: 0.277315\tTPR: 95.07186858316223\tTNR: 92.86177806619078\tTime: 7.602357\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 43.676286697387695\n","Train Epoch: 12\tLoss: 0.277851\tTPR: 95.95744680851064\tTNR: 91.89329189329189\tTime: 1.012983\n","Val_loss: 0.245955\tTPR: 95.61586638830897\tTNR: 93.27110073901206\tTime: 7.966498\n","\n","Validation loss decreased (0.273964 --> 0.245955).  Saving model\n","\n","Epoch Duration 43.98110771179199\n","Train Epoch: 13\tLoss: 0.277661\tTPR: 94.25531914893617\tTNR: 92.06164206164206\tTime: 1.059935\n","Val_loss: 0.265366\tTPR: 94.62809917355372\tTNR: 93.188894654904\tTime: 7.500837\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 43.57070302963257\n","Train Epoch: 14\tLoss: 0.260045\tTPR: 97.65957446808511\tTNR: 92.39834239834241\tTime: 1.029500\n","Val_loss: 0.235517\tTPR: 94.73684210526315\tTNR: 94.06505118569393\tTime: 7.767674\n","\n","Validation loss decreased (0.245955 --> 0.235517).  Saving model\n","\n","Epoch Duration 43.602123737335205\n","Train Epoch: 15\tLoss: 0.277417\tTPR: 95.4356846473029\tTNR: 92.14007782101167\tTime: 1.051914\n","Val_loss: 0.245647\tTPR: 94.0677966101695\tTNR: 94.1321243523316\tTime: 7.555022\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 43.46359324455261\n","Train Epoch: 16\tLoss: 0.265206\tTPR: 97.74590163934425\tTNR: 92.30269989615783\tTime: 1.027035\n","Val_loss: 0.244609\tTPR: 94.76987447698745\tTNR: 94.4516463572725\tTime: 7.737898\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 43.1988160610199\n","Train Epoch: 17\tLoss: 0.262605\tTPR: 96.24217118997912\tTNR: 92.98586801503954\tTime: 1.023739\n","Val_loss: 0.216174\tTPR: 95.74468085106383\tTNR: 94.75524475524476\tTime: 7.637347\n","\n","Validation loss decreased (0.235517 --> 0.216174).  Saving model\n","\n","Epoch Duration 44.216753005981445\n","Train Epoch: 18\tLoss: 0.258594\tTPR: 96.03340292275574\tTNR: 92.85621677687021\tTime: 1.051628\n","Val_loss: 0.210509\tTPR: 95.15789473684211\tTNR: 95.12764027471815\tTime: 7.608128\n","\n","Validation loss decreased (0.216174 --> 0.210509).  Saving model\n","\n","Epoch Duration 43.39655065536499\n","Train Epoch: 19\tLoss: 0.259062\tTPR: 96.42857142857143\tTNR: 92.59979263867288\tTime: 1.025565\n","Val_loss: 0.241047\tTPR: 94.45585215605749\tTNR: 94.65282284231019\tTime: 7.800668\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 43.31678223609924\n","Train Epoch: 20\tLoss: 0.246221\tTPR: 97.89915966386555\tTNR: 92.83307413167444\tTime: 1.018829\n","Val_loss: 0.216772\tTPR: 95.15789473684211\tTNR: 94.86847220422445\tTime: 7.563283\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 42.984851121902466\n","Train Epoch: 21\tLoss: 0.246608\tTPR: 96.88796680497926\tTNR: 92.72373540856032\tTime: 1.023470\n","Val_loss: 0.237221\tTPR: 93.51464435146444\tTNR: 95.32019704433498\tTime: 7.643653\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 42.78180742263794\n","Train Epoch: 22\tLoss: 0.243240\tTPR: 95.82463465553236\tTNR: 93.77674056787242\tTime: 1.042269\n","Val_loss: 0.222208\tTPR: 94.35146443514645\tTNR: 95.54057557687322\tTime: 7.490485\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 42.984174966812134\n","Train Epoch: 23\tLoss: 0.248450\tTPR: 93.94572025052193\tTNR: 93.6470893297031\tTime: 1.029493\n","Val_loss: 0.230405\tTPR: 94.36325678496868\tTNR: 95.55296253079217\tTime: 7.544381\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 42.87479043006897\n","Train Epoch: 24\tLoss: 0.245321\tTPR: 95.69672131147541\tTNR: 93.7435098650052\tTime: 1.007086\n","Val_loss: 0.233983\tTPR: 93.52818371607515\tTNR: 95.38441592117205\tTime: 7.623865\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 44.10896706581116\n","Train Epoch: 25\tLoss: 0.227629\tTPR: 96.40591966173362\tTNR: 94.20909444228526\tTime: 1.032218\n","Val_loss: 0.210075\tTPR: 95.1063829787234\tTNR: 95.97254597254597\tTime: 7.742440\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 43.59408688545227\n","Train Epoch: 26\tLoss: 0.226321\tTPR: 97.73195876288659\tTNR: 93.79784611392242\tTime: 1.044455\n","Val_loss: 0.205601\tTPR: 95.36842105263158\tTNR: 95.27018271348969\tTime: 8.016235\n","\n","Validation loss decreased (0.210509 --> 0.205601).  Saving model\n","\n","Epoch Duration 44.225552797317505\n","Train Epoch: 27\tLoss: 0.243905\tTPR: 93.65750528541226\tTNR: 93.63907241870709\tTime: 1.053543\n","Val_loss: 0.213423\tTPR: 94.73684210526315\tTNR: 95.73668524037838\tTime: 7.842556\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 43.98705315589905\n","Train Epoch: 28\tLoss: 0.224987\tTPR: 97.25158562367865\tTNR: 93.93703847648659\tTime: 1.070615\n","Val_loss: 0.194723\tTPR: 94.97907949790795\tTNR: 95.67021000777807\tTime: 7.705527\n","\n","Validation loss decreased (0.205601 --> 0.194723).  Saving model\n","\n","Epoch Duration 43.642873764038086\n","Train Epoch: 29\tLoss: 0.229125\tTPR: 96.03340292275574\tTNR: 94.23051990146506\tTime: 1.032185\n","Val_loss: 0.218445\tTPR: 93.4322033898305\tTNR: 96.360103626943\tTime: 7.688021\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 43.73071765899658\n","Train Epoch: 30\tLoss: 0.232103\tTPR: 95.74468085106383\tTNR: 94.25019425019426\tTime: 1.034657\n","Val_loss: 0.184686\tTPR: 95.55084745762711\tTNR: 96.139896373057\tTime: 7.888013\n","\n","Validation loss decreased (0.194723 --> 0.184686).  Saving model\n","\n","Epoch Duration 43.65261721611023\n","Train Epoch: 31\tLoss: 0.218944\tTPR: 95.53191489361701\tTNR: 94.43149443149443\tTime: 1.050680\n","Val_loss: 0.202516\tTPR: 95.60669456066945\tTNR: 95.73502722323049\tTime: 7.793735\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 44.85251808166504\n","Train Epoch: 32\tLoss: 0.217225\tTPR: 97.88583509513742\tTNR: 94.13136416634279\tTime: 1.035891\n","Val_loss: 0.220923\tTPR: 93.01848049281314\tTNR: 95.89876703439325\tTime: 7.715729\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 43.94599890708923\n","Train Epoch: 33\tLoss: 0.209114\tTPR: 97.30290456431536\tTNR: 94.60440985732814\tTime: 1.037745\n","Val_loss: 0.180063\tTPR: 95.12711864406779\tTNR: 96.32124352331606\tTime: 7.975771\n","\n","Validation loss decreased (0.184686 --> 0.180063).  Saving model\n","\n","Epoch Duration 44.675824880599976\n","Train Epoch: 34\tLoss: 0.222622\tTPR: 96.82875264270614\tTNR: 94.01476875242906\tTime: 1.058621\n","Val_loss: 0.178325\tTPR: 95.33898305084746\tTNR: 96.59326424870466\tTime: 7.736687\n","\n","Validation loss decreased (0.180063 --> 0.178325).  Saving model\n","\n","Epoch Duration 44.113725662231445\n","Train Epoch: 35\tLoss: 0.234952\tTPR: 96.42857142857143\tTNR: 94.2846034214619\tTime: 1.041640\n","Val_loss: 0.196770\tTPR: 94.83471074380165\tTNR: 96.1338868707836\tTime: 7.794330\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 44.36144232749939\n","Train Epoch: 36\tLoss: 0.219440\tTPR: 96.49484536082474\tTNR: 94.26495393797846\tTime: 1.049721\n","Val_loss: 0.200864\tTPR: 92.72349272349273\tTNR: 96.49850862404358\tTime: 7.823664\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 44.237767696380615\n","Train Epoch: 37\tLoss: 0.201756\tTPR: 96.00840336134453\tTNR: 95.1270088128564\tTime: 1.044906\n","Val_loss: 0.184855\tTPR: 94.35146443514645\tTNR: 96.20171117448794\tTime: 7.749367\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 44.05966591835022\n","Train Epoch: 38\tLoss: 0.196316\tTPR: 97.67441860465115\tTNR: 94.80502655784429\tTime: 1.067065\n","Val_loss: 0.210573\tTPR: 93.30543933054393\tTNR: 96.73321234119783\tTime: 7.738121\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 45.01019334793091\n","Train Epoch: 39\tLoss: 0.216118\tTPR: 95.56025369978859\tTNR: 95.05117243166214\tTime: 1.063761\n","Val_loss: 0.213296\tTPR: 92.25941422594143\tTNR: 96.60357791029297\tTime: 7.720608\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 43.58446216583252\n","Train Epoch: 40\tLoss: 0.211976\tTPR: 95.22821576763485\tTNR: 95.11024643320363\tTime: 1.012908\n","Val_loss: 0.206989\tTPR: 93.22381930184805\tTNR: 96.44386761842959\tTime: 7.741536\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 43.91339683532715\n","Train Epoch: 41\tLoss: 0.199038\tTPR: 96.65970772442589\tTNR: 94.93063658757941\tTime: 1.058197\n","Val_loss: 0.200457\tTPR: 92.84210526315789\tTNR: 96.66969029415576\tTime: 7.627348\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 43.67152953147888\n","Train Epoch: 42\tLoss: 0.199318\tTPR: 96.24217118997912\tTNR: 95.28069493063659\tTime: 1.020660\n","Val_loss: 0.180008\tTPR: 93.82978723404256\tTNR: 96.52939652939652\tTime: 7.637977\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 43.73289442062378\n","Train Epoch: 43\tLoss: 0.202323\tTPR: 97.5103734439834\tTNR: 94.56549935149157\tTime: 1.051650\n","Val_loss: 0.209321\tTPR: 93.00847457627118\tTNR: 96.59326424870466\tTime: 7.720411\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 43.64258003234863\n","Train Epoch: 44\tLoss: 0.207440\tTPR: 94.53781512605042\tTNR: 95.47693105235874\tTime: 1.036770\n","Val_loss: 0.195066\tTPR: 92.60780287474333\tTNR: 96.63854639844257\tTime: 7.683811\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 43.83671760559082\n","Train Epoch: 45\tLoss: 0.192702\tTPR: 96.10655737704919\tTNR: 95.14537902388369\tTime: 1.006719\n","Val_loss: 0.178589\tTPR: 92.53731343283582\tTNR: 97.03483102421339\tTime: 8.092378\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 44.2943651676178\n","Train Epoch: 46\tLoss: 0.206453\tTPR: 96.31147540983606\tTNR: 95.17133956386293\tTime: 1.038609\n","Val_loss: 0.186149\tTPR: 92.21052631578948\tTNR: 96.76039911882856\tTime: 7.851952\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 43.88745927810669\n","Train Epoch: 47\tLoss: 0.185991\tTPR: 96.40591966173362\tTNR: 95.43982381137454\tTime: 1.047538\n","Val_loss: 0.193736\tTPR: 93.51464435146444\tTNR: 96.70728545501686\tTime: 7.811795\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 44.178870677948\n","Train Epoch: 48\tLoss: 0.192160\tTPR: 96.49484536082474\tTNR: 95.23809523809523\tTime: 1.075153\n","Val_loss: 0.218496\tTPR: 91.58110882956879\tTNR: 96.82024659312135\tTime: 7.996895\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 44.84216284751892\n","Train Epoch: 49\tLoss: 0.175191\tTPR: 97.26890756302521\tTNR: 95.80093312597201\tTime: 1.044841\n","Val_loss: 0.223028\tTPR: 91.94214876033058\tTNR: 96.93824597820446\tTime: 7.888664\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 44.26046562194824\n","Train Epoch: 50\tLoss: 0.188583\tTPR: 95.56025369978859\tTNR: 95.62119445524033\tTime: 1.099526\n","Val_loss: 0.228804\tTPR: 92.13709677419355\tTNR: 96.43970893970894\tTime: 7.781295\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 44.15005445480347\n","Train Epoch: 51\tLoss: 0.190282\tTPR: 96.88796680497926\tTNR: 95.43450064850843\tTime: 1.089608\n","Val_loss: 0.200875\tTPR: 91.63179916317992\tTNR: 96.7461757842883\tTime: 7.789934\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 44.52146673202515\n","Train Epoch: 52\tLoss: 0.177982\tTPR: 96.6804979253112\tTNR: 95.92736705577173\tTime: 1.059739\n","Val_loss: 0.206031\tTPR: 92.21052631578948\tTNR: 97.16210962809382\tTime: 8.190922\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 45.37996220588684\n","Train Epoch: 53\tLoss: 0.169474\tTPR: 97.47899159663865\tTNR: 95.8786936236392\tTime: 1.067864\n","Val_loss: 0.199589\tTPR: 92.1971252566735\tTNR: 96.76833225178456\tTime: 7.783443\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 44.37008309364319\n","Train Epoch: 54\tLoss: 0.177208\tTPR: 96.59574468085106\tTNR: 95.68764568764568\tTime: 1.054414\n","Val_loss: 0.193258\tTPR: 92.0997920997921\tTNR: 96.92646868110492\tTime: 7.917044\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 256, num_layers=10, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=512, out_features=1, bias=True)\n",")\n","FO-13-WF-256-HS-10-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.058191\tTPR: 0.0\tTNR: 100.0\tTime: 1.301210\n","Val_loss: 1.033594\tTPR: 0.0\tTNR: 100.0\tTime: 8.380985\n","\n","Validation loss decreased (inf --> 1.033594).  Saving model\n","\n","Epoch Duration 52.57805275917053\n","Train Epoch: 1\tLoss: 1.036934\tTPR: 0.0\tTNR: 100.0\tTime: 1.275767\n","Val_loss: 1.009674\tTPR: 0.0\tTNR: 100.0\tTime: 8.231144\n","\n","Validation loss decreased (1.033594 --> 1.009674).  Saving model\n","\n","Epoch Duration 52.462491035461426\n","Train Epoch: 2\tLoss: 1.025798\tTPR: 0.0\tTNR: 100.0\tTime: 1.282922\n","Val_loss: 0.897366\tTPR: 0.0\tTNR: 100.0\tTime: 8.303261\n","\n","Validation loss decreased (1.009674 --> 0.897366).  Saving model\n","\n","Epoch Duration 52.52797794342041\n","Train Epoch: 3\tLoss: 0.915448\tTPR: 0.0\tTNR: 100.0\tTime: 1.278468\n","Val_loss: 0.536970\tTPR: 74.84407484407485\tTNR: 90.06613928154584\tTime: 8.839537\n","\n","Validation loss decreased (0.897366 --> 0.536970).  Saving model\n","\n","Epoch Duration 53.5514235496521\n","Train Epoch: 4\tLoss: 0.556861\tTPR: 67.64705882352942\tTNR: 92.10730948678072\tTime: 1.378639\n","Val_loss: 0.422751\tTPR: 91.25799573560768\tTNR: 85.66619189434158\tTime: 8.529327\n","\n","Validation loss decreased (0.536970 --> 0.422751).  Saving model\n","\n","Epoch Duration 53.81104254722595\n","Train Epoch: 5\tLoss: 0.420584\tTPR: 95.13742071881607\tTNR: 84.54463013343697\tTime: 1.296637\n","Val_loss: 0.387433\tTPR: 92.42105263157895\tTNR: 87.13230529998704\tTime: 8.470371\n","\n","Validation loss decreased (0.422751 --> 0.387433).  Saving model\n","\n","Epoch Duration 53.00759959220886\n","Train Epoch: 6\tLoss: 0.378020\tTPR: 97.31958762886597\tTNR: 85.85701310496951\tTime: 1.306928\n","Val_loss: 0.370947\tTPR: 94.83471074380165\tTNR: 88.02542812662169\tTime: 8.373395\n","\n","Validation loss decreased (0.387433 --> 0.370947).  Saving model\n","\n","Epoch Duration 52.97079372406006\n","Train Epoch: 7\tLoss: 0.352901\tTPR: 97.46300211416491\tTNR: 87.42065034330871\tTime: 1.291225\n","Val_loss: 0.333601\tTPR: 93.89473684210526\tTNR: 89.5425683555786\tTime: 8.489278\n","\n","Validation loss decreased (0.370947 --> 0.333601).  Saving model\n","\n","Epoch Duration 52.926658391952515\n","Train Epoch: 8\tLoss: 0.332551\tTPR: 95.74468085106383\tTNR: 88.78528878528878\tTime: 1.274258\n","Val_loss: 0.335696\tTPR: 95.45454545454545\tTNR: 89.95848469122988\tTime: 8.219636\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 52.28243541717529\n","Train Epoch: 9\tLoss: 0.310919\tTPR: 97.87234042553192\tTNR: 89.88603988603988\tTime: 1.248046\n","Val_loss: 0.297304\tTPR: 95.81589958158996\tTNR: 91.34042001555613\tTime: 8.603127\n","\n","Validation loss decreased (0.333601 --> 0.297304).  Saving model\n","\n","Epoch Duration 53.20735216140747\n","Train Epoch: 10\tLoss: 0.318698\tTPR: 96.38297872340425\tTNR: 90.09324009324008\tTime: 1.298484\n","Val_loss: 0.293005\tTPR: 95.13742071881607\tTNR: 91.41080450835601\tTime: 8.461445\n","\n","Validation loss decreased (0.297304 --> 0.293005).  Saving model\n","\n","Epoch Duration 52.42636060714722\n","Train Epoch: 11\tLoss: 0.300178\tTPR: 98.52941176470588\tTNR: 89.85225505443235\tTime: 1.276022\n","Val_loss: 0.273769\tTPR: 95.27896995708154\tTNR: 91.96220553973595\tTime: 8.135619\n","\n","Validation loss decreased (0.293005 --> 0.273769).  Saving model\n","\n","Epoch Duration 52.33458685874939\n","Train Epoch: 12\tLoss: 0.285957\tTPR: 97.67441860465115\tTNR: 90.80191734680658\tTime: 1.269141\n","Val_loss: 0.304768\tTPR: 92.90060851926978\tTNR: 91.6092999090791\tTime: 8.313698\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 52.43980407714844\n","Train Epoch: 13\tLoss: 0.261431\tTPR: 98.92241379310344\tTNR: 91.7184265010352\tTime: 1.259253\n","Val_loss: 0.275374\tTPR: 94.53781512605042\tTNR: 92.26283048211509\tTime: 8.722490\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 52.90249514579773\n","Train Epoch: 14\tLoss: 0.291626\tTPR: 97.1311475409836\tTNR: 90.86188992731049\tTime: 1.309558\n","Val_loss: 0.266887\tTPR: 94.5945945945946\tTNR: 92.7246790299572\tTime: 8.508984\n","\n","Validation loss decreased (0.273769 --> 0.266887).  Saving model\n","\n","Epoch Duration 52.96684122085571\n","Train Epoch: 15\tLoss: 0.269896\tTPR: 97.07724425887265\tTNR: 91.6504602618955\tTime: 1.321171\n","Val_loss: 0.265598\tTPR: 94.9290060851927\tTNR: 92.41459929861021\tTime: 8.284767\n","\n","Validation loss decreased (0.266887 --> 0.265598).  Saving model\n","\n","Epoch Duration 53.8536262512207\n","Train Epoch: 16\tLoss: 0.261378\tTPR: 97.7035490605428\tTNR: 91.80604174769869\tTime: 1.280175\n","Val_loss: 0.256099\tTPR: 94.74789915966386\tTNR: 93.05339554173146\tTime: 8.654274\n","\n","Validation loss decreased (0.265598 --> 0.256099).  Saving model\n","\n","Epoch Duration 53.508028507232666\n","Train Epoch: 17\tLoss: 0.252094\tTPR: 98.09725158562368\tTNR: 92.31765772768493\tTime: 1.320246\n","Val_loss: 0.243360\tTPR: 94.27966101694916\tTNR: 94.22279792746114\tTime: 8.414092\n","\n","Validation loss decreased (0.256099 --> 0.243360).  Saving model\n","\n","Epoch Duration 53.154114723205566\n","Train Epoch: 18\tLoss: 0.257343\tTPR: 97.68907563025209\tTNR: 92.57387247278382\tTime: 1.310077\n","Val_loss: 0.234751\tTPR: 95.36842105263158\tTNR: 93.87067513282364\tTime: 8.465996\n","\n","Validation loss decreased (0.243360 --> 0.234751).  Saving model\n","\n","Epoch Duration 53.51455998420715\n","Train Epoch: 19\tLoss: 0.252854\tTPR: 97.31958762886597\tTNR: 92.35759698974958\tTime: 1.293594\n","Val_loss: 0.244646\tTPR: 95.86776859504133\tTNR: 93.48728593668916\tTime: 8.537929\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 53.24532604217529\n","Train Epoch: 20\tLoss: 0.229667\tTPR: 97.88583509513742\tTNR: 93.5613421427646\tTime: 1.322616\n","Val_loss: 0.225547\tTPR: 95.33898305084746\tTNR: 94.19689119170984\tTime: 8.447174\n","\n","Validation loss decreased (0.234751 --> 0.225547).  Saving model\n","\n","Epoch Duration 53.58150601387024\n","Train Epoch: 21\tLoss: 0.235603\tTPR: 97.44680851063829\tTNR: 93.31779331779332\tTime: 1.283976\n","Val_loss: 0.233767\tTPR: 94.91525423728814\tTNR: 94.39119170984456\tTime: 8.364276\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 53.53170847892761\n","Train Epoch: 22\tLoss: 0.242304\tTPR: 97.73195876288659\tTNR: 92.79875437913586\tTime: 1.275949\n","Val_loss: 0.215079\tTPR: 93.4322033898305\tTNR: 95.25906735751295\tTime: 8.544487\n","\n","Validation loss decreased (0.225547 --> 0.215079).  Saving model\n","\n","Epoch Duration 53.35153651237488\n","Train Epoch: 23\tLoss: 0.218439\tTPR: 97.23404255319149\tTNR: 93.97824397824398\tTime: 1.307466\n","Val_loss: 0.209278\tTPR: 94.52631578947368\tTNR: 95.27018271348969\tTime: 8.686859\n","\n","Validation loss decreased (0.215079 --> 0.209278).  Saving model\n","\n","Epoch Duration 53.526155948638916\n","Train Epoch: 24\tLoss: 0.228327\tTPR: 97.14867617107943\tTNR: 93.45539540319439\tTime: 1.290655\n","Val_loss: 0.215879\tTPR: 94.73684210526315\tTNR: 94.51859530905793\tTime: 8.557411\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 53.4166464805603\n","Train Epoch: 25\tLoss: 0.208469\tTPR: 97.65957446808511\tTNR: 94.13364413364414\tTime: 1.285362\n","Val_loss: 0.203201\tTPR: 96.69421487603306\tTNR: 94.29164504411001\tTime: 8.225324\n","\n","Validation loss decreased (0.209278 --> 0.203201).  Saving model\n","\n","Epoch Duration 52.74680829048157\n","Train Epoch: 26\tLoss: 0.207309\tTPR: 97.28601252609603\tTNR: 94.19162453001427\tTime: 1.284495\n","Val_loss: 0.199715\tTPR: 95.33898305084746\tTNR: 95.10362694300518\tTime: 8.332123\n","\n","Validation loss decreased (0.203201 --> 0.199715).  Saving model\n","\n","Epoch Duration 52.285317182540894\n","Train Epoch: 27\tLoss: 0.215836\tTPR: 97.28601252609603\tTNR: 93.72488007260469\tTime: 1.275542\n","Val_loss: 0.195946\tTPR: 95.36842105263158\tTNR: 95.69781002980433\tTime: 8.251155\n","\n","Validation loss decreased (0.199715 --> 0.195946).  Saving model\n","\n","Epoch Duration 52.57492661476135\n","Train Epoch: 28\tLoss: 0.190804\tTPR: 97.88583509513742\tTNR: 94.49410545407436\tTime: 1.244834\n","Val_loss: 0.205900\tTPR: 95.24793388429752\tTNR: 95.09600415153088\tTime: 8.145856\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 51.49887776374817\n","Train Epoch: 29\tLoss: 0.210739\tTPR: 96.72131147540983\tTNR: 94.01609553478713\tTime: 1.248032\n","Val_loss: 0.188042\tTPR: 95.07494646680942\tTNR: 95.80582524271844\tTime: 8.345164\n","\n","Validation loss decreased (0.195946 --> 0.188042).  Saving model\n","\n","Epoch Duration 51.57978868484497\n","Train Epoch: 30\tLoss: 0.200014\tTPR: 96.70103092783505\tTNR: 94.82288828337875\tTime: 1.225933\n","Val_loss: 0.170536\tTPR: 95.52238805970148\tTNR: 96.20613751132979\tTime: 8.047215\n","\n","Validation loss decreased (0.188042 --> 0.170536).  Saving model\n","\n","Epoch Duration 51.23596692085266\n","Train Epoch: 31\tLoss: 0.227073\tTPR: 93.7759336099585\tTNR: 95.11024643320363\tTime: 1.230334\n","Val_loss: 0.191137\tTPR: 94.8024948024948\tTNR: 96.01867462067176\tTime: 7.986465\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 50.47931981086731\n","Train Epoch: 32\tLoss: 0.219069\tTPR: 93.98340248962656\tTNR: 95.3307392996109\tTime: 1.213238\n","Val_loss: 0.214787\tTPR: 93.26530612244898\tTNR: 96.07894053492599\tTime: 7.849190\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 50.21197462081909\n","Train Epoch: 33\tLoss: 0.200717\tTPR: 96.08247422680412\tTNR: 95.01751654340211\tTime: 1.221106\n","Val_loss: 0.198069\tTPR: 94.35146443514645\tTNR: 96.44801659320716\tTime: 7.968175\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 50.88297462463379\n","Train Epoch: 34\tLoss: 0.201295\tTPR: 96.47302904564316\tTNR: 94.90272373540856\tTime: 1.209719\n","Val_loss: 0.179931\tTPR: 94.24307036247335\tTNR: 96.6463809400492\tTime: 8.082565\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 50.576950550079346\n","Train Epoch: 35\tLoss: 0.184622\tTPR: 97.47899159663865\tTNR: 95.73613271124935\tTime: 1.237301\n","Val_loss: 0.189769\tTPR: 94.52631578947368\tTNR: 95.94401969677335\tTime: 7.980481\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 50.53165626525879\n","Train Epoch: 36\tLoss: 0.194544\tTPR: 97.30290456431536\tTNR: 94.86381322957197\tTime: 1.219209\n","Val_loss: 0.200030\tTPR: 93.83983572895276\tTNR: 96.3530175210902\tTime: 8.143054\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 50.64536714553833\n","Train Epoch: 37\tLoss: 0.191730\tTPR: 95.4070981210856\tTNR: 95.85116037858161\tTime: 1.249888\n","Val_loss: 0.183607\tTPR: 94.38669438669439\tTNR: 96.58928803008689\tTime: 8.030371\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 50.84338331222534\n","Train Epoch: 38\tLoss: 0.181744\tTPR: 95.74468085106383\tTNR: 95.86894586894587\tTime: 1.242947\n","Val_loss: 0.169341\tTPR: 96.17021276595744\tTNR: 96.56824656824656\tTime: 8.080951\n","\n","Validation loss decreased (0.170536 --> 0.169341).  Saving model\n","\n","Epoch Duration 51.07313632965088\n","Train Epoch: 39\tLoss: 0.188151\tTPR: 95.56025369978859\tTNR: 95.55641922528825\tTime: 1.250432\n","Val_loss: 0.188152\tTPR: 93.55509355509356\tTNR: 96.57631954350927\tTime: 8.164080\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 51.573094844818115\n","Train Epoch: 40\tLoss: 0.185119\tTPR: 96.63865546218487\tTNR: 96.03421461897355\tTime: 1.240802\n","Val_loss: 0.190647\tTPR: 93.18181818181817\tTNR: 96.53606642449402\tTime: 8.068862\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 51.130513429641724\n","Train Epoch: 41\tLoss: 0.179927\tTPR: 97.54098360655738\tTNR: 95.93717549325027\tTime: 1.240920\n","Val_loss: 0.174451\tTPR: 94.94736842105263\tTNR: 96.92885836464947\tTime: 8.300944\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 51.4248948097229\n","Train Epoch: 42\tLoss: 0.193117\tTPR: 95.37815126050421\tTNR: 95.99533437013997\tTime: 1.251689\n","Val_loss: 0.184875\tTPR: 94.35146443514645\tTNR: 96.78506611355976\tTime: 8.305979\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 51.70550990104675\n","Train Epoch: 43\tLoss: 0.202456\tTPR: 95.58823529411765\tTNR: 95.54173146708139\tTime: 1.345284\n","Val_loss: 0.171811\tTPR: 95.18828451882845\tTNR: 96.92766398755509\tTime: 8.495985\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 52.64905858039856\n","Train Epoch: 44\tLoss: 0.167353\tTPR: 97.87234042553192\tTNR: 96.06319606319606\tTime: 1.251412\n","Val_loss: 0.175205\tTPR: 94.91525423728814\tTNR: 96.80051813471503\tTime: 8.438293\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 52.06944918632507\n","Train Epoch: 45\tLoss: 0.205279\tTPR: 95.87628865979381\tTNR: 95.44569871545349\tTime: 1.233299\n","Val_loss: 0.197220\tTPR: 93.76299376299376\tTNR: 96.61522500324212\tTime: 8.035574\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 51.80066227912903\n","Train Epoch: 46\tLoss: 0.182074\tTPR: 96.19450317124736\tTNR: 95.8025650991061\tTime: 1.269386\n","Val_loss: 0.189379\tTPR: 93.6842105263158\tTNR: 96.87702475055073\tTime: 8.047391\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 51.40624785423279\n","Train Epoch: 47\tLoss: 0.174121\tTPR: 96.82875264270614\tTNR: 96.26894675476098\tTime: 1.219866\n","Val_loss: 0.180021\tTPR: 93.89473684210526\tTNR: 97.05844239989632\tTime: 8.088677\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 51.05783438682556\n","Train Epoch: 48\tLoss: 0.178944\tTPR: 96.82875264270614\tTNR: 96.03575592693355\tTime: 1.257239\n","Val_loss: 0.205794\tTPR: 91.12050739957716\tTNR: 96.90374400829123\tTime: 8.074676\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 51.20679235458374\n","Train Epoch: 49\tLoss: 0.178132\tTPR: 96.19450317124736\tTNR: 96.06166601891437\tTime: 1.285279\n","Val_loss: 0.195784\tTPR: 93.09623430962343\tTNR: 96.8369198859217\tTime: 8.030802\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 51.246293783187866\n","Train Epoch: 50\tLoss: 0.158237\tTPR: 97.67441860465115\tTNR: 96.3855421686747\tTime: 1.250196\n","Val_loss: 0.178072\tTPR: 94.10526315789474\tTNR: 96.96773357522353\tTime: 8.297332\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 51.34432291984558\n","Train Epoch: 51\tLoss: 0.174803\tTPR: 97.05882352941177\tTNR: 96.1767755313634\tTime: 1.249240\n","Val_loss: 0.181695\tTPR: 94.14225941422593\tTNR: 96.90173710137412\tTime: 8.118659\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 52.067988872528076\n","Train Epoch: 52\tLoss: 0.161392\tTPR: 97.67441860465115\tTNR: 96.20417152480891\tTime: 1.252246\n","Val_loss: 0.154364\tTPR: 95.44468546637745\tTNR: 97.18018367610917\tTime: 8.259808\n","\n","Validation loss decreased (0.169341 --> 0.154364).  Saving model\n","\n","Epoch Duration 52.59308123588562\n","Train Epoch: 53\tLoss: 0.196148\tTPR: 95.22821576763485\tTNR: 95.9792477302205\tTime: 1.277240\n","Val_loss: 0.203238\tTPR: 92.22689075630252\tTNR: 96.78589942975636\tTime: 8.331978\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 52.53157663345337\n","Train Epoch: 54\tLoss: 0.162736\tTPR: 97.25158562367865\tTNR: 96.3855421686747\tTime: 1.305768\n","Val_loss: 0.181882\tTPR: 93.26315789473684\tTNR: 97.11027601399508\tTime: 8.367240\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 52.85520935058594\n","Train Epoch: 55\tLoss: 0.179634\tTPR: 96.90721649484536\tTNR: 96.26313740755158\tTime: 1.273490\n","Val_loss: 0.213645\tTPR: 91.94214876033058\tTNR: 96.91229891022314\tTime: 8.344236\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 52.820765256881714\n","Train Epoch: 56\tLoss: 0.193639\tTPR: 95.49180327868852\tTNR: 96.14485981308411\tTime: 1.261998\n","Val_loss: 0.188858\tTPR: 93.72384937238493\tTNR: 96.92766398755509\tTime: 8.478991\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 52.57035803794861\n","Train Epoch: 57\tLoss: 0.175092\tTPR: 96.86847599164928\tTNR: 96.26604434072345\tTime: 1.272223\n","Val_loss: 0.184905\tTPR: 93.47368421052632\tTNR: 97.11027601399508\tTime: 8.105422\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 52.39876842498779\n","Train Epoch: 58\tLoss: 0.167867\tTPR: 97.07724425887265\tTNR: 96.36976533125892\tTime: 1.309943\n","Val_loss: 0.192372\tTPR: 92.51559251559252\tTNR: 96.90053170794968\tTime: 8.294424\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 52.19302272796631\n","Train Epoch: 59\tLoss: 0.165170\tTPR: 97.30290456431536\tTNR: 96.25162127107653\tTime: 1.263176\n","Val_loss: 0.186917\tTPR: 92.84210526315789\tTNR: 97.23986004924193\tTime: 8.357831\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 51.95769023895264\n","Train Epoch: 60\tLoss: 0.172580\tTPR: 95.69672131147541\tTNR: 96.56022845275182\tTime: 1.286699\n","Val_loss: 0.188484\tTPR: 93.40425531914893\tTNR: 97.17689717689719\tTime: 8.619540\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 52.850093603134155\n","Train Epoch: 61\tLoss: 0.176478\tTPR: 96.4509394572025\tTNR: 96.17528847400493\tTime: 1.266323\n","Val_loss: 0.197633\tTPR: 93.26315789473684\tTNR: 96.82519113645199\tTime: 8.443859\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 52.29847574234009\n","Train Epoch: 62\tLoss: 0.157597\tTPR: 98.31932773109243\tTNR: 96.29341627786417\tTime: 1.280019\n","Val_loss: 0.211551\tTPR: 92.60780287474333\tTNR: 96.87216093445814\tTime: 8.487960\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 52.36802864074707\n","Train Epoch: 63\tLoss: 0.178545\tTPR: 96.70103092783505\tTNR: 96.02958349552355\tTime: 1.308567\n","Val_loss: 0.180220\tTPR: 93.76299376299376\tTNR: 97.03021657372585\tTime: 8.599197\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 53.611732482910156\n","Train Epoch: 64\tLoss: 0.152001\tTPR: 97.67441860465115\tTNR: 96.56691281254048\tTime: 1.290679\n","Val_loss: 0.188272\tTPR: 93.09623430962343\tTNR: 97.19989629245528\tTime: 8.395607\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 52.75939130783081\n","Train Epoch: 65\tLoss: 0.173716\tTPR: 97.16599190283401\tTNR: 96.2847492855287\tTime: 1.280678\n","Val_loss: 0.197266\tTPR: 93.05263157894737\tTNR: 97.11027601399508\tTime: 8.487130\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 52.54963207244873\n","Train Epoch: 66\tLoss: 0.157692\tTPR: 97.28601252609603\tTNR: 96.47348632179438\tTime: 1.260778\n","Val_loss: 0.238994\tTPR: 89.6694214876033\tTNR: 97.02906071613909\tTime: 8.360620\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 52.246140241622925\n","Train Epoch: 67\tLoss: 0.172708\tTPR: 96.4509394572025\tTNR: 96.44755607416052\tTime: 1.268758\n","Val_loss: 0.199811\tTPR: 92.72349272349273\tTNR: 97.00427960057061\tTime: 8.149687\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 51.982765913009644\n","Train Epoch: 68\tLoss: 0.149832\tTPR: 98.10924369747899\tTNR: 96.61741835147744\tTime: 1.261067\n","Val_loss: 0.213363\tTPR: 92.51559251559252\tTNR: 96.88756322137206\tTime: 8.153805\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 51.852229595184326\n","Train Epoch: 69\tLoss: 0.161485\tTPR: 97.30290456431536\tTNR: 96.4461738002594\tTime: 1.246406\n","Val_loss: 0.160363\tTPR: 94.66950959488273\tTNR: 97.17726272174025\tTime: 8.264168\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 52.611881732940674\n","Train Epoch: 70\tLoss: 0.157080\tTPR: 97.65957446808511\tTNR: 96.62004662004662\tTime: 1.258320\n","Val_loss: 0.205037\tTPR: 91.78947368421052\tTNR: 97.0843592069457\tTime: 8.386784\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 52.13748121261597\n","Train Epoch: 71\tLoss: 0.151457\tTPR: 97.89915966386555\tTNR: 96.63037843442198\tTime: 1.242462\n","Val_loss: 0.212736\tTPR: 91.58110882956879\tTNR: 96.75535366645036\tTime: 8.341672\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 52.32540488243103\n","Train Epoch: 72\tLoss: 0.173096\tTPR: 96.21848739495799\tTNR: 96.33229652669777\tTime: 1.258009\n","Val_loss: 0.211520\tTPR: 91.47609147609148\tTNR: 96.95240565426015\tTime: 8.421271\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=1024, out_features=1, bias=True)\n",")\n","FO-13-WF-512-HS-2-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.156055\tTPR: 51.774530271398746\tTNR: 24.620770128354728\tTime: 0.983423\n","Val_loss: 0.718095\tTPR: 80.5439330543933\tTNR: 89.30515945035002\tTime: 7.982432\n","\n","Validation loss decreased (inf --> 0.718095).  Saving model\n","\n","Epoch Duration 42.56925344467163\n","Train Epoch: 1\tLoss: 0.763410\tTPR: 69.76744186046511\tTNR: 93.10791553310014\tTime: 0.990338\n","Val_loss: 0.528109\tTPR: 85.47368421052632\tTNR: 89.68511079435014\tTime: 7.817115\n","\n","Validation loss decreased (0.718095 --> 0.528109).  Saving model\n","\n","Epoch Duration 42.722108125686646\n","Train Epoch: 2\tLoss: 0.585986\tTPR: 76.97095435684648\tTNR: 90.72632944228275\tTime: 0.995942\n","Val_loss: 0.422489\tTPR: 90.8695652173913\tTNR: 90.3388515261252\tTime: 8.534555\n","\n","Validation loss decreased (0.528109 --> 0.422489).  Saving model\n","\n","Epoch Duration 43.637320041656494\n","Train Epoch: 3\tLoss: 0.491214\tTPR: 85.47717842323651\tTNR: 89.37743190661479\tTime: 1.051898\n","Val_loss: 0.380486\tTPR: 96.82875264270614\tTNR: 88.72910998834045\tTime: 7.900778\n","\n","Validation loss decreased (0.422489 --> 0.380486).  Saving model\n","\n","Epoch Duration 42.84786629676819\n","Train Epoch: 4\tLoss: 0.422298\tTPR: 91.23173277661796\tTNR: 88.92778426033968\tTime: 0.996188\n","Val_loss: 0.357407\tTPR: 96.91991786447639\tTNR: 89.30564568462037\tTime: 7.717045\n","\n","Validation loss decreased (0.380486 --> 0.357407).  Saving model\n","\n","Epoch Duration 42.063650131225586\n","Train Epoch: 5\tLoss: 0.383892\tTPR: 92.11618257261411\tTNR: 88.98832684824902\tTime: 1.007521\n","Val_loss: 0.337553\tTPR: 97.5359342915811\tTNR: 89.33160285528878\tTime: 8.479432\n","\n","Validation loss decreased (0.357407 --> 0.337553).  Saving model\n","\n","Epoch Duration 43.38324332237244\n","Train Epoch: 6\tLoss: 0.347124\tTPR: 93.61702127659575\tTNR: 90.13209013209014\tTime: 1.021598\n","Val_loss: 0.294661\tTPR: 97.21030042918454\tTNR: 90.86202433341963\tTime: 7.744377\n","\n","Validation loss decreased (0.337553 --> 0.294661).  Saving model\n","\n","Epoch Duration 42.73621320724487\n","Train Epoch: 7\tLoss: 0.335387\tTPR: 93.3609958506224\tTNR: 90.19455252918289\tTime: 0.975145\n","Val_loss: 0.288702\tTPR: 97.45762711864407\tTNR: 90.88082901554404\tTime: 7.644635\n","\n","Validation loss decreased (0.294661 --> 0.288702).  Saving model\n","\n","Epoch Duration 42.04850435256958\n","Train Epoch: 8\tLoss: 0.315197\tTPR: 94.11764705882352\tTNR: 90.88906168999482\tTime: 0.979769\n","Val_loss: 0.265310\tTPR: 97.03389830508475\tTNR: 91.90414507772022\tTime: 7.703557\n","\n","Validation loss decreased (0.288702 --> 0.265310).  Saving model\n","\n","Epoch Duration 41.89387655258179\n","Train Epoch: 9\tLoss: 0.300022\tTPR: 94.25531914893617\tTNR: 91.38824138824138\tTime: 1.009753\n","Val_loss: 0.263695\tTPR: 97.05263157894737\tTNR: 92.25087469223791\tTime: 7.702965\n","\n","Validation loss decreased (0.265310 --> 0.263695).  Saving model\n","\n","Epoch Duration 42.35418343544006\n","Train Epoch: 10\tLoss: 0.297563\tTPR: 93.73695198329854\tTNR: 91.59859976662777\tTime: 0.987244\n","Val_loss: 0.259641\tTPR: 96.44351464435147\tTNR: 93.23308270676691\tTime: 7.955104\n","\n","Validation loss decreased (0.263695 --> 0.259641).  Saving model\n","\n","Epoch Duration 43.338953495025635\n","Train Epoch: 11\tLoss: 0.288858\tTPR: 94.71458773784354\tTNR: 92.07151185386708\tTime: 1.041412\n","Val_loss: 0.252416\tTPR: 96.4509394572025\tTNR: 93.27110073901206\tTime: 7.949577\n","\n","Validation loss decreased (0.259641 --> 0.252416).  Saving model\n","\n","Epoch Duration 43.00162386894226\n","Train Epoch: 12\tLoss: 0.262107\tTPR: 94.71458773784354\tTNR: 92.66744396942609\tTime: 1.018162\n","Val_loss: 0.259212\tTPR: 94.8024948024948\tTNR: 93.41200881857087\tTime: 7.978274\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 42.91797661781311\n","Train Epoch: 13\tLoss: 0.263216\tTPR: 97.9253112033195\tTNR: 92.15304798962386\tTime: 0.977882\n","Val_loss: 0.246359\tTPR: 93.6842105263158\tTNR: 94.22055202799015\tTime: 7.798558\n","\n","Validation loss decreased (0.252416 --> 0.246359).  Saving model\n","\n","Epoch Duration 42.36005616188049\n","Train Epoch: 14\tLoss: 0.246403\tTPR: 97.23404255319149\tTNR: 93.13649313649314\tTime: 1.013836\n","Val_loss: 0.250811\tTPR: 93.93305439330544\tTNR: 94.37386569872959\tTime: 7.995313\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 42.60514187812805\n","Train Epoch: 15\tLoss: 0.259377\tTPR: 96.70103092783505\tTNR: 92.7468535097963\tTime: 0.995178\n","Val_loss: 0.251921\tTPR: 93.69747899159664\tTNR: 94.36236391912908\tTime: 7.802089\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 42.235719203948975\n","Train Epoch: 16\tLoss: 0.236923\tTPR: 97.05882352941177\tTNR: 93.41627786417833\tTime: 0.993163\n","Val_loss: 0.272754\tTPR: 91.42259414225941\tTNR: 95.1387088410682\tTime: 8.002914\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 42.85208797454834\n","Train Epoch: 17\tLoss: 0.231308\tTPR: 97.04016913319239\tTNR: 94.0536338904003\tTime: 1.040706\n","Val_loss: 0.243795\tTPR: 90.45553145336225\tTNR: 95.74440563963265\tTime: 7.915638\n","\n","Validation loss decreased (0.246359 --> 0.243795).  Saving model\n","\n","Epoch Duration 43.57626795768738\n","Train Epoch: 18\tLoss: 0.245060\tTPR: 97.5103734439834\tTNR: 93.34630350194553\tTime: 0.978577\n","Val_loss: 0.251224\tTPR: 91.42259414225941\tTNR: 95.41094114596837\tTime: 7.822965\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 42.70914030075073\n","Train Epoch: 19\tLoss: 0.230994\tTPR: 96.28865979381443\tTNR: 94.00544959128065\tTime: 1.014180\n","Val_loss: 0.273931\tTPR: 88.69936034115139\tTNR: 95.93422245241486\tTime: 7.891090\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 42.76023459434509\n","Train Epoch: 20\tLoss: 0.225814\tTPR: 96.86847599164928\tTNR: 94.43796188253599\tTime: 0.998491\n","Val_loss: 0.237755\tTPR: 91.8918918918919\tTNR: 95.44806121125666\tTime: 8.080559\n","\n","Validation loss decreased (0.243795 --> 0.237755).  Saving model\n","\n","Epoch Duration 43.07309651374817\n","Train Epoch: 21\tLoss: 0.215141\tTPR: 96.55172413793103\tTNR: 94.53933747412007\tTime: 1.042650\n","Val_loss: 0.287841\tTPR: 87.36842105263159\tTNR: 96.33277180251393\tTime: 8.044395\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 42.66734194755554\n","Train Epoch: 22\tLoss: 0.220781\tTPR: 96.61733615221986\tTNR: 94.57183573001684\tTime: 1.032488\n","Val_loss: 0.296236\tTPR: 87.88501026694045\tTNR: 95.95068137573004\tTime: 8.129574\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 43.271307706832886\n","Train Epoch: 23\tLoss: 0.213702\tTPR: 97.68907563025209\tTNR: 94.64748574390876\tTime: 0.983266\n","Val_loss: 0.277360\tTPR: 88.21052631578948\tTNR: 96.29389659193987\tTime: 7.937661\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 42.87200212478638\n","Train Epoch: 24\tLoss: 0.232848\tTPR: 95.19832985386222\tTNR: 94.54168287307144\tTime: 1.007119\n","Val_loss: 0.293461\tTPR: 87.63326226012794\tTNR: 96.30972420044024\tTime: 7.960019\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 44.256123542785645\n","Train Epoch: 25\tLoss: 0.205152\tTPR: 98.12108559498957\tTNR: 94.73615973032543\tTime: 1.014228\n","Val_loss: 0.300820\tTPR: 86.05150214592274\tTNR: 97.13952886357752\tTime: 8.055501\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 42.92285680770874\n","Train Epoch: 26\tLoss: 0.211279\tTPR: 96.28865979381443\tTNR: 95.2770208900999\tTime: 1.010473\n","Val_loss: 0.255620\tTPR: 87.20682302771856\tTNR: 96.69817428460443\tTime: 7.904947\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 42.546245098114014\n","Train Epoch: 27\tLoss: 0.199397\tTPR: 96.40591966173362\tTNR: 95.6082394092499\tTime: 1.048806\n","Val_loss: 0.281738\tTPR: 86.4406779661017\tTNR: 96.98186528497409\tTime: 8.084862\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 42.54877424240112\n","Train Epoch: 28\tLoss: 0.200289\tTPR: 96.6804979253112\tTNR: 95.4993514915694\tTime: 0.971377\n","Val_loss: 0.270024\tTPR: 85.4389721627409\tTNR: 96.97087378640776\tTime: 7.668294\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 41.870182037353516\n","Train Epoch: 29\tLoss: 0.187196\tTPR: 96.84873949579831\tTNR: 95.76205287713842\tTime: 0.976688\n","Val_loss: 0.268964\tTPR: 89.05263157894737\tTNR: 96.69560710120513\tTime: 7.760295\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 42.3129563331604\n","Train Epoch: 30\tLoss: 0.185445\tTPR: 97.30290456431536\tTNR: 95.40856031128405\tTime: 0.992743\n","Val_loss: 0.272587\tTPR: 87.94178794178794\tTNR: 96.31694981195695\tTime: 7.623323\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 41.99269461631775\n","Train Epoch: 31\tLoss: 0.195824\tTPR: 95.9830866807611\tTNR: 95.84143023707735\tTime: 0.962113\n","Val_loss: 0.241579\tTPR: 90.3765690376569\tTNR: 96.56468758102153\tTime: 8.439815\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 42.86732530593872\n","Train Epoch: 32\tLoss: 0.180302\tTPR: 97.87234042553192\tTNR: 95.92074592074592\tTime: 1.067756\n","Val_loss: 0.253969\tTPR: 89.3970893970894\tTNR: 96.66709894955258\tTime: 7.744049\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 42.12996053695679\n","Train Epoch: 33\tLoss: 0.176517\tTPR: 97.65957446808511\tTNR: 95.93369593369593\tTime: 0.991181\n","Val_loss: 0.228439\tTPR: 90.02079002079002\tTNR: 96.51147711062119\tTime: 7.902717\n","\n","Validation loss decreased (0.237755 --> 0.228439).  Saving model\n","\n","Epoch Duration 43.0840482711792\n","Train Epoch: 34\tLoss: 0.194863\tTPR: 95.90163934426229\tTNR: 95.8073727933541\tTime: 1.015445\n","Val_loss: 0.267093\tTPR: 86.84759916492693\tTNR: 96.68092830286528\tTime: 7.923218\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 42.928847789764404\n","Train Epoch: 35\tLoss: 0.178750\tTPR: 97.4947807933194\tTNR: 96.21418384545572\tTime: 1.017940\n","Val_loss: 0.289496\tTPR: 89.1213389121339\tTNR: 97.005444646098\tTime: 7.802349\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 42.549166679382324\n","Train Epoch: 36\tLoss: 0.180788\tTPR: 96.4509394572025\tTNR: 95.92895112148321\tTime: 0.973130\n","Val_loss: 0.245160\tTPR: 88.0\tTNR: 96.98069197874823\tTime: 7.628919\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 41.751667499542236\n","Train Epoch: 37\tLoss: 0.166932\tTPR: 98.09725158562368\tTNR: 96.39849721466511\tTime: 0.979095\n","Val_loss: 0.269105\tTPR: 87.65690376569037\tTNR: 96.84988332901219\tTime: 7.606363\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 41.72841691970825\n","Train Epoch: 38\tLoss: 0.171707\tTPR: 97.44680851063829\tTNR: 96.32219632219632\tTime: 0.959736\n","Val_loss: 0.288357\tTPR: 86.9022869022869\tTNR: 96.62819348981974\tTime: 7.826451\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 42.02128601074219\n","Train Epoch: 39\tLoss: 0.191819\tTPR: 95.87628865979381\tTNR: 96.04255871285844\tTime: 0.964948\n","Val_loss: 0.219861\tTPR: 90.54621848739495\tTNR: 96.99326075686885\tTime: 7.787899\n","\n","Validation loss decreased (0.228439 --> 0.219861).  Saving model\n","\n","Epoch Duration 42.94046711921692\n","Train Epoch: 40\tLoss: 0.177340\tTPR: 97.5103734439834\tTNR: 96.21271076523995\tTime: 1.015958\n","Val_loss: 0.358918\tTPR: 85.3305785123967\tTNR: 96.574987026466\tTime: 7.752529\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 42.71437478065491\n","Train Epoch: 41\tLoss: 0.177258\tTPR: 96.70103092783505\tTNR: 96.17231088620734\tTime: 1.032511\n","Val_loss: 0.212127\tTPR: 91.73728813559322\tTNR: 96.82642487046633\tTime: 7.714511\n","\n","Validation loss decreased (0.219861 --> 0.212127).  Saving model\n","\n","Epoch Duration 42.77687692642212\n","Train Epoch: 42\tLoss: 0.174558\tTPR: 98.37067209775967\tTNR: 95.93559278015842\tTime: 0.996650\n","Val_loss: 0.248025\tTPR: 87.5\tTNR: 97.13730569948187\tTime: 7.722417\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 41.91314506530762\n","Train Epoch: 43\tLoss: 0.171045\tTPR: 97.26890756302521\tTNR: 96.29341627786417\tTime: 0.977235\n","Val_loss: 0.275914\tTPR: 87.92372881355932\tTNR: 97.29274611398964\tTime: 7.726811\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 42.083555698394775\n","Train Epoch: 44\tLoss: 0.169038\tTPR: 97.9381443298969\tTNR: 96.18528610354224\tTime: 0.984132\n","Val_loss: 0.279060\tTPR: 88.56548856548856\tTNR: 97.22474387239009\tTime: 7.792609\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 41.99248695373535\n","Train Epoch: 45\tLoss: 0.173928\tTPR: 96.21848739495799\tTNR: 96.37117677553137\tTime: 1.005164\n","Val_loss: 0.325783\tTPR: 85.03118503118503\tTNR: 97.30255479185578\tTime: 7.691729\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 42.09882712364197\n","Train Epoch: 46\tLoss: 0.165874\tTPR: 97.0954356846473\tTNR: 96.47211413748379\tTime: 1.040267\n","Val_loss: 0.255613\tTPR: 89.3305439330544\tTNR: 96.86284677210267\tTime: 7.917136\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 43.513574838638306\n","Train Epoch: 47\tLoss: 0.168875\tTPR: 97.67441860465115\tTNR: 96.32076693872264\tTime: 0.995685\n","Val_loss: 0.313478\tTPR: 87.02928870292888\tTNR: 97.2647135079077\tTime: 7.910955\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 42.654149293899536\n","Train Epoch: 48\tLoss: 0.154787\tTPR: 97.88583509513742\tTNR: 96.51509262857884\tTime: 0.989315\n","Val_loss: 0.283484\tTPR: 88.0\tTNR: 97.17506803161851\tTime: 8.014149\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 42.796056509017944\n","Train Epoch: 49\tLoss: 0.151652\tTPR: 98.10924369747899\tTNR: 96.60445826853292\tTime: 1.022335\n","Val_loss: 0.226746\tTPR: 90.12605042016807\tTNR: 97.23950233281494\tTime: 7.806242\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 42.262903690338135\n","Train Epoch: 50\tLoss: 0.167311\tTPR: 97.28601252609603\tTNR: 96.33086995980811\tTime: 0.969642\n","Val_loss: 0.256429\tTPR: 88.84297520661157\tTNR: 97.26258432797094\tTime: 7.756081\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 42.18828868865967\n","Train Epoch: 51\tLoss: 0.163777\tTPR: 97.0954356846473\tTNR: 96.31647211413748\tTime: 0.978990\n","Val_loss: 0.282945\tTPR: 88.62660944206009\tTNR: 97.81258089567693\tTime: 7.657717\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 41.80889129638672\n","Train Epoch: 52\tLoss: 0.156675\tTPR: 97.07724425887265\tTNR: 96.73278879813302\tTime: 1.018583\n","Val_loss: 0.267672\tTPR: 86.65254237288136\tTNR: 97.30569948186528\tTime: 7.775830\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 41.868674516677856\n","Train Epoch: 53\tLoss: 0.158281\tTPR: 97.7035490605428\tTNR: 96.71982367431609\tTime: 0.974312\n","Val_loss: 0.312979\tTPR: 85.41226215644821\tTNR: 97.38308070993652\tTime: 8.251685\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 42.637139081954956\n","Train Epoch: 54\tLoss: 0.172543\tTPR: 96.05809128630706\tTNR: 96.65369649805447\tTime: 1.053091\n","Val_loss: 0.323216\tTPR: 86.27858627858627\tTNR: 97.41927117105433\tTime: 7.936593\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 42.5159330368042\n","Train Epoch: 55\tLoss: 0.150441\tTPR: 97.89915966386555\tTNR: 96.74701918092275\tTime: 0.975195\n","Val_loss: 0.364222\tTPR: 86.01694915254238\tTNR: 97.73316062176166\tTime: 7.857333\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 42.39125990867615\n","Train Epoch: 56\tLoss: 0.156400\tTPR: 97.30290456431536\tTNR: 96.65369649805447\tTime: 0.979476\n","Val_loss: 0.299225\tTPR: 88.22314049586777\tTNR: 97.11987545407369\tTime: 7.869604\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 42.71196937561035\n","Train Epoch: 57\tLoss: 0.154529\tTPR: 97.5103734439834\tTNR: 96.79636835278859\tTime: 0.967957\n","Val_loss: 0.319756\tTPR: 89.1891891891892\tTNR: 97.41927117105433\tTime: 7.865242\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 42.354881286621094\n","Train Epoch: 58\tLoss: 0.153082\tTPR: 97.88583509513742\tTNR: 96.82601373234874\tTime: 1.010691\n","Val_loss: 0.261647\tTPR: 87.1578947368421\tTNR: 97.5508617338344\tTime: 7.787081\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 42.68868803977966\n","Train Epoch: 59\tLoss: 0.148209\tTPR: 97.91231732776617\tTNR: 96.82354466485154\tTime: 0.973784\n","Val_loss: 0.235405\tTPR: 90.73684210526316\tTNR: 97.31761047039005\tTime: 7.783163\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 42.35995531082153\n","Train Epoch: 60\tLoss: 0.156361\tTPR: 97.30290456431536\tTNR: 96.7704280155642\tTime: 1.007920\n","Val_loss: 0.328521\tTPR: 85.53719008264463\tTNR: 97.5609756097561\tTime: 7.806012\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 42.518434047698975\n","Train Epoch: 61\tLoss: 0.149995\tTPR: 97.25158562367865\tTNR: 96.89078896230082\tTime: 0.986380\n","Val_loss: 0.269790\tTPR: 87.23849372384937\tTNR: 97.38138449572207\tTime: 7.918530\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 512, num_layers=5, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=1024, out_features=1, bias=True)\n",")\n","FO-13-WF-512-HS-5-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.065450\tTPR: 46.723044397463006\tTNR: 54.37232802176448\tTime: 1.305275\n","Val_loss: 0.880436\tTPR: 49.48024948024948\tTNR: 97.27661781870056\tTime: 8.321780\n","\n","Validation loss decreased (inf --> 0.880436).  Saving model\n","\n","Epoch Duration 52.05510449409485\n","Train Epoch: 1\tLoss: 0.910398\tTPR: 42.47422680412371\tTNR: 98.17049435578046\tTime: 1.247074\n","Val_loss: 0.505406\tTPR: 73.01255230125523\tTNR: 90.57557687321753\tTime: 8.462697\n","\n","Validation loss decreased (0.880436 --> 0.505406).  Saving model\n","\n","Epoch Duration 52.40655851364136\n","Train Epoch: 2\tLoss: 0.546533\tTPR: 65.12605042016807\tTNR: 92.53499222395023\tTime: 1.251472\n","Val_loss: 0.367265\tTPR: 93.22381930184805\tTNR: 88.05970149253731\tTime: 8.357091\n","\n","Validation loss decreased (0.505406 --> 0.367265).  Saving model\n","\n","Epoch Duration 52.187560081481934\n","Train Epoch: 3\tLoss: 0.380163\tTPR: 91.44050104384134\tTNR: 88.1369117075068\tTime: 1.254103\n","Val_loss: 0.308091\tTPR: 97.04016913319239\tTNR: 89.53232283974609\tTime: 8.328264\n","\n","Validation loss decreased (0.367265 --> 0.308091).  Saving model\n","\n","Epoch Duration 52.342166900634766\n","Train Epoch: 4\tLoss: 0.323630\tTPR: 95.34883720930233\tTNR: 89.49345770177484\tTime: 1.250655\n","Val_loss: 0.290934\tTPR: 95.86776859504133\tTNR: 90.58121432278152\tTime: 8.276331\n","\n","Validation loss decreased (0.308091 --> 0.290934).  Saving model\n","\n","Epoch Duration 51.85449504852295\n","Train Epoch: 5\tLoss: 0.297758\tTPR: 95.53191489361701\tTNR: 90.74074074074075\tTime: 1.289722\n","Val_loss: 0.278504\tTPR: 96.25779625779626\tTNR: 92.12812864738686\tTime: 8.203518\n","\n","Validation loss decreased (0.290934 --> 0.278504).  Saving model\n","\n","Epoch Duration 52.113526821136475\n","Train Epoch: 6\tLoss: 0.279651\tTPR: 95.77167019027483\tTNR: 91.98082653193418\tTime: 1.245935\n","Val_loss: 0.254057\tTPR: 96.84210526315789\tTNR: 92.60075158740443\tTime: 8.139730\n","\n","Validation loss decreased (0.278504 --> 0.254057).  Saving model\n","\n","Epoch Duration 51.33478665351868\n","Train Epoch: 7\tLoss: 0.279284\tTPR: 96.4509394572025\tTNR: 92.35057694800986\tTime: 1.252323\n","Val_loss: 0.228340\tTPR: 97.0893970893971\tTNR: 94.28089741927117\tTime: 8.205433\n","\n","Validation loss decreased (0.254057 --> 0.228340).  Saving model\n","\n","Epoch Duration 51.10364270210266\n","Train Epoch: 8\tLoss: 0.251006\tTPR: 95.74468085106383\tTNR: 93.74514374514375\tTime: 1.242772\n","Val_loss: 0.210542\tTPR: 97.03389830508475\tTNR: 94.94818652849742\tTime: 8.274640\n","\n","Validation loss decreased (0.228340 --> 0.210542).  Saving model\n","\n","Epoch Duration 51.2218291759491\n","Train Epoch: 9\tLoss: 0.244668\tTPR: 95.95744680851064\tTNR: 93.8875938875939\tTime: 1.272423\n","Val_loss: 0.219766\tTPR: 93.85593220338984\tTNR: 95.19430051813471\tTime: 8.188424\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 51.5114631652832\n","Train Epoch: 10\tLoss: 0.219656\tTPR: 96.1456102783726\tTNR: 95.042071197411\tTime: 1.306833\n","Val_loss: 0.215731\tTPR: 94.94736842105263\tTNR: 95.30905792406375\tTime: 8.278085\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 51.70605182647705\n","Train Epoch: 11\tLoss: 0.237864\tTPR: 94.39834024896265\tTNR: 94.70817120622567\tTime: 1.250840\n","Val_loss: 0.201302\tTPR: 95.87852494577007\tTNR: 95.71853576510154\tTime: 8.089728\n","\n","Validation loss decreased (0.210542 --> 0.201302).  Saving model\n","\n","Epoch Duration 51.81523942947388\n","Train Epoch: 12\tLoss: 0.220478\tTPR: 97.04016913319239\tTNR: 94.27386967223732\tTime: 1.246503\n","Val_loss: 0.229476\tTPR: 92.14876033057851\tTNR: 95.55007784120394\tTime: 8.100465\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 51.11245131492615\n","Train Epoch: 13\tLoss: 0.228145\tTPR: 95.0207468879668\tTNR: 95.01945525291828\tTime: 1.222472\n","Val_loss: 0.220973\tTPR: 94.0677966101695\tTNR: 96.06217616580311\tTime: 8.106918\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 50.812594413757324\n","Train Epoch: 14\tLoss: 0.208629\tTPR: 97.68907563025209\tTNR: 94.27164333851736\tTime: 1.216550\n","Val_loss: 0.215146\tTPR: 93.26315789473684\tTNR: 96.04768692497085\tTime: 8.393463\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 51.40398073196411\n","Train Epoch: 15\tLoss: 0.219423\tTPR: 95.4356846473029\tTNR: 95.04539559014266\tTime: 1.270929\n","Val_loss: 0.207366\tTPR: 92.27467811158799\tTNR: 96.42764690654931\tTime: 8.287295\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 51.123892068862915\n","Train Epoch: 16\tLoss: 0.213187\tTPR: 96.6804979253112\tTNR: 94.88975356679636\tTime: 1.229715\n","Val_loss: 0.200943\tTPR: 92.42105263157895\tTNR: 96.7215239082545\tTime: 8.226185\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 52.083147048950195\n","Train Epoch: 17\tLoss: 0.217441\tTPR: 92.76595744680851\tTNR: 95.45454545454545\tTime: 1.271386\n","Val_loss: 0.207884\tTPR: 91.68443496801706\tTNR: 96.76291596529846\tTime: 8.317015\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 52.52259349822998\n","Train Epoch: 18\tLoss: 0.191145\tTPR: 97.46300211416491\tTNR: 95.29731830547999\tTime: 1.230110\n","Val_loss: 0.198709\tTPR: 92.11087420042644\tTNR: 96.72407095688203\tTime: 8.245522\n","\n","Validation loss decreased (0.201302 --> 0.198709).  Saving model\n","\n","Epoch Duration 51.69501042366028\n","Train Epoch: 19\tLoss: 0.192473\tTPR: 97.44680851063829\tTNR: 95.60994560994561\tTime: 1.221898\n","Val_loss: 0.214750\tTPR: 91.68399168399168\tTNR: 96.45960316431072\tTime: 8.465198\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 51.741376638412476\n","Train Epoch: 20\tLoss: 0.187980\tTPR: 97.91231732776617\tTNR: 95.50110203552444\tTime: 1.230391\n","Val_loss: 0.216641\tTPR: 92.3076923076923\tTNR: 96.45960316431072\tTime: 8.314923\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 51.547144651412964\n","Train Epoch: 21\tLoss: 0.193901\tTPR: 97.52577319587628\tTNR: 95.04346697807188\tTime: 1.261825\n","Val_loss: 0.208260\tTPR: 91.3135593220339\tTNR: 96.87823834196891\tTime: 8.504461\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 51.860493183135986\n","Train Epoch: 22\tLoss: 0.188386\tTPR: 96.63865546218487\tTNR: 95.64541213063764\tTime: 1.260793\n","Val_loss: 0.223467\tTPR: 92.35537190082644\tTNR: 96.36741048261547\tTime: 8.465833\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 51.91343021392822\n","Train Epoch: 23\tLoss: 0.217841\tTPR: 94.39834024896265\tTNR: 94.91569390402074\tTime: 1.279790\n","Val_loss: 0.250928\tTPR: 89.46280991735537\tTNR: 96.47119875454074\tTime: 8.586701\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 53.0933895111084\n","Train Epoch: 24\tLoss: 0.187463\tTPR: 95.34883720930233\tTNR: 96.20417152480891\tTime: 1.312370\n","Val_loss: 0.233116\tTPR: 91.80672268907563\tTNR: 96.6433385173665\tTime: 8.563542\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 52.535444021224976\n","Train Epoch: 25\tLoss: 0.173178\tTPR: 98.08510638297872\tTNR: 95.72649572649573\tTime: 1.278751\n","Val_loss: 0.209475\tTPR: 92.0\tTNR: 96.6308150835817\tTime: 8.449886\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 52.41186308860779\n","Train Epoch: 26\tLoss: 0.180387\tTPR: 97.05882352941177\tTNR: 95.52877138413686\tTime: 1.295180\n","Val_loss: 0.195568\tTPR: 92.37288135593221\tTNR: 96.96891191709844\tTime: 8.531444\n","\n","Validation loss decreased (0.198709 --> 0.195568).  Saving model\n","\n","Epoch Duration 52.97222685813904\n","Train Epoch: 27\tLoss: 0.172439\tTPR: 97.71784232365145\tTNR: 95.56420233463035\tTime: 1.286791\n","Val_loss: 0.220672\tTPR: 90.10526315789474\tTNR: 97.07140080342101\tTime: 8.611026\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 53.38205289840698\n","Train Epoch: 28\tLoss: 0.176181\tTPR: 95.37815126050421\tTNR: 95.99533437013997\tTime: 1.281321\n","Val_loss: 0.205121\tTPR: 92.16101694915254\tTNR: 97.15025906735751\tTime: 8.486953\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 52.89381814002991\n","Train Epoch: 29\tLoss: 0.159360\tTPR: 98.53862212943632\tTNR: 95.98081161675094\tTime: 1.291959\n","Val_loss: 0.209187\tTPR: 91.84100418410041\tTNR: 96.99248120300751\tTime: 8.434532\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 52.81781005859375\n","Train Epoch: 30\tLoss: 0.166054\tTPR: 97.31958762886597\tTNR: 95.8349552355002\tTime: 1.255152\n","Val_loss: 0.212622\tTPR: 90.85106382978724\tTNR: 97.29344729344729\tTime: 8.653324\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 53.002604722976685\n","Train Epoch: 31\tLoss: 0.168298\tTPR: 95.37815126050421\tTNR: 96.56557801969933\tTime: 1.297068\n","Val_loss: 0.220868\tTPR: 90.63829787234042\tTNR: 97.31934731934732\tTime: 8.686130\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 53.098729372024536\n","Train Epoch: 32\tLoss: 0.161315\tTPR: 96.42857142857143\tTNR: 96.57853810264385\tTime: 1.328463\n","Val_loss: 0.216565\tTPR: 91.42259414225941\tTNR: 97.0832253046409\tTime: 8.690814\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 52.94341540336609\n","Train Epoch: 33\tLoss: 0.171707\tTPR: 97.75967413441956\tTNR: 95.79275418776783\tTime: 1.272903\n","Val_loss: 0.281810\tTPR: 88.37675350701403\tTNR: 96.90627843494084\tTime: 8.849069\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 52.89529752731323\n","Train Epoch: 34\tLoss: 0.160411\tTPR: 96.49484536082474\tTNR: 96.45776566757493\tTime: 1.288852\n","Val_loss: 0.201723\tTPR: 91.80672268907563\tTNR: 97.20062208398133\tTime: 8.568352\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 52.56135368347168\n","Train Epoch: 35\tLoss: 0.149126\tTPR: 97.05882352941177\tTNR: 96.85069984447901\tTime: 1.276290\n","Val_loss: 0.221799\tTPR: 90.9090909090909\tTNR: 97.30535043399404\tTime: 8.627994\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 53.26512026786804\n","Train Epoch: 36\tLoss: 0.147848\tTPR: 97.46300211416491\tTNR: 96.70941831843503\tTime: 1.252440\n","Val_loss: 0.181998\tTPR: 93.09623430962343\tTNR: 97.35545760954109\tTime: 8.639056\n","\n","Validation loss decreased (0.195568 --> 0.181998).  Saving model\n","\n","Epoch Duration 52.84063220024109\n","Train Epoch: 37\tLoss: 0.146738\tTPR: 97.7035490605428\tTNR: 96.8494749124854\tTime: 4.398708\n","Val_loss: 0.179729\tTPR: 92.32409381663112\tTNR: 97.44917778065518\tTime: 8.716931\n","\n","Validation loss decreased (0.181998 --> 0.179729).  Saving model\n","\n","Epoch Duration 56.78077006340027\n","Train Epoch: 38\tLoss: 0.148629\tTPR: 98.35051546391752\tTNR: 96.63941871026339\tTime: 1.304850\n","Val_loss: 0.224849\tTPR: 90.66937119675457\tTNR: 96.92167814001819\tTime: 8.784944\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 53.632519245147705\n","Train Epoch: 39\tLoss: 0.154877\tTPR: 97.31958762886597\tTNR: 96.6523939275983\tTime: 1.293339\n","Val_loss: 0.222382\tTPR: 91.21338912133892\tTNR: 97.13507907700286\tTime: 8.783766\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 53.74682664871216\n","Train Epoch: 40\tLoss: 0.142398\tTPR: 97.46300211416491\tTNR: 97.08511465215702\tTime: 1.283468\n","Val_loss: 0.174384\tTPR: 93.47368421052632\tTNR: 97.52494492678501\tTime: 9.387824\n","\n","Validation loss decreased (0.179729 --> 0.174384).  Saving model\n","\n","Epoch Duration 54.162261962890625\n","Train Epoch: 41\tLoss: 0.150294\tTPR: 97.31958762886597\tTNR: 96.83404697028675\tTime: 1.327427\n","Val_loss: 0.202485\tTPR: 91.0041841004184\tTNR: 97.53694581280789\tTime: 8.625940\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 53.16145634651184\n","Train Epoch: 42\tLoss: 0.151875\tTPR: 98.32985386221294\tTNR: 96.94023077920394\tTime: 1.278960\n","Val_loss: 0.211344\tTPR: 92.05020920502092\tTNR: 97.1869328493648\tTime: 8.749959\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 52.936060667037964\n","Train Epoch: 43\tLoss: 0.133936\tTPR: 98.73949579831933\tTNR: 96.83773976153446\tTime: 1.282204\n","Val_loss: 0.208579\tTPR: 91.15789473684211\tTNR: 97.57677854088377\tTime: 8.941303\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 53.34957480430603\n","Train Epoch: 44\tLoss: 0.150469\tTPR: 97.5103734439834\tTNR: 96.96498054474708\tTime: 1.295358\n","Val_loss: 0.171668\tTPR: 92.75053304904051\tTNR: 97.61750615045966\tTime: 8.810532\n","\n","Validation loss decreased (0.174384 --> 0.171668).  Saving model\n","\n","Epoch Duration 53.70096516609192\n","Train Epoch: 45\tLoss: 0.134800\tTPR: 98.10924369747899\tTNR: 97.12286158631416\tTime: 1.306432\n","Val_loss: 0.201043\tTPR: 91.57894736842105\tTNR: 97.48606971621096\tTime: 8.642692\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 53.43542981147766\n","Train Epoch: 46\tLoss: 0.138799\tTPR: 97.25158562367865\tTNR: 97.43490089389817\tTime: 1.299879\n","Val_loss: 0.190067\tTPR: 91.86295503211991\tTNR: 97.46278317152104\tTime: 8.519546\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 53.9703586101532\n","Train Epoch: 47\tLoss: 0.142434\tTPR: 97.47899159663865\tTNR: 96.91550025920166\tTime: 1.259610\n","Val_loss: 0.230980\tTPR: 90.43659043659044\tTNR: 97.26364933212294\tTime: 8.439681\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 53.324777126312256\n","Train Epoch: 48\tLoss: 0.128363\tTPR: 98.28693790149893\tTNR: 97.29449838187702\tTime: 1.245209\n","Val_loss: 0.190665\tTPR: 91.0041841004184\tTNR: 97.71843401607467\tTime: 8.414179\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 52.69567275047302\n","Train Epoch: 49\tLoss: 0.157462\tTPR: 96.70103092783505\tTNR: 96.91189827429609\tTime: 1.221354\n","Val_loss: 0.224238\tTPR: 91.02296450939458\tTNR: 97.53662647478284\tTime: 8.312400\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 52.48171544075012\n","Train Epoch: 50\tLoss: 0.140068\tTPR: 97.4947807933194\tTNR: 97.10877738882407\tTime: 1.253649\n","Val_loss: 0.224784\tTPR: 91.0041841004184\tTNR: 97.35545760954109\tTime: 8.520826\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 52.373433113098145\n","Train Epoch: 51\tLoss: 0.140317\tTPR: 97.9381443298969\tTNR: 96.87297262229141\tTime: 1.290214\n","Val_loss: 0.175418\tTPR: 92.96375266524521\tTNR: 97.77288618412534\tTime: 8.322855\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 52.2588427066803\n","Train Epoch: 52\tLoss: 0.138360\tTPR: 97.28601252609603\tTNR: 97.21249837935953\tTime: 1.247286\n","Val_loss: 0.221925\tTPR: 91.36842105263158\tTNR: 97.56382013735909\tTime: 8.423783\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 53.2165470123291\n","Train Epoch: 53\tLoss: 0.123873\tTPR: 98.72340425531915\tTNR: 97.38409738409737\tTime: 1.236826\n","Val_loss: 0.263083\tTPR: 89.8580121703854\tTNR: 97.27237303545915\tTime: 8.364941\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 52.35095167160034\n","Train Epoch: 54\tLoss: 0.120962\tTPR: 98.72340425531915\tTNR: 97.57834757834758\tTime: 1.283838\n","Val_loss: 0.222755\tTPR: 90.08264462809917\tTNR: 97.44421380384016\tTime: 8.382330\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 52.368473291397095\n","Train Epoch: 55\tLoss: 0.125986\tTPR: 98.94957983193278\tTNR: 97.29134266459305\tTime: 1.252652\n","Val_loss: 0.192089\tTPR: 90.88983050847457\tTNR: 97.87564766839378\tTime: 8.414862\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 52.18246388435364\n","Train Epoch: 56\tLoss: 0.127323\tTPR: 98.14432989690721\tTNR: 97.45685740236148\tTime: 1.240849\n","Val_loss: 0.174156\tTPR: 93.22033898305084\tTNR: 97.75906735751295\tTime: 8.797374\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 53.66995692253113\n","Train Epoch: 57\tLoss: 0.130883\tTPR: 98.32985386221294\tTNR: 97.2384286269934\tTime: 1.282053\n","Val_loss: 0.175876\tTPR: 94.3157894736842\tTNR: 97.38240248801347\tTime: 8.754865\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 53.99599051475525\n","Train Epoch: 58\tLoss: 0.126983\tTPR: 98.95615866388309\tTNR: 97.27732399844419\tTime: 1.268303\n","Val_loss: 0.217337\tTPR: 91.73553719008265\tTNR: 97.30150492994292\tTime: 8.465463\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 53.307457447052\n","Train Epoch: 59\tLoss: 0.130414\tTPR: 97.7035490605428\tTNR: 97.49773110333204\tTime: 1.248888\n","Val_loss: 0.168265\tTPR: 92.22462203023758\tTNR: 98.09807219562686\tTime: 8.451259\n","\n","Validation loss decreased (0.171668 --> 0.168265).  Saving model\n","\n","Epoch Duration 52.5734965801239\n","Train Epoch: 60\tLoss: 0.163173\tTPR: 96.51639344262296\tTNR: 97.2871235721703\tTime: 1.246326\n","Val_loss: 0.196826\tTPR: 92.56198347107438\tTNR: 97.59989621172808\tTime: 8.453461\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 52.47777056694031\n","Train Epoch: 61\tLoss: 0.122399\tTPR: 98.53862212943632\tTNR: 97.45883573188124\tTime: 1.235762\n","Val_loss: 0.172259\tTPR: 93.14775160599572\tTNR: 97.59223300970874\tTime: 8.522650\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 53.032187938690186\n","Train Epoch: 62\tLoss: 0.128812\tTPR: 97.87234042553192\tTNR: 97.29344729344729\tTime: 1.274175\n","Val_loss: 0.199611\tTPR: 92.93139293139293\tTNR: 97.41927117105433\tTime: 8.524659\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 53.4095025062561\n","Train Epoch: 63\tLoss: 0.116578\tTPR: 99.36170212765958\tTNR: 97.55244755244755\tTime: 1.282606\n","Val_loss: 0.195816\tTPR: 92.67782426778243\tTNR: 97.45916515426497\tTime: 8.384399\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 52.67277646064758\n","Train Epoch: 64\tLoss: 0.133934\tTPR: 97.88583509513742\tTNR: 97.35717061795569\tTime: 1.249023\n","Val_loss: 0.185574\tTPR: 93.39019189765459\tTNR: 97.78583452026415\tTime: 8.429230\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 53.361852169036865\n","Train Epoch: 65\tLoss: 0.129204\tTPR: 98.08510638297872\tTNR: 97.42294742294743\tTime: 1.270370\n","Val_loss: 0.253470\tTPR: 91.32231404958677\tTNR: 97.19771665801764\tTime: 8.542377\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 52.902111530303955\n","Train Epoch: 66\tLoss: 0.122128\tTPR: 98.5200845665962\tTNR: 97.59036144578313\tTime: 1.266790\n","Val_loss: 0.212337\tTPR: 91.84100418410041\tTNR: 97.67954368680321\tTime: 8.320527\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 52.44119954109192\n","Train Epoch: 67\tLoss: 0.118438\tTPR: 97.64453961456103\tTNR: 97.74757281553399\tTime: 1.293793\n","Val_loss: 0.195623\tTPR: 93.64406779661016\tTNR: 97.82383419689118\tTime: 8.414894\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 52.412235498428345\n","Train Epoch: 68\tLoss: 0.128373\tTPR: 98.10924369747899\tTNR: 97.14878175220322\tTime: 1.259772\n","Val_loss: 0.246030\tTPR: 90.61224489795919\tTNR: 97.40327187743443\tTime: 8.510583\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 53.016165256500244\n","Train Epoch: 69\tLoss: 0.131488\tTPR: 97.28601252609603\tTNR: 97.52366135096591\tTime: 1.280932\n","Val_loss: 0.200018\tTPR: 92.79661016949152\tTNR: 97.69430051813471\tTime: 8.501449\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 53.453065156936646\n","Train Epoch: 70\tLoss: 0.117780\tTPR: 98.29787234042553\tTNR: 97.6042476042476\tTime: 1.278463\n","Val_loss: 0.209403\tTPR: 93.13929313929314\tTNR: 97.58786149656335\tTime: 8.450519\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 53.57200837135315\n","Train Epoch: 71\tLoss: 0.127615\tTPR: 97.89915966386555\tTNR: 97.65422498703991\tTime: 1.222421\n","Val_loss: 0.235084\tTPR: 91.47609147609148\tTNR: 97.43223965763195\tTime: 8.208802\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 51.60501503944397\n","Train Epoch: 72\tLoss: 0.125132\tTPR: 98.10924369747899\tTNR: 97.42094349403835\tTime: 1.244004\n","Val_loss: 0.187225\tTPR: 93.94572025052193\tTNR: 97.49773110333204\tTime: 8.109056\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 51.7452278137207\n","Train Epoch: 73\tLoss: 0.118386\tTPR: 98.73150105708245\tTNR: 97.68104676771603\tTime: 1.248214\n","Val_loss: 0.216140\tTPR: 91.3135593220339\tTNR: 97.73316062176166\tTime: 8.420724\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 52.26977205276489\n","Train Epoch: 74\tLoss: 0.123281\tTPR: 97.89915966386555\tTNR: 97.74494556765163\tTime: 1.275229\n","Val_loss: 0.216322\tTPR: 91.63179916317992\tTNR: 97.74436090225564\tTime: 8.281391\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 52.24343919754028\n","Train Epoch: 75\tLoss: 0.123203\tTPR: 97.91231732776617\tTNR: 97.74406845585375\tTime: 1.231001\n","Val_loss: 0.168082\tTPR: 94.00428265524626\tTNR: 97.9546925566343\tTime: 8.245195\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 51.93598675727844\n","Train Epoch: 76\tLoss: 0.136807\tTPR: 97.0954356846473\tTNR: 97.43190661478599\tTime: 1.232470\n","Val_loss: 0.201976\tTPR: 92.81183932346723\tTNR: 97.75877704365851\tTime: 8.258836\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 52.581663846969604\n","Train Epoch: 77\tLoss: 0.115073\tTPR: 98.76288659793815\tTNR: 97.59958479304528\tTime: 1.216338\n","Val_loss: 0.280419\tTPR: 90.20408163265307\tTNR: 97.26045183069333\tTime: 8.428643\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 51.98607063293457\n","Train Epoch: 78\tLoss: 0.114577\tTPR: 98.73949579831933\tTNR: 97.62830482115086\tTime: 1.241604\n","Val_loss: 0.223789\tTPR: 92.9460580912863\tTNR: 97.52269779507134\tTime: 8.295115\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 51.97439360618591\n","Train Epoch: 79\tLoss: 0.123457\tTPR: 98.74739039665971\tTNR: 97.45883573188124\tTime: 1.240232\n","Val_loss: 0.177938\tTPR: 94.00428265524626\tTNR: 97.96763754045308\tTime: 8.509100\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 512, num_layers=10, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=1024, out_features=1, bias=True)\n",")\n","FO-13-WF-512-HS-10-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.070812\tTPR: 0.2061855670103093\tTNR: 99.61074347995329\tTime: 1.765774\n","Val_loss: 1.006468\tTPR: 0.0\tTNR: 100.0\tTime: 9.435838\n","\n","Validation loss decreased (inf --> 1.006468).  Saving model\n","\n","Epoch Duration 68.46140956878662\n","Train Epoch: 1\tLoss: 1.024066\tTPR: 0.0\tTNR: 100.0\tTime: 1.764872\n","Val_loss: 0.715925\tTPR: 37.00623700623701\tTNR: 98.88471015432499\tTime: 9.406245\n","\n","Validation loss decreased (1.006468 --> 0.715925).  Saving model\n","\n","Epoch Duration 69.85316300392151\n","Train Epoch: 2\tLoss: 0.756264\tTPR: 7.676348547717843\tTNR: 99.76653696498055\tTime: 1.751897\n","Val_loss: 0.397739\tTPR: 92.5531914893617\tTNR: 86.41543641543642\tTime: 9.209435\n","\n","Validation loss decreased (0.715925 --> 0.397739).  Saving model\n","\n","Epoch Duration 68.51473593711853\n","Train Epoch: 3\tLoss: 0.408870\tTPR: 91.86295503211991\tTNR: 86.6537216828479\tTime: 1.755337\n","Val_loss: 0.344113\tTPR: 95.55084745762711\tTNR: 88.5880829015544\tTime: 9.506570\n","\n","Validation loss decreased (0.397739 --> 0.344113).  Saving model\n","\n","Epoch Duration 69.49378776550293\n","Train Epoch: 4\tLoss: 0.357322\tTPR: 96.78800856531049\tTNR: 87.5210355987055\tTime: 2.048759\n","Val_loss: 0.303120\tTPR: 97.88583509513742\tTNR: 89.6489182536598\tTime: 9.285702\n","\n","Validation loss decreased (0.344113 --> 0.303120).  Saving model\n","\n","Epoch Duration 69.57664275169373\n","Train Epoch: 5\tLoss: 0.328508\tTPR: 97.00214132762312\tTNR: 89.35922330097087\tTime: 1.739948\n","Val_loss: 0.276191\tTPR: 98.33679833679834\tTNR: 90.9090909090909\tTime: 9.360964\n","\n","Validation loss decreased (0.303120 --> 0.276191).  Saving model\n","\n","Epoch Duration 68.98450946807861\n","Train Epoch: 6\tLoss: 0.303905\tTPR: 98.53862212943632\tTNR: 89.79644755607417\tTime: 1.752423\n","Val_loss: 0.253838\tTPR: 97.6545842217484\tTNR: 92.17920497216107\tTime: 9.345134\n","\n","Validation loss decreased (0.276191 --> 0.253838).  Saving model\n","\n","Epoch Duration 69.40969777107239\n","Train Epoch: 7\tLoss: 0.285893\tTPR: 98.53862212943632\tTNR: 90.71697134707637\tTime: 1.755952\n","Val_loss: 0.265517\tTPR: 96.71457905544148\tTNR: 92.10902011680727\tTime: 9.314020\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 67.9177680015564\n","Train Epoch: 8\tLoss: 0.275848\tTPR: 98.94957983193278\tTNR: 90.8372213582167\tTime: 1.695267\n","Val_loss: 0.253686\tTPR: 96.84210526315789\tTNR: 92.69146041207723\tTime: 9.308043\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 67.94644260406494\n","Train Epoch: 9\tLoss: 0.272106\tTPR: 96.42857142857143\tTNR: 92.05546915500258\tTime: 1.690957\n","Val_loss: 0.236527\tTPR: 96.86192468619247\tTNR: 93.03863106040964\tTime: 9.125790\n","\n","Validation loss decreased (0.253838 --> 0.236527).  Saving model\n","\n","Epoch Duration 68.11287450790405\n","Train Epoch: 10\tLoss: 0.249509\tTPR: 98.52941176470588\tTNR: 92.02954898911354\tTime: 1.751225\n","Val_loss: 0.240865\tTPR: 93.42915811088297\tTNR: 94.67878001297858\tTime: 9.226417\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 68.12115097045898\n","Train Epoch: 11\tLoss: 0.250627\tTPR: 96.88796680497926\tTNR: 93.00907911802854\tTime: 1.685903\n","Val_loss: 0.215676\tTPR: 95.89322381930184\tTNR: 94.71771576898118\tTime: 9.312810\n","\n","Validation loss decreased (0.236527 --> 0.215676).  Saving model\n","\n","Epoch Duration 68.21707105636597\n","Train Epoch: 12\tLoss: 0.231187\tTPR: 97.9253112033195\tTNR: 92.82749675745785\tTime: 1.733228\n","Val_loss: 0.218464\tTPR: 95.18828451882845\tTNR: 95.72206378014\tTime: 9.253271\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 68.33029222488403\n","Train Epoch: 13\tLoss: 0.230173\tTPR: 94.32773109243698\tTNR: 94.85484707102125\tTime: 1.666303\n","Val_loss: 0.217462\tTPR: 95.42619542619542\tTNR: 95.0201011541953\tTime: 9.184937\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 67.26900553703308\n","Train Epoch: 14\tLoss: 0.214663\tTPR: 97.74590163934425\tTNR: 93.88629283489097\tTime: 1.686458\n","Val_loss: 0.184932\tTPR: 96.16204690831557\tTNR: 95.9989641331089\tTime: 9.144841\n","\n","Validation loss decreased (0.215676 --> 0.184932).  Saving model\n","\n","Epoch Duration 67.46333336830139\n","Train Epoch: 15\tLoss: 0.197730\tTPR: 97.46300211416491\tTNR: 94.88275683378676\tTime: 1.698348\n","Val_loss: 0.197342\tTPR: 95.21829521829522\tTNR: 95.9668006743613\tTime: 9.327799\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 68.24755668640137\n","Train Epoch: 16\tLoss: 0.175638\tTPR: 98.31932773109243\tTNR: 95.47693105235874\tTime: 1.661589\n","Val_loss: 0.213221\tTPR: 93.93305439330544\tTNR: 96.42208970702619\tTime: 9.170596\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 67.25396990776062\n","Train Epoch: 17\tLoss: 0.192081\tTPR: 97.4947807933194\tTNR: 95.09918319719954\tTime: 1.715118\n","Val_loss: 0.182244\tTPR: 95.52238805970148\tTNR: 96.24498251974622\tTime: 9.279107\n","\n","Validation loss decreased (0.184932 --> 0.182244).  Saving model\n","\n","Epoch Duration 68.13055849075317\n","Train Epoch: 18\tLoss: 0.160688\tTPR: 98.49137931034483\tTNR: 95.8203933747412\tTime: 1.765392\n","Val_loss: 0.187908\tTPR: 96.04989604989605\tTNR: 96.16132797302555\tTime: 9.250664\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 67.94086527824402\n","Train Epoch: 19\tLoss: 0.176598\tTPR: 97.7035490605428\tTNR: 95.53999740697525\tTime: 1.672929\n","Val_loss: 0.207943\tTPR: 93.86892177589851\tTNR: 96.56691281254048\tTime: 9.421432\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 68.51173639297485\n","Train Epoch: 20\tLoss: 0.184772\tTPR: 96.28865979381443\tTNR: 95.75710393149085\tTime: 1.678631\n","Val_loss: 0.188084\tTPR: 94.38669438669439\tTNR: 96.31694981195695\tTime: 9.207958\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 67.66555595397949\n","Train Epoch: 21\tLoss: 0.177746\tTPR: 97.91231732776617\tTNR: 95.70854401659535\tTime: 1.675595\n","Val_loss: 0.173551\tTPR: 94.88272921108742\tTNR: 96.73701929302084\tTime: 9.260082\n","\n","Validation loss decreased (0.182244 --> 0.173551).  Saving model\n","\n","Epoch Duration 68.09359645843506\n","Train Epoch: 22\tLoss: 0.175971\tTPR: 97.47899159663865\tTNR: 95.91757387247279\tTime: 1.740149\n","Val_loss: 0.168485\tTPR: 94.73684210526315\tTNR: 96.86406634702604\tTime: 9.333335\n","\n","Validation loss decreased (0.173551 --> 0.168485).  Saving model\n","\n","Epoch Duration 69.0536150932312\n","Train Epoch: 23\tLoss: 0.190066\tTPR: 94.71458773784354\tTNR: 96.24303666278016\tTime: 1.753013\n","Val_loss: 0.209658\tTPR: 93.01848049281314\tTNR: 96.65152498377677\tTime: 9.390700\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 68.29681825637817\n","Train Epoch: 24\tLoss: 0.168592\tTPR: 96.63865546218487\tTNR: 96.50077760497668\tTime: 1.685529\n","Val_loss: 0.194262\tTPR: 94.62809917355372\tTNR: 96.49714582252206\tTime: 9.336199\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 68.18369555473328\n","Train Epoch: 25\tLoss: 0.169657\tTPR: 97.71784232365145\tTNR: 96.03112840466926\tTime: 1.681464\n","Val_loss: 0.203855\tTPR: 93.3609958506224\tTNR: 96.79636835278859\tTime: 9.606628\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 68.27014493942261\n","Train Epoch: 26\tLoss: 0.161658\tTPR: 97.9253112033195\tTNR: 96.3035019455253\tTime: 1.740662\n","Val_loss: 0.169775\tTPR: 94.27966101694916\tTNR: 97.1761658031088\tTime: 9.349291\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 68.52434372901917\n","Train Epoch: 27\tLoss: 0.154094\tTPR: 97.4947807933194\tTNR: 96.61610268378062\tTime: 1.688721\n","Val_loss: 0.191497\tTPR: 94.76987447698745\tTNR: 96.79802955665025\tTime: 9.403142\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 68.18911647796631\n","Train Epoch: 28\tLoss: 0.168541\tTPR: 96.92622950819673\tTNR: 96.19678089304257\tTime: 1.699066\n","Val_loss: 0.194067\tTPR: 93.59504132231406\tTNR: 97.15879605604567\tTime: 10.136071\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 69.66158199310303\n","Train Epoch: 29\tLoss: 0.164989\tTPR: 97.52577319587628\tTNR: 96.34098871156091\tTime: 1.761813\n","Val_loss: 0.190808\tTPR: 94.62809917355372\tTNR: 96.69174883238195\tTime: 9.664291\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 69.67052865028381\n","Train Epoch: 30\tLoss: 0.153896\tTPR: 98.31932773109243\tTNR: 96.15085536547434\tTime: 1.699816\n","Val_loss: 0.180712\tTPR: 94.00826446280992\tTNR: 96.78256357031655\tTime: 9.693850\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 69.47959065437317\n","Train Epoch: 31\tLoss: 0.150150\tTPR: 98.12108559498957\tTNR: 96.49941656942825\tTime: 1.720059\n","Val_loss: 0.223177\tTPR: 92.9460580912863\tTNR: 96.58884565499352\tTime: 9.464746\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 69.93415093421936\n","Train Epoch: 32\tLoss: 0.160576\tTPR: 97.47899159663865\tTNR: 96.3841368584759\tTime: 1.694136\n","Val_loss: 0.157922\tTPR: 96.65271966527197\tTNR: 96.92766398755509\tTime: 9.299675\n","\n","Validation loss decreased (0.168485 --> 0.157922).  Saving model\n","\n","Epoch Duration 70.11688494682312\n","Train Epoch: 33\tLoss: 0.165844\tTPR: 96.63865546218487\tTNR: 96.33229652669777\tTime: 1.800341\n","Val_loss: 0.194303\tTPR: 93.42915811088297\tTNR: 97.02790395846853\tTime: 9.553294\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 70.17629194259644\n","Train Epoch: 34\tLoss: 0.163054\tTPR: 96.47302904564316\tTNR: 96.56290531776914\tTime: 1.699482\n","Val_loss: 0.187689\tTPR: 95.42619542619542\tTNR: 96.74490986901829\tTime: 9.303724\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 69.00906562805176\n","Train Epoch: 35\tLoss: 0.162126\tTPR: 97.46300211416491\tTNR: 96.30781189273222\tTime: 1.694129\n","Val_loss: 0.189293\tTPR: 93.59504132231406\tTNR: 96.9252724442138\tTime: 9.337746\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 69.5275068283081\n","Train Epoch: 36\tLoss: 0.143539\tTPR: 98.10924369747899\tTNR: 96.66925868325558\tTime: 1.704902\n","Val_loss: 0.161681\tTPR: 95.76271186440678\tTNR: 97.34455958549223\tTime: 9.252888\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 68.94093060493469\n","Train Epoch: 37\tLoss: 0.151338\tTPR: 97.71784232365145\tTNR: 96.47211413748379\tTime: 1.665904\n","Val_loss: 0.189286\tTPR: 93.51464435146444\tTNR: 97.10915219082187\tTime: 9.621139\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 70.54278874397278\n","Train Epoch: 38\tLoss: 0.160035\tTPR: 96.61733615221986\tTNR: 96.76123850239668\tTime: 1.700191\n","Val_loss: 0.183370\tTPR: 94.73684210526315\tTNR: 97.12323441751977\tTime: 9.442947\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 69.39959955215454\n","Train Epoch: 39\tLoss: 0.156627\tTPR: 97.47899159663865\tTNR: 96.47485743908761\tTime: 1.690527\n","Val_loss: 0.186962\tTPR: 93.93305439330544\tTNR: 97.03137153227898\tTime: 9.491631\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 69.10808062553406\n","Train Epoch: 40\tLoss: 0.140905\tTPR: 98.30866807610994\tTNR: 96.89078896230082\tTime: 1.670438\n","Val_loss: 0.150716\tTPR: 96.37526652452026\tTNR: 97.53981613362683\tTime: 9.485627\n","\n","Validation loss decreased (0.157922 --> 0.150716).  Saving model\n","\n","Epoch Duration 68.6923885345459\n","Train Epoch: 41\tLoss: 0.155606\tTPR: 97.89915966386555\tTNR: 96.85069984447901\tTime: 1.745850\n","Val_loss: 0.179695\tTPR: 94.46808510638299\tTNR: 97.17689717689719\tTime: 9.254338\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 69.22407388687134\n","Train Epoch: 42\tLoss: 0.142273\tTPR: 98.10924369747899\tTNR: 96.95438050803526\tTime: 1.709810\n","Val_loss: 0.196616\tTPR: 94.17879417879418\tTNR: 96.84865776163922\tTime: 9.264100\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 69.26112198829651\n","Train Epoch: 43\tLoss: 0.157060\tTPR: 97.46300211416491\tTNR: 96.68350822645421\tTime: 1.677631\n","Val_loss: 0.185197\tTPR: 94.00826446280992\tTNR: 97.18474312402698\tTime: 9.304680\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 69.06453895568848\n","Train Epoch: 44\tLoss: 0.143941\tTPR: 97.28601252609603\tTNR: 96.927265655387\tTime: 1.683051\n","Val_loss: 0.202847\tTPR: 92.51559251559252\tTNR: 97.00427960057061\tTime: 9.371094\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 68.99868845939636\n","Train Epoch: 45\tLoss: 0.170986\tTPR: 97.52577319587628\tTNR: 96.66536914493318\tTime: 1.668700\n","Val_loss: 0.209688\tTPR: 93.14516129032258\tTNR: 96.95945945945947\tTime: 9.281900\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 69.18549680709839\n","Train Epoch: 46\tLoss: 0.140048\tTPR: 97.68907563025209\tTNR: 96.98030067392432\tTime: 1.693444\n","Val_loss: 0.138319\tTPR: 97.05263157894737\tTNR: 97.39536089153816\tTime: 9.367723\n","\n","Validation loss decreased (0.150716 --> 0.138319).  Saving model\n","\n","Epoch Duration 70.33316922187805\n","Train Epoch: 47\tLoss: 0.154111\tTPR: 96.24217118997912\tTNR: 96.78464929340075\tTime: 1.729030\n","Val_loss: 0.180473\tTPR: 94.57202505219206\tTNR: 97.18656813172566\tTime: 9.562672\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 70.54251146316528\n","Train Epoch: 48\tLoss: 0.135920\tTPR: 98.31932773109243\tTNR: 97.00622083981337\tTime: 1.712831\n","Val_loss: 0.196619\tTPR: 93.23467230443974\tTNR: 97.16284492809949\tTime: 9.319439\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 69.38465809822083\n","Train Epoch: 49\tLoss: 0.130604\tTPR: 98.29787234042553\tTNR: 97.2027972027972\tTime: 1.703312\n","Val_loss: 0.161816\tTPR: 94.91525423728814\tTNR: 97.29274611398964\tTime: 9.434721\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 69.31177520751953\n","Train Epoch: 50\tLoss: 0.135290\tTPR: 98.73949579831933\tTNR: 97.01918092275791\tTime: 1.680433\n","Val_loss: 0.191448\tTPR: 93.76299376299376\tTNR: 97.19880689923485\tTime: 9.340571\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 68.93472933769226\n","Train Epoch: 51\tLoss: 0.140425\tTPR: 98.5200845665962\tTNR: 96.9685192382433\tTime: 1.690539\n","Val_loss: 0.195411\tTPR: 92.40246406570843\tTNR: 97.10577547047372\tTime: 9.366657\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 69.82875227928162\n","Train Epoch: 52\tLoss: 0.139647\tTPR: 97.71784232365145\tTNR: 97.02983138780804\tTime: 1.703624\n","Val_loss: 0.180206\tTPR: 95.60669456066945\tTNR: 97.29064039408867\tTime: 9.340152\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 69.6212887763977\n","Train Epoch: 53\tLoss: 0.150983\tTPR: 97.74590163934425\tTNR: 96.70301142263759\tTime: 1.704252\n","Val_loss: 0.161109\tTPR: 94.97907949790795\tTNR: 97.36842105263158\tTime: 9.465897\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 69.64361023902893\n","Train Epoch: 54\tLoss: 0.149242\tTPR: 97.25158562367865\tTNR: 97.02033942220496\tTime: 1.691116\n","Val_loss: 0.183733\tTPR: 94.17879417879418\tTNR: 97.3155232784334\tTime: 9.613073\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 69.59465193748474\n","Train Epoch: 55\tLoss: 0.139661\tTPR: 97.91231732776617\tTNR: 96.97912615065474\tTime: 1.694341\n","Val_loss: 0.152923\tTPR: 95.47413793103449\tTNR: 97.61904761904762\tTime: 9.305825\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 69.44478940963745\n","Train Epoch: 56\tLoss: 0.142661\tTPR: 96.90721649484536\tTNR: 96.96379914363565\tTime: 1.714999\n","Val_loss: 0.173763\tTPR: 93.97089397089398\tTNR: 97.40630268447671\tTime: 8.940489\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 67.6042127609253\n","Train Epoch: 57\tLoss: 0.120362\tTPR: 99.36575052854123\tTNR: 97.33126052597487\tTime: 1.650791\n","Val_loss: 0.171150\tTPR: 94.70338983050848\tTNR: 97.5\tTime: 9.104422\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 68.06756496429443\n","Train Epoch: 58\tLoss: 0.125025\tTPR: 98.53862212943632\tTNR: 97.29028912226111\tTime: 1.659841\n","Val_loss: 0.202877\tTPR: 93.59504132231406\tTNR: 97.23663725998962\tTime: 9.187581\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 67.73239088058472\n","Train Epoch: 59\tLoss: 0.130670\tTPR: 98.5200845665962\tTNR: 97.30535043399404\tTime: 1.731862\n","Val_loss: 0.202626\tTPR: 92.81314168377823\tTNR: 97.26151849448411\tTime: 8.963295\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 66.57726716995239\n","Train Epoch: 60\tLoss: 0.134913\tTPR: 97.46300211416491\tTNR: 97.20171006607073\tTime: 1.677667\n","Val_loss: 0.188649\tTPR: 93.4322033898305\tTNR: 97.40932642487047\tTime: 9.001684\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 66.64163112640381\n","Train Epoch: 61\tLoss: 0.132220\tTPR: 98.08510638297872\tTNR: 97.33229733229733\tTime: 1.651869\n","Val_loss: 0.178291\tTPR: 94.94736842105263\tTNR: 97.30465206686536\tTime: 9.368901\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 66.5071268081665\n","Train Epoch: 62\tLoss: 0.136912\tTPR: 97.7035490605428\tTNR: 97.0439517697394\tTime: 1.679127\n","Val_loss: 0.167848\tTPR: 95.12711864406779\tTNR: 97.5259067357513\tTime: 9.097982\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 66.51556777954102\n","Train Epoch: 63\tLoss: 0.130423\tTPR: 97.87234042553192\tTNR: 97.4099974099974\tTime: 1.640379\n","Val_loss: 0.232459\tTPR: 91.73553719008265\tTNR: 97.31447846393357\tTime: 9.102574\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 67.01762747764587\n","Train Epoch: 64\tLoss: 0.154347\tTPR: 96.90721649484536\tTNR: 97.09355131698456\tTime: 1.646572\n","Val_loss: 0.179587\tTPR: 93.86892177589851\tTNR: 97.44785593988858\tTime: 9.832539\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 67.8125205039978\n","Train Epoch: 65\tLoss: 0.129451\tTPR: 98.50107066381156\tTNR: 97.25566343042071\tTime: 1.738075\n","Val_loss: 0.184667\tTPR: 93.59504132231406\tTNR: 97.4961079398028\tTime: 9.253173\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 67.67910051345825\n","Train Epoch: 66\tLoss: 0.136650\tTPR: 97.31958762886597\tTNR: 97.14545218632412\tTime: 1.672647\n","Val_loss: 0.207168\tTPR: 92.85714285714286\tTNR: 97.32537003375747\tTime: 9.319173\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 1024, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=2048, out_features=1, bias=True)\n",")\n","FO-13-WF-1024-HS-2-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.087188\tTPR: 24.481327800829874\tTNR: 65.20103761348898\tTime: 1.203254\n","Val_loss: 0.467264\tTPR: 85.74380165289256\tTNR: 89.36170212765957\tTime: 8.667097\n","\n","Validation loss decreased (inf --> 0.467264).  Saving model\n","\n","Epoch Duration 51.31649661064148\n","Train Epoch: 1\tLoss: 0.501364\tTPR: 81.9327731092437\tTNR: 90.18921721099015\tTime: 1.229578\n","Val_loss: 0.354831\tTPR: 96.65271966527197\tTNR: 89.00700025926886\tTime: 8.703200\n","\n","Validation loss decreased (0.467264 --> 0.354831).  Saving model\n","\n","Epoch Duration 50.91000771522522\n","Train Epoch: 2\tLoss: 0.379262\tTPR: 94.57202505219206\tTNR: 89.52417995591858\tTime: 1.206043\n","Val_loss: 0.330040\tTPR: 97.56592292089249\tTNR: 89.41420963761527\tTime: 8.629239\n","\n","Validation loss decreased (0.354831 --> 0.330040).  Saving model\n","\n","Epoch Duration 50.61066508293152\n","Train Epoch: 3\tLoss: 0.337863\tTPR: 93.57601713062098\tTNR: 91.06796116504854\tTime: 1.248966\n","Val_loss: 0.272432\tTPR: 98.50107066381156\tTNR: 91.44336569579288\tTime: 8.480677\n","\n","Validation loss decreased (0.330040 --> 0.272432).  Saving model\n","\n","Epoch Duration 51.439510345458984\n","Train Epoch: 4\tLoss: 0.319007\tTPR: 96.47302904564316\tTNR: 90.63553826199741\tTime: 1.207898\n","Val_loss: 0.267013\tTPR: 96.42105263157895\tTNR: 92.22495788518854\tTime: 8.761271\n","\n","Validation loss decreased (0.272432 --> 0.267013).  Saving model\n","\n","Epoch Duration 51.56705021858215\n","Train Epoch: 5\tLoss: 0.292705\tTPR: 95.0207468879668\tTNR: 91.73800259403372\tTime: 1.252942\n","Val_loss: 0.240159\tTPR: 97.2457627118644\tTNR: 93.00518134715026\tTime: 8.745074\n","\n","Validation loss decreased (0.267013 --> 0.240159).  Saving model\n","\n","Epoch Duration 51.41444945335388\n","Train Epoch: 6\tLoss: 0.275709\tTPR: 93.69747899159664\tTNR: 92.78123379989633\tTime: 1.262993\n","Val_loss: 0.249235\tTPR: 95.81589958158996\tTNR: 92.88306974332383\tTime: 8.603368\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 50.79562711715698\n","Train Epoch: 7\tLoss: 0.249006\tTPR: 96.40591966173362\tTNR: 93.69089260266874\tTime: 1.205837\n","Val_loss: 0.239851\tTPR: 96.21052631578947\tTNR: 94.27238564208889\tTime: 8.766541\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 50.57695031166077\n","Train Epoch: 8\tLoss: 0.248164\tTPR: 95.7983193277311\tTNR: 94.01244167962675\tTime: 1.266105\n","Val_loss: 0.213938\tTPR: 95.73560767590618\tTNR: 94.92425223358798\tTime: 8.653608\n","\n","Validation loss decreased (0.240159 --> 0.213938).  Saving model\n","\n","Epoch Duration 50.8813214302063\n","Train Epoch: 9\tLoss: 0.233354\tTPR: 94.39834024896265\tTNR: 94.39688715953307\tTime: 1.235023\n","Val_loss: 0.238007\tTPR: 91.0041841004184\tTNR: 95.55353901996371\tTime: 8.612938\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 51.795387506484985\n","Train Epoch: 10\tLoss: 0.231902\tTPR: 96.86847599164928\tTNR: 94.15272915856346\tTime: 1.194396\n","Val_loss: 0.237264\tTPR: 91.78947368421052\tTNR: 95.84035246857587\tTime: 8.543305\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 50.38639259338379\n","Train Epoch: 11\tLoss: 0.231391\tTPR: 97.71784232365145\tTNR: 94.39688715953307\tTime: 1.185470\n","Val_loss: 0.259608\tTPR: 87.92372881355932\tTNR: 96.17875647668393\tTime: 8.517601\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 50.44904065132141\n","Train Epoch: 12\tLoss: 0.207978\tTPR: 95.58823529411765\tTNR: 95.2954898911353\tTime: 1.183771\n","Val_loss: 0.260734\tTPR: 87.52598752598753\tTNR: 96.40772921800026\tTime: 8.617349\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 50.58248257637024\n","Train Epoch: 13\tLoss: 0.215318\tTPR: 97.3360655737705\tTNR: 95.10643821391484\tTime: 1.222753\n","Val_loss: 0.274504\tTPR: 88.57142857142857\tTNR: 96.14385873799013\tTime: 8.816603\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 50.70577430725098\n","Train Epoch: 14\tLoss: 0.194813\tTPR: 97.4947807933194\tTNR: 95.20290418773499\tTime: 1.212283\n","Val_loss: 0.277769\tTPR: 84.51882845188284\tTNR: 96.81099299974073\tTime: 8.609929\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 50.805877685546875\n","Train Epoch: 15\tLoss: 0.215810\tTPR: 94.26229508196722\tTNR: 95.74247144340602\tTime: 1.182147\n","Val_loss: 0.229369\tTPR: 90.75630252100841\tTNR: 96.55261793675479\tTime: 8.566417\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 51.562488079071045\n","Train Epoch: 16\tLoss: 0.199612\tTPR: 95.16806722689076\tTNR: 95.94349403836185\tTime: 1.208563\n","Val_loss: 0.239592\tTPR: 90.55441478439425\tTNR: 96.57365347177158\tTime: 8.417055\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 49.875794887542725\n","Train Epoch: 17\tLoss: 0.180823\tTPR: 97.71784232365145\tTNR: 96.12191958495461\tTime: 1.167509\n","Val_loss: 0.235025\tTPR: 88.70292887029288\tTNR: 96.77210267046928\tTime: 8.446183\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 49.61571288108826\n","Train Epoch: 18\tLoss: 0.185598\tTPR: 96.84873949579831\tTNR: 95.89165370658372\tTime: 1.187640\n","Val_loss: 0.267790\tTPR: 87.44769874476988\tTNR: 97.16100596318383\tTime: 8.259353\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 48.91437864303589\n","Train Epoch: 19\tLoss: 0.185348\tTPR: 95.9830866807611\tTNR: 96.28190180075138\tTime: 1.140821\n","Val_loss: 0.249816\tTPR: 89.26315789473685\tTNR: 96.88998315407542\tTime: 8.310332\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 48.44790053367615\n","Train Epoch: 20\tLoss: 0.168835\tTPR: 97.47899159663865\tTNR: 96.08605495075169\tTime: 1.170441\n","Val_loss: 0.266039\tTPR: 87.65957446808511\tTNR: 97.24164724164724\tTime: 8.298945\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 48.89886522293091\n","Train Epoch: 21\tLoss: 0.173779\tTPR: 96.61733615221986\tTNR: 96.33372198471305\tTime: 1.161049\n","Val_loss: 0.259594\tTPR: 89.26315789473685\tTNR: 97.11027601399508\tTime: 8.930192\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 50.01607298851013\n","Train Epoch: 22\tLoss: 0.158561\tTPR: 98.30866807610994\tTNR: 96.60577795051172\tTime: 1.185570\n","Val_loss: 0.291035\tTPR: 87.39669421487604\tTNR: 96.97716658017644\tTime: 8.443883\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 49.50742769241333\n","Train Epoch: 23\tLoss: 0.167916\tTPR: 97.30290456431536\tTNR: 96.38132295719845\tTime: 1.173417\n","Val_loss: 0.296983\tTPR: 87.06365503080082\tTNR: 97.04088254380272\tTime: 8.255325\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 49.11443495750427\n","Train Epoch: 24\tLoss: 0.158713\tTPR: 97.04016913319239\tTNR: 96.82601373234874\tTime: 1.157976\n","Val_loss: 0.295482\tTPR: 84.97854077253218\tTNR: 97.45016826300802\tTime: 8.258923\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 48.885294675827026\n","Train Epoch: 25\tLoss: 0.163135\tTPR: 97.26890756302521\tTNR: 96.51373768792119\tTime: 1.154159\n","Val_loss: 0.271735\tTPR: 87.02928870292888\tTNR: 97.31656728026964\tTime: 8.279276\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 48.80255889892578\n","Train Epoch: 26\tLoss: 0.166259\tTPR: 95.9830866807611\tTNR: 96.95556419225288\tTime: 1.150853\n","Val_loss: 0.274521\tTPR: 87.11018711018711\tTNR: 97.35442873816625\tTime: 8.440557\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 48.786834955215454\n","Train Epoch: 27\tLoss: 0.161696\tTPR: 96.84873949579831\tTNR: 96.70813893208916\tTime: 1.167712\n","Val_loss: 0.342112\tTPR: 84.42105263157896\tTNR: 97.4601529091616\tTime: 8.267456\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 48.65750527381897\n","Train Epoch: 28\tLoss: 0.152072\tTPR: 97.28601252609603\tTNR: 96.97912615065474\tTime: 1.161692\n","Val_loss: 0.266190\tTPR: 87.20682302771856\tTNR: 97.44917778065518\tTime: 8.247502\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 1024, num_layers=5, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=2048, out_features=1, bias=True)\n",")\n","FO-13-WF-1024-HS-5-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.071097\tTPR: 90.42553191489363\tTNR: 6.954156954156954\tTime: 1.872856\n","Val_loss: 0.533294\tTPR: 71.75732217573221\tTNR: 91.74228675136116\tTime: 10.609469\n","\n","Validation loss decreased (inf --> 0.533294).  Saving model\n","\n","Epoch Duration 76.2423677444458\n","Train Epoch: 1\tLoss: 0.568745\tTPR: 67.4468085106383\tTNR: 93.11059311059311\tTime: 1.931555\n","Val_loss: 0.331384\tTPR: 91.73728813559322\tTNR: 89.9740932642487\tTime: 10.599040\n","\n","Validation loss decreased (0.533294 --> 0.331384).  Saving model\n","\n","Epoch Duration 76.61383295059204\n","Train Epoch: 2\tLoss: 0.342493\tTPR: 91.9661733615222\tTNR: 89.85619898950641\tTime: 2.046162\n","Val_loss: 0.291075\tTPR: 95.45454545454545\tTNR: 90.72392319667878\tTime: 10.874420\n","\n","Validation loss decreased (0.331384 --> 0.291075).  Saving model\n","\n","Epoch Duration 77.3889000415802\n","Train Epoch: 3\tLoss: 0.291787\tTPR: 93.31941544885177\tTNR: 91.59859976662777\tTime: 2.002103\n","Val_loss: 0.261634\tTPR: 94.38669438669439\tTNR: 93.60653611723512\tTime: 10.647485\n","\n","Validation loss decreased (0.291075 --> 0.261634).  Saving model\n","\n","Epoch Duration 77.01058602333069\n","Train Epoch: 4\tLoss: 0.276547\tTPR: 93.69747899159664\tTNR: 93.62363919129082\tTime: 1.941241\n","Val_loss: 0.209508\tTPR: 97.85867237687366\tTNR: 94.42071197411003\tTime: 10.607757\n","\n","Validation loss decreased (0.261634 --> 0.209508).  Saving model\n","\n","Epoch Duration 76.54407787322998\n","Train Epoch: 5\tLoss: 0.244655\tTPR: 95.13742071881607\tTNR: 93.91112838450576\tTime: 1.984054\n","Val_loss: 0.241426\tTPR: 95.0413223140496\tTNR: 94.82355993772704\tTime: 10.606372\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 75.45623326301575\n","Train Epoch: 6\tLoss: 0.226451\tTPR: 96.47302904564316\tTNR: 94.72114137483787\tTime: 1.866997\n","Val_loss: 0.223597\tTPR: 95.27720739219713\tTNR: 94.89941596365996\tTime: 10.544529\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 74.71763610839844\n","Train Epoch: 7\tLoss: 0.211185\tTPR: 96.88796680497926\tTNR: 94.69520103761349\tTime: 1.853309\n","Val_loss: 0.199480\tTPR: 94.52631578947368\tTNR: 96.31981339898924\tTime: 10.523529\n","\n","Validation loss decreased (0.209508 --> 0.199480).  Saving model\n","\n","Epoch Duration 76.34110474586487\n","Train Epoch: 8\tLoss: 0.206647\tTPR: 95.77167019027483\tTNR: 95.09003756963337\tTime: 1.980335\n","Val_loss: 0.247112\tTPR: 91.0041841004184\tTNR: 96.51283380865958\tTime: 10.630230\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 75.55825710296631\n","Train Epoch: 9\tLoss: 0.223646\tTPR: 95.05154639175257\tTNR: 95.73115349682108\tTime: 1.864024\n","Val_loss: 0.207805\tTPR: 94.52631578947368\tTNR: 96.29389659193987\tTime: 10.720957\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 75.56897258758545\n","Train Epoch: 10\tLoss: 0.196569\tTPR: 96.86847599164928\tTNR: 95.21586931155193\tTime: 1.894912\n","Val_loss: 0.223810\tTPR: 94.38669438669439\tTNR: 95.8889897548956\tTime: 10.460412\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 75.31468367576599\n","Train Epoch: 11\tLoss: 0.186274\tTPR: 98.29787234042553\tTNR: 95.32504532504532\tTime: 1.852400\n","Val_loss: 0.195611\tTPR: 94.56066945606695\tTNR: 96.22763806066892\tTime: 10.456107\n","\n","Validation loss decreased (0.199480 --> 0.195611).  Saving model\n","\n","Epoch Duration 76.17830514907837\n","Train Epoch: 12\tLoss: 0.197949\tTPR: 97.52577319587628\tTNR: 95.13429349941612\tTime: 1.874141\n","Val_loss: 0.200801\tTPR: 95.24793388429752\tTNR: 95.99117799688635\tTime: 10.523740\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 75.13435578346252\n","Train Epoch: 13\tLoss: 0.196755\tTPR: 97.74590163934425\tTNR: 94.85981308411215\tTime: 1.846219\n","Val_loss: 0.207985\tTPR: 91.10169491525424\tTNR: 97.11139896373057\tTime: 10.637605\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 74.71089768409729\n","Train Epoch: 14\tLoss: 0.165492\tTPR: 97.41379310344827\tTNR: 96.19565217391305\tTime: 1.857947\n","Val_loss: 0.210265\tTPR: 92.63157894736842\tTNR: 97.0843592069457\tTime: 10.491804\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 74.5434923171997\n","Train Epoch: 15\tLoss: 0.174126\tTPR: 96.61733615221986\tTNR: 96.1912164788185\tTime: 1.847737\n","Val_loss: 0.250533\tTPR: 86.9022869022869\tTNR: 97.57489300998573\tTime: 10.659574\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 74.78668403625488\n","Train Epoch: 16\tLoss: 0.181037\tTPR: 94.74789915966386\tTNR: 96.66925868325558\tTime: 1.861461\n","Val_loss: 0.196425\tTPR: 93.34719334719335\tTNR: 96.65413046297498\tTime: 10.401672\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 74.3708918094635\n","Train Epoch: 17\tLoss: 0.164142\tTPR: 98.10924369747899\tTNR: 95.86573354069466\tTime: 1.825723\n","Val_loss: 0.207825\tTPR: 90.26369168356997\tTNR: 97.32432783478374\tTime: 10.633040\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 74.4722011089325\n","Train Epoch: 18\tLoss: 0.157561\tTPR: 96.49484536082474\tTNR: 96.84702218762165\tTime: 1.852931\n","Val_loss: 0.187776\tTPR: 91.10169491525424\tTNR: 97.57772020725388\tTime: 10.594893\n","\n","Validation loss decreased (0.195611 --> 0.187776).  Saving model\n","\n","Epoch Duration 75.41052651405334\n","Train Epoch: 19\tLoss: 0.157979\tTPR: 96.84873949579831\tTNR: 96.7599792638673\tTime: 1.960412\n","Val_loss: 0.211388\tTPR: 90.54621848739495\tTNR: 97.48574390876101\tTime: 10.876740\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 75.1804428100586\n","Train Epoch: 20\tLoss: 0.145414\tTPR: 97.4947807933194\tTNR: 97.0050563982886\tTime: 1.944305\n","Val_loss: 0.222684\tTPR: 89.5277207392197\tTNR: 97.53406878650227\tTime: 10.572029\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 75.1236264705658\n","Train Epoch: 21\tLoss: 0.157411\tTPR: 95.82463465553236\tTNR: 97.14767276027486\tTime: 1.853971\n","Val_loss: 0.200576\tTPR: 90.5781584582441\tTNR: 98.07119741100324\tTime: 10.564687\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 74.91173815727234\n","Train Epoch: 22\tLoss: 0.143524\tTPR: 97.30290456431536\tTNR: 97.30220492866407\tTime: 1.863587\n","Val_loss: 0.202226\tTPR: 90.10526315789474\tTNR: 97.96553064662433\tTime: 10.613301\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 74.9761426448822\n","Train Epoch: 23\tLoss: 0.128275\tTPR: 98.07280513918629\tTNR: 97.50161812297735\tTime: 1.856394\n","Val_loss: 0.216757\tTPR: 89.61864406779661\tTNR: 97.94041450777202\tTime: 10.481072\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 74.86922335624695\n","Train Epoch: 24\tLoss: 0.130029\tTPR: 98.10924369747899\tTNR: 97.47278382581649\tTime: 1.858431\n","Val_loss: 0.213785\tTPR: 90.28925619834712\tTNR: 97.80747275557862\tTime: 10.678286\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 75.62973499298096\n","Train Epoch: 25\tLoss: 0.131154\tTPR: 97.21627408993577\tTNR: 97.61812297734627\tTime: 1.865110\n","Val_loss: 0.208007\tTPR: 91.84100418410041\tTNR: 97.58879958516982\tTime: 10.564038\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 74.94591021537781\n","Train Epoch: 26\tLoss: 0.139800\tTPR: 98.13278008298755\tTNR: 96.9390402075227\tTime: 1.856408\n","Val_loss: 0.161441\tTPR: 94.82758620689656\tTNR: 97.5672877846791\tTime: 10.501858\n","\n","Validation loss decreased (0.187776 --> 0.161441).  Saving model\n","\n","Epoch Duration 75.87105655670166\n","Train Epoch: 27\tLoss: 0.133605\tTPR: 98.52941176470588\tTNR: 96.8895800933126\tTime: 1.944407\n","Val_loss: 0.174148\tTPR: 93.34719334719335\tTNR: 97.63973544287381\tTime: 10.477223\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 75.08198165893555\n","Train Epoch: 28\tLoss: 0.137528\tTPR: 97.52577319587628\tTNR: 97.05462566497988\tTime: 1.851338\n","Val_loss: 0.223480\tTPR: 91.07883817427386\tTNR: 97.47081712062257\tTime: 10.643801\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 75.36820554733276\n","Train Epoch: 29\tLoss: 0.138715\tTPR: 98.54771784232366\tTNR: 96.9520103761349\tTime: 1.859811\n","Val_loss: 0.152679\tTPR: 94.27966101694916\tTNR: 97.83678756476684\tTime: 10.641397\n","\n","Validation loss decreased (0.161441 --> 0.152679).  Saving model\n","\n","Epoch Duration 75.86213326454163\n","Train Epoch: 30\tLoss: 0.136166\tTPR: 98.12108559498957\tTNR: 97.19953325554259\tTime: 1.944605\n","Val_loss: 0.172083\tTPR: 93.09623430962343\tTNR: 97.89992221934146\tTime: 10.512131\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 75.09072923660278\n","Train Epoch: 31\tLoss: 0.132529\tTPR: 97.7035490605428\tTNR: 97.53662647478284\tTime: 1.850798\n","Val_loss: 0.179350\tTPR: 93.19148936170212\tTNR: 97.83734783734783\tTime: 10.473530\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 74.71054124832153\n","Train Epoch: 32\tLoss: 0.133358\tTPR: 97.89915966386555\tTNR: 97.3561430793157\tTime: 1.837364\n","Val_loss: 0.181353\tTPR: 91.47121535181236\tTNR: 98.14838793215071\tTime: 10.663378\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 74.9898452758789\n","Train Epoch: 33\tLoss: 0.124509\tTPR: 98.07280513918629\tTNR: 97.65695792880258\tTime: 1.887975\n","Val_loss: 0.173261\tTPR: 93.27731092436974\tTNR: 97.77086573354069\tTime: 10.538306\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 74.60011959075928\n","Train Epoch: 34\tLoss: 0.118457\tTPR: 99.78991596638656\tTNR: 97.26542249870398\tTime: 1.853219\n","Val_loss: 0.169931\tTPR: 93.7759336099585\tTNR: 97.66536964980544\tTime: 10.403706\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 74.22130465507507\n","Train Epoch: 35\tLoss: 0.115276\tTPR: 99.36575052854123\tTNR: 97.66809172172562\tTime: 1.844857\n","Val_loss: 0.162044\tTPR: 94.10526315789474\tTNR: 97.75819619022937\tTime: 10.417099\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 74.42641949653625\n","Train Epoch: 36\tLoss: 0.113202\tTPR: 99.36575052854123\tTNR: 97.53854126182148\tTime: 1.859980\n","Val_loss: 0.165630\tTPR: 94.14225941422593\tTNR: 97.8739953331605\tTime: 10.411865\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 74.85080361366272\n","Train Epoch: 37\tLoss: 0.129115\tTPR: 98.53862212943632\tTNR: 97.35511474134579\tTime: 1.849015\n","Val_loss: 0.156458\tTPR: 93.90756302521008\tTNR: 97.82270606531883\tTime: 10.540795\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 74.6736159324646\n","Train Epoch: 38\tLoss: 0.128901\tTPR: 98.13278008298755\tTNR: 97.4059662775616\tTime: 1.865713\n","Val_loss: 0.171749\tTPR: 92.5531914893617\tTNR: 97.94094794094794\tTime: 10.435104\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 74.37542676925659\n","Train Epoch: 39\tLoss: 0.113025\tTPR: 99.38524590163934\tTNR: 97.71547248182763\tTime: 1.836282\n","Val_loss: 0.189782\tTPR: 92.93139293139293\tTNR: 97.84723122811569\tTime: 11.352519\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 77.35703659057617\n","Train Epoch: 40\tLoss: 0.123034\tTPR: 98.09725158562368\tTNR: 97.52558621583105\tTime: 1.948329\n","Val_loss: 0.179045\tTPR: 92.88702928870293\tTNR: 98.05548353642727\tTime: 11.414720\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 77.63733887672424\n","Train Epoch: 41\tLoss: 0.116160\tTPR: 98.29787234042553\tTNR: 97.69489769489769\tTime: 1.943704\n","Val_loss: 0.185585\tTPR: 90.31578947368422\tTNR: 98.17286510301932\tTime: 11.377855\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 77.22076392173767\n","Train Epoch: 42\tLoss: 0.117190\tTPR: 98.32985386221294\tTNR: 97.79592895112148\tTime: 1.938040\n","Val_loss: 0.237980\tTPR: 88.63636363636364\tTNR: 97.8463933575506\tTime: 11.330971\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 77.12453365325928\n","Train Epoch: 43\tLoss: 0.112967\tTPR: 98.32985386221294\tTNR: 97.95151043692468\tTime: 1.951385\n","Val_loss: 0.166691\tTPR: 91.89765458422174\tTNR: 98.16133626828952\tTime: 11.274354\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 77.16900181770325\n","Train Epoch: 44\tLoss: 0.113467\tTPR: 98.10924369747899\tTNR: 97.96526697770865\tTime: 1.945310\n","Val_loss: 0.256205\tTPR: 88.23529411764706\tTNR: 97.4801922327575\tTime: 11.360714\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 77.65771245956421\n","Train Epoch: 45\tLoss: 0.114124\tTPR: 97.87234042553192\tTNR: 97.94094794094794\tTime: 1.956603\n","Val_loss: 0.153981\tTPR: 93.61702127659575\tTNR: 98.23879823879824\tTime: 11.338068\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 77.42926096916199\n","Train Epoch: 46\tLoss: 0.119888\tTPR: 98.09725158562368\tTNR: 97.91423759554347\tTime: 1.956336\n","Val_loss: 0.168204\tTPR: 93.05263157894737\tTNR: 98.08215627834652\tTime: 11.309021\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 77.17520833015442\n","Train Epoch: 47\tLoss: 0.119221\tTPR: 98.35051546391752\tTNR: 97.67743609705462\tTime: 1.942597\n","Val_loss: 0.183331\tTPR: 92.72349272349273\tTNR: 97.96394760731422\tTime: 11.420216\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 77.57788729667664\n","Train Epoch: 48\tLoss: 0.110327\tTPR: 99.36170212765958\tTNR: 97.9020979020979\tTime: 2.043634\n","Val_loss: 0.180633\tTPR: 93.34719334719335\tTNR: 97.14693295292439\tTime: 11.479582\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 78.17131209373474\n","Train Epoch: 49\tLoss: 0.145999\tTPR: 98.31932773109243\tTNR: 96.63037843442198\tTime: 1.997854\n","Val_loss: 0.165533\tTPR: 91.97396963123644\tTNR: 98.27965334368129\tTime: 11.420670\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n","Network(\n","  (lstm): LSTM(12, 1024, num_layers=10, batch_first=True, dropout=0.5, bidirectional=True)\n","  (linear): Linear(in_features=2048, out_features=1, bias=True)\n",")\n","FO-13-WF-1024-HS-10-NL-1e-05-LR-100-epochs\n","Train Epoch: 0\tLoss: 1.074156\tTPR: 100.0\tTNR: 0.0\tTime: 2.947814\n","Val_loss: 0.847207\tTPR: 0.0\tTNR: 100.0\tTime: 13.435434\n","\n","Validation loss decreased (inf --> 0.847207).  Saving model\n","\n","Epoch Duration 116.93876695632935\n","Train Epoch: 1\tLoss: 0.857715\tTPR: 0.0\tTNR: 100.0\tTime: 3.091997\n","Val_loss: 0.387464\tTPR: 93.55509355509356\tTNR: 87.48541045260018\tTime: 13.917558\n","\n","Validation loss decreased (0.847207 --> 0.387464).  Saving model\n","\n","Epoch Duration 119.22415232658386\n","Train Epoch: 2\tLoss: 0.400286\tTPR: 95.0207468879668\tTNR: 86.16083009079118\tTime: 3.196376\n","Val_loss: 0.331281\tTPR: 95.42619542619542\tTNR: 89.37880949293218\tTime: 13.780389\n","\n","Validation loss decreased (0.387464 --> 0.331281).  Saving model\n","\n","Epoch Duration 119.37613916397095\n","Train Epoch: 3\tLoss: 0.320635\tTPR: 98.54771784232366\tTNR: 89.15693904020753\tTime: 3.195279\n","Val_loss: 0.261500\tTPR: 95.52238805970148\tTNR: 92.89136345979541\tTime: 13.953941\n","\n","Validation loss decreased (0.331281 --> 0.261500).  Saving model\n","\n","Epoch Duration 119.54647707939148\n","Train Epoch: 4\tLoss: 0.286285\tTPR: 97.30290456431536\tTNR: 91.73800259403372\tTime: 3.134381\n","Val_loss: 0.256570\tTPR: 94.94736842105263\tTNR: 93.06725411429312\tTime: 13.767036\n","\n","Validation loss decreased (0.261500 --> 0.256570).  Saving model\n","\n","Epoch Duration 119.5907552242279\n","Train Epoch: 5\tLoss: 0.245258\tTPR: 97.47899159663865\tTNR: 93.07931570762052\tTime: 3.223907\n","Val_loss: 0.238088\tTPR: 94.97907949790795\tTNR: 94.06274306455795\tTime: 13.837065\n","\n","Validation loss decreased (0.256570 --> 0.238088).  Saving model\n","\n","Epoch Duration 119.11999416351318\n","Train Epoch: 6\tLoss: 0.231975\tTPR: 97.30290456431536\tTNR: 93.73540856031128\tTime: 3.442770\n","Val_loss: 0.218822\tTPR: 94.32773109243698\tTNR: 94.97148781752203\tTime: 14.018229\n","\n","Validation loss decreased (0.238088 --> 0.218822).  Saving model\n","\n","Epoch Duration 120.3830578327179\n","Train Epoch: 7\tLoss: 0.227772\tTPR: 94.81327800829875\tTNR: 94.42282749675745\tTime: 3.204578\n","Val_loss: 0.199622\tTPR: 93.81663113006397\tTNR: 96.03780914152532\tTime: 13.886794\n","\n","Validation loss decreased (0.218822 --> 0.199622).  Saving model\n","\n","Epoch Duration 119.2988612651825\n","Train Epoch: 8\tLoss: 0.187454\tTPR: 97.87234042553192\tTNR: 94.85884485884486\tTime: 3.298143\n","Val_loss: 0.216580\tTPR: 93.38842975206612\tTNR: 96.26362221069019\tTime: 14.061434\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 117.61937808990479\n","Train Epoch: 9\tLoss: 0.174441\tTPR: 96.57387580299786\tTNR: 95.87055016181229\tTime: 2.986070\n","Val_loss: 0.217774\tTPR: 93.18181818181817\tTNR: 96.51011935651272\tTime: 13.887416\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 116.8219907283783\n","Train Epoch: 10\tLoss: 0.182836\tTPR: 96.19450317124736\tTNR: 96.11348620287602\tTime: 3.001804\n","Val_loss: 0.193679\tTPR: 93.55509355509356\tTNR: 96.64116197639736\tTime: 13.814523\n","\n","Validation loss decreased (0.199622 --> 0.193679).  Saving model\n","\n","Epoch Duration 118.63835501670837\n","Train Epoch: 11\tLoss: 0.184056\tTPR: 96.4509394572025\tTNR: 95.90302087384934\tTime: 3.391181\n","Val_loss: 0.198220\tTPR: 92.69311064718163\tTNR: 97.17360300790872\tTime: 13.844875\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 117.0983374118805\n","Train Epoch: 12\tLoss: 0.167705\tTPR: 96.88796680497926\tTNR: 96.54993514915694\tTime: 2.961170\n","Val_loss: 0.167500\tTPR: 94.91525423728814\tTNR: 96.9041450777202\tTime: 13.880331\n","\n","Validation loss decreased (0.193679 --> 0.167500).  Saving model\n","\n","Epoch Duration 119.53387951850891\n","Train Epoch: 13\tLoss: 0.166672\tTPR: 97.28601252609603\tTNR: 96.48645144561131\tTime: 3.393865\n","Val_loss: 0.206476\tTPR: 92.60780287474333\tTNR: 97.04088254380272\tTime: 13.736690\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 116.70124959945679\n","Train Epoch: 14\tLoss: 0.165983\tTPR: 95.82463465553236\tTNR: 96.78464929340075\tTime: 2.973477\n","Val_loss: 0.176403\tTPR: 94.18103448275862\tTNR: 97.46376811594203\tTime: 14.038495\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 116.31487679481506\n","Train Epoch: 15\tLoss: 0.156373\tTPR: 96.92622950819673\tTNR: 96.72897196261682\tTime: 2.969859\n","Val_loss: 0.163951\tTPR: 95.74468085106383\tTNR: 97.22869722869723\tTime: 13.939284\n","\n","Validation loss decreased (0.167500 --> 0.163951).  Saving model\n","\n","Epoch Duration 118.59940910339355\n","Train Epoch: 16\tLoss: 0.146801\tTPR: 97.68907563025209\tTNR: 96.90254017625712\tTime: 3.383428\n","Val_loss: 0.151439\tTPR: 95.36842105263158\tTNR: 97.48606971621096\tTime: 13.906749\n","\n","Validation loss decreased (0.163951 --> 0.151439).  Saving model\n","\n","Epoch Duration 119.25546526908875\n","Train Epoch: 17\tLoss: 0.137477\tTPR: 97.68907563025209\tTNR: 97.12286158631416\tTime: 3.411061\n","Val_loss: 0.135475\tTPR: 96.11231101511879\tTNR: 97.76167680165611\tTime: 13.818730\n","\n","Validation loss decreased (0.151439 --> 0.135475).  Saving model\n","\n","Epoch Duration 119.59827327728271\n","Train Epoch: 18\tLoss: 0.138922\tTPR: 97.7035490605428\tTNR: 96.95319590302087\tTime: 3.542298\n","Val_loss: 0.192897\tTPR: 92.51559251559252\tTNR: 97.26364933212294\tTime: 13.975500\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 117.07250928878784\n","Train Epoch: 19\tLoss: 0.141499\tTPR: 96.84873949579831\tTNR: 97.39502332814929\tTime: 2.960767\n","Val_loss: 0.158004\tTPR: 95.24793388429752\tTNR: 97.32745199792423\tTime: 14.003495\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 116.02526426315308\n","Train Epoch: 20\tLoss: 0.154765\tTPR: 97.11340206185567\tTNR: 96.89892305696121\tTime: 2.980133\n","Val_loss: 0.138903\tTPR: 95.03239740820734\tTNR: 97.92987449864148\tTime: 14.071662\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 116.44240665435791\n","Train Epoch: 21\tLoss: 0.148075\tTPR: 96.2655601659751\tTNR: 97.21141374837873\tTime: 2.999015\n","Val_loss: 0.157052\tTPR: 94.91525423728814\tTNR: 97.65544041450778\tTime: 13.810562\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 116.01362252235413\n","Train Epoch: 22\tLoss: 0.140435\tTPR: 97.28601252609603\tTNR: 97.31621936989498\tTime: 2.956787\n","Val_loss: 0.165806\tTPR: 95.36842105263158\tTNR: 97.66748736555655\tTime: 13.851787\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 116.35647749900818\n","Train Epoch: 23\tLoss: 0.134434\tTPR: 98.5200845665962\tTNR: 97.39603575592693\tTime: 2.956473\n","Val_loss: 0.133637\tTPR: 96.58848614072495\tTNR: 97.6692994950149\tTime: 13.849492\n","\n","Validation loss decreased (0.135475 --> 0.133637).  Saving model\n","\n","Epoch Duration 118.78121948242188\n","Train Epoch: 24\tLoss: 0.132049\tTPR: 98.3402489626556\tTNR: 97.12062256809338\tTime: 3.489575\n","Val_loss: 0.164270\tTPR: 94.6611909650924\tTNR: 97.19662556781311\tTime: 13.811623\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 116.92813634872437\n","Train Epoch: 25\tLoss: 0.140111\tTPR: 97.28601252609603\tTNR: 96.97912615065474\tTime: 2.967432\n","Val_loss: 0.180519\tTPR: 93.83983572895276\tTNR: 97.20960415314731\tTime: 13.901565\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 116.52516031265259\n","Train Epoch: 26\tLoss: 0.133291\tTPR: 97.91231732776617\tTNR: 97.38104498897965\tTime: 2.981575\n","Val_loss: 0.196091\tTPR: 92.06680584551148\tTNR: 97.6014520938675\tTime: 13.915873\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 116.25417256355286\n","Train Epoch: 27\tLoss: 0.136277\tTPR: 97.4947807933194\tTNR: 97.4847659795151\tTime: 2.962669\n","Val_loss: 0.159508\tTPR: 93.6842105263158\tTNR: 97.70636257613063\tTime: 13.848228\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 116.17601037025452\n","Train Epoch: 28\tLoss: 0.129201\tTPR: 98.10924369747899\tTNR: 97.5246241575946\tTime: 2.978159\n","Val_loss: 0.165351\tTPR: 95.37815126050421\tTNR: 97.49870399170555\tTime: 13.825928\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 116.26211547851562\n","Train Epoch: 29\tLoss: 0.130796\tTPR: 98.31932773109243\tTNR: 97.33022291342664\tTime: 2.967934\n","Val_loss: 0.184567\tTPR: 93.80165289256198\tTNR: 97.44421380384016\tTime: 13.888138\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 116.21311783790588\n","Train Epoch: 30\tLoss: 0.137305\tTPR: 97.4947807933194\tTNR: 97.4847659795151\tTime: 2.995967\n","Val_loss: 0.177695\tTPR: 93.72384937238493\tTNR: 97.3424941664506\tTime: 13.797267\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 116.3752715587616\n","Train Epoch: 31\tLoss: 0.137742\tTPR: 97.25158562367865\tTNR: 97.42194584790776\tTime: 2.950316\n","Val_loss: 0.141289\tTPR: 95.77167019027483\tTNR: 97.82355227361057\tTime: 13.705886\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 115.61875796318054\n","Train Epoch: 32\tLoss: 0.129201\tTPR: 98.14432989690721\tTNR: 97.39198131568703\tTime: 2.952012\n","Val_loss: 0.178640\tTPR: 93.30543933054393\tTNR: 97.8739953331605\tTime: 13.809790\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 116.02857685089111\n","Train Epoch: 33\tLoss: 0.128475\tTPR: 97.47899159663865\tTNR: 97.53758424053915\tTime: 2.958604\n","Val_loss: 0.166741\tTPR: 93.05263157894737\tTNR: 97.82298820785279\tTime: 13.918291\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 116.1864812374115\n","Train Epoch: 34\tLoss: 0.135106\tTPR: 97.05882352941177\tTNR: 97.57646448937273\tTime: 2.954601\n","Val_loss: 0.225119\tTPR: 92.85714285714286\tTNR: 97.13061542456505\tTime: 13.908617\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 115.7969024181366\n","Train Epoch: 35\tLoss: 0.125717\tTPR: 98.74739039665971\tTNR: 97.44587060806431\tTime: 2.948540\n","Val_loss: 0.129493\tTPR: 97.2457627118644\tTNR: 98.00518134715026\tTime: 13.814708\n","\n","Validation loss decreased (0.133637 --> 0.129493).  Saving model\n","\n","Epoch Duration 118.32152605056763\n","Train Epoch: 36\tLoss: 0.133407\tTPR: 97.47899159663865\tTNR: 97.57646448937273\tTime: 3.515743\n","Val_loss: 0.186718\tTPR: 93.72384937238493\tTNR: 97.5239823697174\tTime: 13.906411\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 117.25179123878479\n","Train Epoch: 37\tLoss: 0.133199\tTPR: 97.9381443298969\tTNR: 97.36603088101727\tTime: 2.960601\n","Val_loss: 0.167006\tTPR: 95.01039501039502\tTNR: 97.87316820127091\tTime: 13.850856\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 115.85520505905151\n","Train Epoch: 38\tLoss: 0.123406\tTPR: 98.12108559498957\tTNR: 97.84778944638921\tTime: 2.979133\n","Val_loss: 0.127230\tTPR: 96.13733905579399\tTNR: 98.08439037017862\tTime: 13.962878\n","\n","Validation loss decreased (0.129493 --> 0.127230).  Saving model\n","\n","Epoch Duration 119.44380521774292\n","Train Epoch: 39\tLoss: 0.114426\tTPR: 98.0603448275862\tTNR: 97.83902691511386\tTime: 3.128540\n","Val_loss: 0.184924\tTPR: 93.6734693877551\tTNR: 97.63697740846533\tTime: 13.797518\n","\n","EarlyStopping counter: 1 out of 20\n","\n","Epoch Duration 116.39223551750183\n","Train Epoch: 40\tLoss: 0.127472\tTPR: 97.7035490605428\tTNR: 97.76999870348762\tTime: 2.992325\n","Val_loss: 0.161492\tTPR: 94.86081370449678\tTNR: 97.6051779935275\tTime: 13.881233\n","\n","EarlyStopping counter: 2 out of 20\n","\n","Epoch Duration 116.02345275878906\n","Train Epoch: 41\tLoss: 0.121768\tTPR: 97.65957446808511\tTNR: 97.75964775964776\tTime: 2.994482\n","Val_loss: 0.181772\tTPR: 93.47368421052632\tTNR: 97.78411299727874\tTime: 13.834658\n","\n","EarlyStopping counter: 3 out of 20\n","\n","Epoch Duration 116.31060862541199\n","Train Epoch: 42\tLoss: 0.116243\tTPR: 98.09725158562368\tTNR: 97.79764218162974\tTime: 2.965161\n","Val_loss: 0.180859\tTPR: 93.80165289256198\tTNR: 97.78152568759731\tTime: 13.771888\n","\n","EarlyStopping counter: 4 out of 20\n","\n","Epoch Duration 115.74059987068176\n","Train Epoch: 43\tLoss: 0.104891\tTPR: 98.94291754756871\tTNR: 98.10856328539967\tTime: 2.951678\n","Val_loss: 0.227362\tTPR: 91.48073022312373\tTNR: 97.53214703208208\tTime: 13.742808\n","\n","EarlyStopping counter: 5 out of 20\n","\n","Epoch Duration 115.78090763092041\n","Train Epoch: 44\tLoss: 0.141524\tTPR: 97.4947807933194\tTNR: 97.70517308440296\tTime: 2.950389\n","Val_loss: 0.151307\tTPR: 95.56025369978859\tTNR: 97.81059722762015\tTime: 13.718392\n","\n","EarlyStopping counter: 6 out of 20\n","\n","Epoch Duration 115.92581462860107\n","Train Epoch: 45\tLoss: 0.123768\tTPR: 98.12108559498957\tTNR: 97.67924283676909\tTime: 2.944504\n","Val_loss: 0.144179\tTPR: 95.57894736842105\tTNR: 98.14694829596993\tTime: 13.796180\n","\n","EarlyStopping counter: 7 out of 20\n","\n","Epoch Duration 115.68189239501953\n","Train Epoch: 46\tLoss: 0.114396\tTPR: 98.13278008298755\tTNR: 98.10635538261997\tTime: 2.957173\n","Val_loss: 0.223604\tTPR: 92.46861924686193\tTNR: 97.67954368680321\tTime: 13.736398\n","\n","EarlyStopping counter: 8 out of 20\n","\n","Epoch Duration 116.13533520698547\n","Train Epoch: 47\tLoss: 0.108836\tTPR: 99.36974789915966\tTNR: 97.92638672887507\tTime: 2.942672\n","Val_loss: 0.152928\tTPR: 95.1063829787234\tTNR: 97.68194768194768\tTime: 13.724083\n","\n","EarlyStopping counter: 9 out of 20\n","\n","Epoch Duration 115.53228425979614\n","Train Epoch: 48\tLoss: 0.126722\tTPR: 97.44680851063829\tTNR: 97.73374773374773\tTime: 2.962120\n","Val_loss: 0.174974\tTPR: 93.97089397089398\tTNR: 97.65270392945143\tTime: 13.747246\n","\n","EarlyStopping counter: 10 out of 20\n","\n","Epoch Duration 115.85696768760681\n","Train Epoch: 49\tLoss: 0.121606\tTPR: 97.67441860465115\tTNR: 97.74582199766809\tTime: 2.955495\n","Val_loss: 0.133010\tTPR: 95.76271186440678\tTNR: 98.05699481865285\tTime: 13.743591\n","\n","EarlyStopping counter: 11 out of 20\n","\n","Epoch Duration 115.7403724193573\n","Train Epoch: 50\tLoss: 0.118148\tTPR: 98.74739039665971\tTNR: 97.74406845585375\tTime: 2.959930\n","Val_loss: 0.154069\tTPR: 94.91525423728814\tTNR: 98.13471502590674\tTime: 13.744188\n","\n","EarlyStopping counter: 12 out of 20\n","\n","Epoch Duration 115.68204283714294\n","Train Epoch: 51\tLoss: 0.119086\tTPR: 97.74590163934425\tTNR: 97.89719626168224\tTime: 2.965134\n","Val_loss: 0.174648\tTPR: 94.35146443514645\tTNR: 97.91288566243193\tTime: 13.661968\n","\n","EarlyStopping counter: 13 out of 20\n","\n","Epoch Duration 115.6228015422821\n","Train Epoch: 52\tLoss: 0.108376\tTPR: 99.1701244813278\tTNR: 97.98962386511025\tTime: 2.965561\n","Val_loss: 0.238717\tTPR: 89.87603305785123\tTNR: 97.79449922158796\tTime: 13.831708\n","\n","EarlyStopping counter: 14 out of 20\n","\n","Epoch Duration 115.86361360549927\n","Train Epoch: 53\tLoss: 0.118279\tTPR: 97.5103734439834\tTNR: 98.09338521400778\tTime: 2.960714\n","Val_loss: 0.210047\tTPR: 92.25941422594143\tTNR: 98.15919108115115\tTime: 13.727593\n","\n","EarlyStopping counter: 15 out of 20\n","\n","Epoch Duration 115.70717740058899\n","Train Epoch: 54\tLoss: 0.106862\tTPR: 98.12108559498957\tTNR: 98.26267340853106\tTime: 2.970921\n","Val_loss: 0.158963\tTPR: 94.0677966101695\tTNR: 98.17357512953367\tTime: 14.294015\n","\n","EarlyStopping counter: 16 out of 20\n","\n","Epoch Duration 116.86217880249023\n","Train Epoch: 55\tLoss: 0.109692\tTPR: 98.29787234042553\tTNR: 98.05749805749807\tTime: 2.980848\n","Val_loss: 0.191101\tTPR: 92.43697478991596\tTNR: 97.77086573354069\tTime: 13.789614\n","\n","EarlyStopping counter: 17 out of 20\n","\n","Epoch Duration 115.66149568557739\n","Train Epoch: 56\tLoss: 0.108427\tTPR: 98.73949579831933\tTNR: 98.09486780715396\tTime: 2.951042\n","Val_loss: 0.182123\tTPR: 91.78947368421052\tTNR: 97.96553064662433\tTime: 13.834290\n","\n","EarlyStopping counter: 18 out of 20\n","\n","Epoch Duration 115.83104348182678\n","Train Epoch: 57\tLoss: 0.121636\tTPR: 97.65957446808511\tTNR: 98.05749805749807\tTime: 3.079469\n","Val_loss: 0.156510\tTPR: 94.68085106382979\tTNR: 97.55244755244755\tTime: 13.710220\n","\n","EarlyStopping counter: 19 out of 20\n","\n","Epoch Duration 116.02934551239014\n","Train Epoch: 58\tLoss: 0.128136\tTPR: 97.26890756302521\tTNR: 97.49870399170555\tTime: 2.958881\n","Val_loss: 0.191779\tTPR: 93.69747899159664\tTNR: 97.66718506998446\tTime: 13.948329\n","\n","EarlyStopping counter: 20 out of 20\n","\n","Early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DALJyzvMmvRj","colab_type":"code","colab":{}},"source":["   \n"],"execution_count":null,"outputs":[]}]}